{"index":{"slug":"index","filePath":"index.md","title":"Zero's Garden","links":["maps/Public-Cloud-Map","maps/SRE-Map","Taking-notes","maps/AI-Productivity-Tool-Map"],"tags":[],"content":"Welcome to my digital garden, where I keep notes of my thoughts and knowledge about topics I’m interested in like computer science.\nNotes are loosely grouped into topics and interconnected, and there is no strict hierarchy. Here are some top-level links to expand on.\n\nPublic Cloud Map\nSRE Map\nTaking notes\nAI Productivity Tool Map\n\nTo focus on permanent notes and keep the scale of this place under control, fleeting notes and automatically imported notes are stored in a separate Logseq graph inspired by note.xuanwo.io/.\nPersonal Use Notice\nContent on this website is provided “as is” and the author may move or delete content at any time, causing link rot.\nIt is therefore not recommended to directly link to any specific notes on this website, except as required by the CC BY-NC-ND 4.0 license.\nYou may contact the author if you need a stable reference. The author may decide, at their sole discretion, to publish a blog post on l2dy.github.io/blog/.\nLegal Notice\nUnless otherwise stated, content on this website is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License."},"maps/AI-Productivity-Tool-Map":{"slug":"maps/AI-Productivity-Tool-Map","filePath":"maps/AI Productivity Tool Map.md","title":"AI Productivity Tool Map","links":["notes/AI/Claude-Code","notes/AI/Codex-CLI","notes/AI/LLM-model-comparison-and-leaderboards"],"tags":[],"content":"Chatbots\n\nChatGPT\nGemini\nDeepSeek\nZ.ai Cchat\nKimi AI\n\nCoding Assistant\n\nGitHub Copilot\nGemini CLI\nClaude Code\nCodex CLI\nAmazon Q Developer, 50 agentic requests per month free\n\nModels\n\nLLM model comparison and leaderboards\n"},"maps/AWS-Map":{"slug":"maps/AWS-Map","filePath":"maps/AWS Map.md","title":"AWS Map","links":["notes/Cloud/AWS/AWS-backbone-network","notes/Cloud/AWS/AWS-VPC","notes/Cloud/AWS/Hyperplane","notes/Cloud/AWS/Network-Load-Balancer","notes/Cloud/AWS/AWS-pitfalls"],"tags":[],"content":"Networking\nThe AWS backbone network connects AWS Regions, Availability Zones, and the Internet.\nAWS VPC is a SDN built for AWS powering isolated virtual networks.\nHyperplane is an AWS internal network load balancing service, powering other AWS services such as the Network Load Balancer (NLB) and EFS.\nOther Notes\nAWS pitfalls"},"maps/Computer-Networking-Map":{"slug":"maps/Computer-Networking-Map","filePath":"maps/Computer Networking Map.md","title":"Computer Networking Map","links":["notes/Network/NIC-offload","notes/Network/NIC-scaling-and-steering"],"tags":[],"content":"NIC\nNetwork interface controller (NIC) is the hardware component for networking.\n\nNIC offload\nNIC scaling and steering\n\nTCP\nTODOs\n\nCongestion Control Algorithms\nexplicit congestion notification (ECN)\nHyStart++\nSACK loss recovery\nProportional Rate Reduction (RFC6937)\nbandwidth-delay product (BDP)\npacket pacing\nBBRv3 for WAN traffic and BBR.Swift for traffic within a datacenter\n"},"maps/DevOps-Roadmap":{"slug":"maps/DevOps-Roadmap","filePath":"maps/DevOps Roadmap.md","title":"DevOps Roadmap","links":[],"tags":[],"content":"mindmap\n\troot((DevOps))\n\t\tDevelopment\n\t\t\tProject Management\n\t\t\tCoding Skills\n\t\t\tSoftware Engineering\n\t\t\tArchitecture\n\t\t\t\tTrade-offs\n\t\t\t\tPerformance\n\t\t\t\tComplexity\n\t\t\t\tResilience, e.g. user quota, load shedding\n\t\t\t\tExtensibility, e.g. bfe\n\t\t\t\tServicability, e.g. cloud infra that supports VM live migration\n\t\t\tEffort Estimation\n\t\t\tContinuous Integration\n\t\t\t\tUnit &amp; Integration Testing\n\t\t\t\tStatic analysis, e.g. SonarQube, npm audit\n\t\t\t\tDynamic analysis, e.g. fuzzing, ASan\n\t\tOperations\n\t\t\tContinuous Delivery\n\t\t\t\tProduction tests\n\t\t\t\tStress Testing\n\t\t\t\tCanary Testing\n\t\t\tProduction Platform\n\t\t\t\tInfrastructure Frameworks\n\t\t\tResilience\n\t\t\t\tDisaster Recovery\n\t\t\t\tChaos Engineering\n\t\t\tElasticity\n\t\t\t\tLoad Balancing\n\t\t\t\tAuto Scaling\n\t\t\tSecurity\n\t\t\t\tWAF\n\t\t\t\tHIDS\n\t\t\t\tZero Trust\n\t\t\tObservability\n\t\t\t\tMetrics and Logs\n\t\t\t\tTraces\n\t\t\t\tContinuous Profiling\n\t\t\t\tAlerting\n\t\t\t\tService Level Objectives\n\t\t\tTroubleshooting\n\t\t\t\tEmergency Response\n\t\t\t\tLinux skills\n\t\t\t\tNetworking\n\t\t\tProcess\n\t\t\t\tChange Management\n\t\t\t\tPlaybooks\n\t\t\t\tAutomation\n\t\t\t\tOn-Call Rotation\n\t\t\tCost &amp; Performance Optimization\n\t\t\t\tCost Data Analysis\n\t\t\t\tTracing and Profiling\n\t\t\t\tCapacity Planning\n\t\t\tManagement &amp; Culture\n\t\t\t\tBlameless Postmortem or Post-Incident Reviews\n\t\t\t\tTeam Structure\n\t\t\t\tTeamwork\n\t\t\t\tOKR\n\t\t\t\tData-Driven\n\nExternal references\n\nGeneric mitigations www.oreilly.com/content/generic-mitigations/\n"},"maps/FreeBSD-Map":{"slug":"maps/FreeBSD-Map","filePath":"maps/FreeBSD Map.md","title":"FreeBSD Map","links":["notes/Operating-System/FreeBSD/DTrace","notes/Operating-System/FreeBSD/Upgrading-FreeBSD"],"tags":[],"content":"Features\n\nDTrace\n\nNotes\n\nUpgrading FreeBSD\n"},"maps/Google-Cloud-Map":{"slug":"maps/Google-Cloud-Map","filePath":"maps/Google Cloud Map.md","title":"Google Cloud Map","links":["notes/Cloud/Google-Cloud/Andromeda","notes/Cloud/Google-Cloud/Maglev"],"tags":[],"content":"Networking\nAndromeda powers VM-to-VM communication.\nMaglev powers regional Network Load Balancers."},"maps/Linux-Map":{"slug":"maps/Linux-Map","filePath":"maps/Linux Map.md","title":"Linux Map","links":["notes/Operating-System/Linux/De-prioritize-Linux-process","notes/Operating-System/Linux/TCP-kernel-parameters","notes/Network/SNMPv2-TCP-statistics","notes/Operating-System/Linux/BBR","notes/Operating-System/Linux/Firewalld","notes/Operating-System/Linux/nftables","notes/Operating-System/Linux/SysRq-key","notes/Operating-System/Linux/BPF"],"tags":[],"content":"Process\nScheduling\n\nDe-prioritize Linux process\n\nNetwork\nTCP\n\nTCP kernel parameters\nSNMPv2 TCP statistics\nBBR\n\nFirewall\n\nFirewalld\nnftables\n\nAdministration\n\nSysRq key\n\nBPF\n\nBPF\n"},"maps/Microsoft-Azure-Map":{"slug":"maps/Microsoft-Azure-Map","filePath":"maps/Microsoft Azure Map.md","title":"Microsoft Azure Map","links":["notes/Cloud/Azure/Virtual-Filtering-Platform","notes/Cloud/Azure/Azure-Accelerated-Networking","notes/Cloud/Azure/Azure-Load-Balancer","notes/Cloud/Azure/Ananta","notes/Network/Direct-Server-Return","notes/Cloud/Azure/Azure-Blob-Storage"],"tags":[],"content":"Networking\nAzure Host SDN is comprised of Virtual Filtering Platform and the hardware offload counterpart Azure Accelerated Networking (AccelNet) with Azure SmartNIC based on FPGAs.\nAzure Load Balancer implements L4 load balancing powered by Ananta, utilizing DSR and VM-to-VM Fastpath to reduce number of packets processed.\nAzure Blob Storage is an object storage service, equivalent to Amazon S3 on Azure.\nWith stateless fallback on load balancers and host connection limit, the Azure networking stack is hostile to long-lived connections, especially in large quantities."},"maps/NGINX-Map":{"slug":"maps/NGINX-Map","filePath":"maps/NGINX Map.md","title":"NGINX Map","links":["notes/NGINX/NGINX-location-directive","notes/NGINX/NGINX-HTTP-variables-to-log","notes/NGINX/Byte-range-request","notes/NGINX/proxy/Headers-in-NGINX","notes/NGINX/proxy/Health-Checks-in-NGINX","notes/NGINX/proxy/How-NGINX-round-robin-upstream-implements-passive-health-checks","notes/NGINX/proxy/Upstream-Keepalive","notes/NGINX/NGINX-realip-configuration-for-Cloudflare","notes/Performance-tuning/Optimize-single-box-NGINX-performance","notes/NGINX/NGINX-proxy-cache","notes/NGINX/NGINX-IPv6-rate-limiting","notes/NGINX/openresty/Customize-error-page-of-ngx.exit","notes/NGINX/NGINX-code-walkthrough---Client-closed-request","notes/NGINX/NGINX-code-walkthrough---Upstream-connect-timeout","notes/NGINX/NGINX-thundering-herd-problem"],"tags":[],"content":"NGINX is a high-performance Web server, mostly used to serve HTTP requests.\nConfiguration\n\nNGINX location directive\nNGINX HTTP variables to log\nByte-range request\nProxy\n\nHeaders in NGINX\nHealth Checks in NGINX\n\nHow NGINX round-robin upstream implements passive health checks\n\n\nUpstream Keepalive\n\n\nNGINX realip configuration for Cloudflare\n\nOptimization\n\nOptimize single-box NGINX performance\nNGINX proxy cache\n\nAccess Control\n\nNGINX IPv6 rate limiting\nCustomize error page of ngx.exit (with Lua)\n\nCode Walkthrough\n\nNGINX code walkthrough - Client closed request\nNGINX code walkthrough - Upstream connect timeout\nNGINX thundering herd problem\n\nQuick Notes\n\nNGINX reserves a large amount of RAM if worker_connections is set to an unreasonable value.\nserver_tokens is best turned off to reduce metadata leak and save bandwidth.\nNested locations are a trap where proxy_pass does not get inherited. Avoid them if possible.\nIncrease proxy_buffers and client_body_buffer_size to save a temporary file read and write, but note that it also increases memory pressure.\n"},"maps/Package-Managers-Map":{"slug":"maps/Package-Managers-Map","filePath":"maps/Package Managers Map.md","title":"Package Managers Map","links":[],"tags":[],"content":"For use in $HOME:\n\ngithub.com/conda-forge/miniforge, with the conda-forge channel set as the default (and only) channel.\n\nFor deterministic and declarative configuration:\n\nNix with nix-installer, and\nhome-mangler for a lightweight package-only alternative to home-manager, or\nnix-darwin for declarative system-wide configuration on macOS.\n\nTraditional package managers:\n\nMacPorts (macOS)\nDNF with RPM\nAPT with dpkg or alternative frontends like oma\n"},"maps/Presentation-Skills-Map":{"slug":"maps/Presentation-Skills-Map","filePath":"maps/Presentation Skills Map.md","title":"Presentation Skills Map","links":["notes/Note-Making/Open-source-diagram-editors"],"tags":[],"content":"Diagrams\nOpen source diagram editors"},"maps/Public-Cloud-Map":{"slug":"maps/Public-Cloud-Map","filePath":"maps/Public Cloud Map.md","title":"Public Cloud Map","links":["maps/AWS-Map","maps/Microsoft-Azure-Map","maps/Google-Cloud-Map","notes/Cloud/AWS/AWS-pitfalls"],"tags":[],"content":"Architecture Exploration\n\nAWS Map\nMicrosoft Azure Map\nGoogle Cloud Map\n\nNitty-Gritty\n\nAWS pitfalls\n"},"maps/SRE-Map":{"slug":"maps/SRE-Map","filePath":"maps/SRE Map.md","title":"SRE Map","links":["notes/SRE/On-Call","notes/SRE/Monitoring","notes/SRE/Emergency-Response","notes/SRE/Change-Management","notes/SRE/Capacity-Planning","notes/SRE/Measuring-Service-Risk","notes/SRE/Managing-Service-Risk","notes/SRE/Eliminating-Toil"],"tags":["sre"],"content":"Definition\nSRE is what happens when you ask a software engineer to design an ops team.\nWe want systems that runs and repairs itself: automatic, not just automated.\nTopics\n\nOn-Call\nMonitoring\nEmergency Response\nChange Management\nCapacity Planning\nRisk Management\n\nMeasuring Service Risk\nManaging Service Risk\n\n\nEliminating Toil\nSimplicity\n\nSRE teams should\n\nPush back when accidental complexity is introduced into the systems for which they are responsible.\nConstantly strive to eliminate complexity in systems they onboard and for which they assume operational responsibility.\n\n\n\n\nHierarchy of Needs (from most basic to most advanced)\n\nMonitoring\nIncident Response\nPostmertem w/ RCA\nTesting and Release procedures\nCapacity Planning\nDevelopment\nProduct\n\n\n"},"maps/Self-Hosting-Map":{"slug":"maps/Self-Hosting-Map","filePath":"maps/Self-Hosting Map.md","title":"Self-Hosting Map","links":["notes/Self-Hosting/NAS-solutions"],"tags":[],"content":"Network\nStorage\nNAS solutions"},"notes/AI/Claude-Code":{"slug":"notes/AI/Claude-Code","filePath":"notes/AI/Claude Code.md","title":"Claude Code","links":[],"tags":[],"content":"CCometixLine\n# docs.claude.com/en/docs/claude-code/setup\ncurl -fsSL claude.ai/install.sh | bash\n \n# fancy statusline\ngit clone github.com/Haleclipse/CCometixLine.git\ncd CCometixLine\ncargo build --release\n \nmkdir -p ~/.claude/ccline\ncp target/release/ccometixline ~/.claude/ccline/ccline\nchmod +x ~/.claude/ccline/ccline\n \n \n# then edit your `.claude/settings.json` docs.claude.com/en/docs/claude-code/statusline\n{\n  &quot;statusLine&quot;: {\n    &quot;type&quot;: &quot;command&quot;,\n    &quot;command&quot;: &quot;~/.claude/ccline/ccline&quot;,\n    &quot;padding&quot;: 0\n  },\n  &quot;env&quot;: {\n    &quot;CLAUDE_CODE_DISABLE_NONESSENTIAL_TRAFFIC&quot;: &quot;1&quot;\n  }\n}\nShort-lived node process\nCCometixLine calls npm view, which fetches the latest Claude Code version from the npm registry - this happens when the usage segment is enabled.\nConfig\n\nIt’s recommended to disable auto-compact and “micromanage” the context window of each session, unless you need very long sessions of YOLO mode.\n\nKeyboard shortcuts\n\nCtrl+R to search prompt history, and Esc to modify the selected prompt.\n\nPlan usage limits\nsupport.claude.com/en/articles/11145838-using-claude-code-with-your-pro-or-max-plan\nReference prompts\n(In plan mode)\n&gt; I need to refactor our authentication system to use OAuth2. Create a detailed migration plan.\n\n...\n\n&gt; Create a detailed MIGRATION_PLAN.md file that includes:\n- All migration phases and steps\n- Dependencies between steps\n- Estimated effort for each phase\n- Success criteria and checkpoints\n- Any risks or considerations\n\nThis will help me track progress across multiple sessions.\n\nCompare your xxx changes with other files in the same directory. Does your implementation match existing conventions?\n\nReview Phase 5 Checkpoint in MIGRATION_PLAN.md to see if it has been correctly implemented.\n\nUpdate MIGRATION_PLAN.md accordingly. Only fix discrepencies and keep the implementation status unchanged.\nDon&#039;t include &quot;changed xxx&quot; phrases. Instead, focus on guiding someone who wants to implement this from scratch without our reference implementation.\nDon&#039;t include complete file content as it would limit divergent thinking.\n\nLet Claude Code name the file:\nWrite it to docs/*.md\n\nSystem prompt evolution\ngithub.com/marckrenn/cc-mvp-prompts"},"notes/AI/CodeLayer":{"slug":"notes/AI/CodeLayer","filePath":"notes/AI/CodeLayer.md","title":"CodeLayer","links":[],"tags":[],"content":"macOS install\nInstall the app from .dmg and run:\nsudo ln -s /Applications/CodeLayer-Nightly.app/Contents/Resources/bin/humanlayer codelayer-nightly;\nfor i in cld hld humanlayer; do sudo ln -s &quot;/Applications/CodeLayer-Nightly.app/Contents/Resources/bin/$i&quot; &quot;/usr/local/bin/$i-nightly&quot;; done\nUsage\nUse slash commands, as documented in github.com/humanlayer/humanlayer/blob/bdea199cec94a1605d2a0de42309d67a14dafdf2/CONTRIBUTING.md."},"notes/AI/Codex-CLI":{"slug":"notes/AI/Codex-CLI","filePath":"notes/AI/Codex CLI.md","title":"Codex CLI","links":[],"tags":[],"content":"Configuration\ndisable_response_storage = true\nThe official documentation’s “Required for ZDR orgs.” refers to Zero Data Retention.\nLogin\nrequires_openai_auth = true\nIf using a single provider with responses API, you may set requires_openai_auth on the model provider and save your API key with codex login:\nprintenv OPENAI_API_KEY | codex login --with-api-key\ncodex login --with-api-key &lt; my_key.txt\nOtherwise, use API key (if needed) from the “env_key” environment variable, or specify the header statically:\nhttp_headers = { &quot;Authorization&quot; = &quot;Bearer sk-...&quot; }\nReferences\n\ngithub.com/openai/codex/blob/26f7c46856060f440615645bdf2faf9e62c74e72/codex-rs/core/src/model_provider_info.rs#L83-L86\n"},"notes/AI/Good-Reads-on-AI":{"slug":"notes/AI/Good-Reads-on-AI","filePath":"notes/AI/Good Reads on AI.md","title":"Good Reads on AI","links":[],"tags":[],"content":"Fundamental:\n\nEngineering Fear grepmeetsworld.blog/engineering-fear-the-real-currency-of-ai-hype/\nThe Software Engineering Identity Crisis annievella.com/posts/the-software-engineering-identity-crisis/\n\nSpecific arguments:\n\nThe AI coding trap chrisloy.dev/post/2025/09/28/the-ai-coding-trap\nWhy I stopped using AI code editors lucianonooijen.com/blog/why-i-stopped-using-ai-code-editors/\nAI and the new junior engineer rosipov.com/blog/ai-and-the-new-junior-engineer/\nWhen (not) to use an AI agent? learn.microsoft.com/en-us/agent-framework/overview/agent-framework-overview\n\nInteresting projects:\n\ngithub.com/wedow/ticket\n"},"notes/AI/LLM-model-comparison-and-leaderboards":{"slug":"notes/AI/LLM-model-comparison-and-leaderboards","filePath":"notes/AI/LLM model comparison and leaderboards.md","title":"LLM model comparison and leaderboards","links":[],"tags":[],"content":"Price\npricepertoken.com/\nPerformance\nCoding\n\nleaderboard.letta.com/\nmetr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/\nswe-rebench.com/\nwww.swebench.com/\nwww.tbench.ai/leaderboard\nlmarena.ai/leaderboard (crowdsourced, less accurate for high-complexity tasks)\nllm-stats.com/\n"},"notes/AI/Opus-4.5-demo":{"slug":"notes/AI/Opus-4.5-demo","filePath":"notes/AI/Opus 4.5 demo.md","title":"Opus 4.5 demo","links":[],"tags":[],"content":"Systemd Timer with Traffic Shaping\nThis guide explains how to set up a scheduled task using systemd timers with automatic network bandwidth limiting. This pattern is useful for resource-intensive tasks like backups, data synchronization, or batch uploads that should run during off-peak hours without saturating network bandwidth.\nOverview\nThe setup consists of three components:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComponentPurposeService unitDefines the task to run (oneshot)Timer unitSchedules when the service runsTraffic control scriptManages bandwidth limiting via tc\nHow It Works\n┌─────────────┐     triggers      ┌─────────────────┐\n│   Timer     │ ─────────────────▶│    Service      │\n│  (systemd)  │                   │   (oneshot)     │\n└─────────────┘                   └────────┬────────┘\n                                           │\n                    ┌──────────────────────┼──────────────────────┐\n                    │                      │                      │\n                    ▼                      ▼                      ▼\n            ┌──────────────┐      ┌──────────────┐      ┌──────────────┐\n            │ ExecStartPre │      │  ExecStart   │      │ ExecStopPost │\n            │  (as root)   │      │  (as user)   │      │  (as root)   │\n            │              │      │              │      │              │\n            │ Enable tc    │      │  Run task    │      │ Disable tc   │\n            │ shaping      │      │              │      │ shaping      │\n            └──────────────┘      └──────────────┘      └──────────────┘\n\n\nThe timer triggers the service at the scheduled time\nExecStartPre runs as root (+ prefix) to set up traffic shaping\nExecStart runs the actual task as a non-root user\nExecStopPost cleans up traffic shaping rules (runs even if the task fails)\n\nTraffic Shaping Mechanism\nThe traffic control script uses Linux’s HTB (Hierarchical Token Bucket) qdisc combined with iptables cgroup matching:\n\nHTB Qdisc: Creates a traffic class hierarchy on the network interface\nBandwidth Class: Adds a rate-limited class for the task’s traffic\nCgroup Matching: Uses iptables to mark packets from the service’s cgroup\nPacket Filter: Directs marked packets to the bandwidth-limited class\n\nThis approach is superior to application-level throttling because:\n\nWorks with any program (no application support required)\nApplies to all child processes automatically\nUses kernel-level queuing for accurate rate limiting\n\nService Unit Structure\n[Unit]\nDescription=Scheduled Task with Bandwidth Limiting\nAfter=network.target\n \n[Service]\nType=oneshot\nUser=taskuser\nGroup=taskgroup\nExecStartPre=+/usr/local/bin/tc-shape.sh start eth0 50mbit\nExecStart=/path/to/your/task\nExecStopPost=+/usr/local/bin/tc-shape.sh stop eth0\nKey points:\n\nType=oneshot: Service runs once and exits\nUser/Group: Run the task as a non-root user for security\n+ prefix: Run the traffic control script as root (required for tc/iptables)\nExecStopPost: Always runs, ensuring cleanup even on failure\n\nTimer Unit Structure\n[Unit]\nDescription=Daily Task Timer\n \n[Timer]\nOnCalendar=*-*-* 01:00:00\nPersistent=true\n \n[Install]\nWantedBy=timers.target\nKey points:\n\nOnCalendar: Defines the schedule using systemd calendar syntax\nPersistent=true: If the system was off at the scheduled time, run immediately on next boot\n\nCommon Schedule Examples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScheduleOnCalendar ValueDaily at 01:00*-*-* 01:00:00Every Monday at 01:00Mon *-*-* 01:00:00Twice daily (01:00 and 13:00)*-*-* 01,13:00:00Every 6 hours*-*-* 00/6:00:00First day of month*-*-01 01:00:00\nTraffic Control Script\nThe script accepts start and stop commands with optional interface and rate parameters:\n#!/bin/bash\n# Usage: tc-shape.sh start|stop [interface] [rate]\n \nset -euo pipefail\n \nACTION=&quot;${1:-}&quot;\nIFACE=&quot;${2:-eth0}&quot;\nRATE=&quot;${3:-50mbit}&quot;\nMARK=&quot;0x12345&quot;\nCGROUP_PATH=&quot;system.slice/your-service.service&quot;\nCLASSID=&quot;1:10&quot;\n \ncase &quot;$ACTION&quot; in\n    start)\n        # Set up HTB qdisc if not present\n        if ! tc qdisc show dev &quot;$IFACE&quot; | grep -q &quot;htb 1:&quot;; then\n            tc qdisc add dev &quot;$IFACE&quot; root handle 1: htb default 99\n            tc class add dev &quot;$IFACE&quot; parent 1: classid 1:99 htb rate 10gbit\n            tc qdisc add dev &quot;$IFACE&quot; parent 1:99 fq_codel\n        fi\n \n        # Add bandwidth-limited class\n        if tc class add dev &quot;$IFACE&quot; parent 1: classid &quot;$CLASSID&quot; htb rate &quot;$RATE&quot; ceil &quot;$RATE&quot; 2&gt;/dev/null; then\n            tc qdisc add dev &quot;$IFACE&quot; parent &quot;$CLASSID&quot; fq_codel\n        else\n            tc class change dev &quot;$IFACE&quot; parent 1: classid &quot;$CLASSID&quot; htb rate &quot;$RATE&quot; ceil &quot;$RATE&quot;\n        fi\n \n        # Filter marked packets to limited class\n        tc filter add dev &quot;$IFACE&quot; parent 1: protocol ip prio 1 handle &quot;$MARK&quot; fw flowid &quot;$CLASSID&quot; 2&gt;/dev/null || true\n \n        # Mark packets from service cgroup\n        iptables -t mangle -C OUTPUT -m cgroup --path &quot;$CGROUP_PATH&quot; -j MARK --set-mark &quot;$MARK&quot; 2&gt;/dev/null || \\\n            iptables -t mangle -A OUTPUT -m cgroup --path &quot;$CGROUP_PATH&quot; -j MARK --set-mark &quot;$MARK&quot;\n \n        echo &quot;Traffic shaping enabled: $RATE on $IFACE&quot;\n        ;;\n \n    stop)\n        # Remove iptables rule\n        iptables -t mangle -D OUTPUT -m cgroup --path &quot;$CGROUP_PATH&quot; -j MARK --set-mark &quot;$MARK&quot; 2&gt;/dev/null || true\n \n        # Remove tc filter and class\n        tc filter del dev &quot;$IFACE&quot; parent 1: protocol ip prio 1 handle &quot;$MARK&quot; fw 2&gt;/dev/null || true\n        tc class del dev &quot;$IFACE&quot; parent 1: classid &quot;$CLASSID&quot; 2&gt;/dev/null || true\n \n        echo &quot;Traffic shaping disabled&quot;\n        ;;\n \n    *)\n        echo &quot;Usage: $0 start|stop [interface] [rate]&quot; &gt;&amp;2\n        exit 1\n        ;;\nesac\nInstallation\n# Install the traffic control script\nsudo install -m 755 tc-shape.sh /usr/local/bin/\n \n# Install systemd units\nsudo cp your-task.service your-task.timer /etc/systemd/system/\n \n# Reload systemd and enable the timer\nsudo systemctl daemon-reload\nsudo systemctl enable --now your-task.timer\nConfiguration\nNetwork Interface\nFind your interface name:\nip link show\nUpdate the service file with the correct interface name in ExecStartPre and ExecStopPost.\nCgroup Path\nThe cgroup path in the traffic control script must match the service name:\nsystem.slice/&lt;service-name&gt;.service\n\nOperations\nManual Trigger\nsudo systemctl start your-task.service\nCheck Timer Status\nsystemctl list-timers your-task.timer\nView Logs\njournalctl -u your-task.service\nMonitor Traffic Shaping\n# Watch bandwidth usage\nwatch -n1 &#039;tc -s class show dev eth0 | grep -A4 &quot;class htb 1:10&quot;&#039;\n \n# View processes in cgroup\nsystemd-cgls /system.slice/your-task.service\nRequirements\n\nLinux with systemd\niproute2 (provides tc command)\niptables with cgroup match support (xt_cgroup kernel module)\n\nVerify cgroup support:\nmodinfo xt_cgroup\nTroubleshooting\nTimer Not Firing\n# Check timer status\nsystemctl status your-task.timer\n \n# Verify timer is enabled\nsystemctl is-enabled your-task.timer\nTraffic Shaping Not Working\n# Check if qdisc is set up\ntc qdisc show dev eth0\n \n# Check if class exists\ntc class show dev eth0\n \n# Check iptables rules\niptables -t mangle -L OUTPUT -v\nPermission Errors\nEnsure the + prefix is used for ExecStartPre and ExecStopPost to run as root.\nSecurity Considerations\n\nRun the actual task as a non-privileged user\nOnly the traffic control setup/teardown requires root privileges\nThe cgroup isolation prevents the task from affecting other processes’ network traffic\nConsider adding ProtectSystem=, PrivateTmp=, and other hardening options to the service unit\n"},"notes/AI/Reputable-vendors-offering-free-LLM-API":{"slug":"notes/AI/Reputable-vendors-offering-free-LLM-API","filePath":"notes/AI/Reputable vendors offering free LLM API.md","title":"Reputable vendors offering free LLM API","links":[],"tags":[],"content":"Cerebras\nCerebras provides a generous free tier, but tokens per minute is slightly more limited than others.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelTokensRequestsMax Context Lengthqwen-3-235b-a22bminute: 64,000hour: 1,000,000day: 1,000,000minute: 30hour: 900day: 14,40040,000\nModelScope.AI\nModelScope offers 2,000 free API calls if you are in China mainland. github.com/QwenLM/qwen-code/commit/dc087deace4f30c21793ec6c78a400de7a24b2a2\n\n免费推理API由阿里云提供算力支持，要求您的ModelScope账号必须绑定阿里云账号后才能正常使用。\n每位魔搭注册用户，当前每天允许进行总数为2000次的API-Inference调用，平台后续可能随时调整此额度。\n\nGemini Code Assist\ndevelopers.google.com/gemini-code-assist/resources/quotas\nIndividual usage quota of requests from Gemini Code Assist agent mode and the Gemini CLI:\n\n60 requests per user per minute\n1000 requests per user per day\n\nGemini API\nai.google.dev/gemini-api/docs/rate-limits\nRate limits in 3 dimensions: RPM, TPM, RPD. See link above for details.\nRequests per day/minute: 100/5 for Gemini 2.5 Pro and 250/10 for Gemini 2.5 Flash\nOpenRouter\nopenrouter.ai/docs/api-reference/limits\nFree usage limits: If you’re using a free model variant (with an ID ending in :free), you can make up to 20 requests per minute. The following per-day limits apply:\n\nIf you have purchased less than 10 credits, you’re limited to 50 :free model requests per day.\nIf you purchase at least 10 credits, your daily limit is increased to 1000 :free model requests per day.\n"},"notes/AI/Running-MLX-models-on-Apple-Silicon-macOS":{"slug":"notes/AI/Running-MLX-models-on-Apple-Silicon-macOS","filePath":"notes/AI/Running MLX models on Apple Silicon macOS.md","title":"Running MLX models on Apple Silicon macOS","links":[],"tags":[],"content":"brew install pipx\npipx ensurepath # as needed\npipx install mlx-lm\npipx inject mlx-lm tiktoken # for Kimi-Linear\nFor API,\n# Download the model\nmlx_lm.server --model mlx-community/GLM-4.7-Flash-4bit --port &lt;port&gt; --max-tokens=128000\n \n# Run in offline mode after reviewing custom code for security\nHF_HUB_OFFLINE=1 mlx_lm.server --model mlx-community/GLM-4.7-Flash-4bit --port 6599 --max-tokens=128000 --trust-remote-code\nFor simple chat,\nmlx_lm.chat --model mlx-community/GLM-4.7-Flash-4bit\n \n# or with `llm` via the API server:\npipx install llm\n \ncat &gt; &quot;$(dirname &quot;$(llm logs path)&quot;)&quot;/extra-openai-models.yaml &lt;&lt;&#039;EOF&#039;\n- model_id: glm-4.7-flash\n  model_name: mlx-community/GLM-4.7-Flash-4bit\n  api_base: &quot;http://localhost:6599&quot;\nEOF\nllm models default glm-4.7-flash\nThe cache directory is .cache/huggingface for models downloaded from Hugging Face.\nReferences\n\ngithub.com/Aider-AI/aider/issues/4526\n"},"notes/Apple-Music":{"slug":"notes/Apple-Music","filePath":"notes/Apple Music.md","title":"Apple Music","links":[],"tags":[],"content":"List of loved songs\nExport “Apple Media Services information” from privacy.apple.com/ to get a list of loved songs in CSV format.\nAlternatively, create a Smart Playlist on your Mac, but it could only find songs in your library."},"notes/CICD/Production-container-deployments-without-Kubernetes":{"slug":"notes/CICD/Production-container-deployments-without-Kubernetes","filePath":"notes/CICD/Production container deployments without Kubernetes.md","title":"Production container deployments without Kubernetes","links":[],"tags":[],"content":"Kamal\ngithub.com/basecamp/kamal\nKamal offers zero-downtime deploys, rolling restarts, asset bridging, remote builds, accessory service management, and everything else you need to deploy and manage your web app in production with Docker. Originally built for Rails apps, Kamal will work with any type of web app that can be containerized.\nuncloud\ngithub.com/psviderski/uncloud\nTake your Docker Compose apps to production with zero-downtime deployments, automatic HTTPS, and cross-machine scaling. No Kubernetes required.\nNomad\ngithub.com/hashicorp/nomad\nNomad is a simple and flexible workload orchestrator to deploy and manage containers (docker, podman), non-containerized applications (executable, Java), and virtual machines (qemu) across on-prem and clouds at scale.\nNote: Business Source License, Change Date is Four years from the date the Licensed Work is published."},"notes/CLI/Bash/Best-way-to-add-path-to-PATH-environment-variable":{"slug":"notes/CLI/Bash/Best-way-to-add-path-to-PATH-environment-variable","filePath":"notes/CLI/Bash/Best way to add path to PATH environment variable.md","title":"Best way to add path to PATH environment variable","links":[],"tags":[],"content":"Solution\nif [[ ! &quot;$PATH&quot; == *your_path* ]]; then\n  PATH=&quot;${PATH:+${PATH}:}your_path&quot;\nfi\nAlternatively,\nif [ -z &quot;$YOUR_APP_HOME&quot; ]; then\n  export YOUR_APP_HOME=&quot;$HOME/.yourapp&quot;\n  export PATH=&quot;$YOUR_APP_HOME/bin:$PATH&quot;\nfi\nor more strictly,\nexport PNPM_HOME=&quot;$HOME/.local/share/pnpm&quot;\ncase &quot;:$PATH:&quot; in\n  *&quot;:$PNPM_HOME:&quot;*) ;;\n  *) export PATH=&quot;$PNPM_HOME:$PATH&quot; ;;\nesac\nExplanation\n[[ ! &quot;$PATH&quot; == *your_path* ]] checks if PATH contains your new path already, hence avoiding duplicates. This doesn’t work well for nested bin directories, but that rarely happens.\n${parameter:+word} uses word if parameter is null or unset. Therefore, if PATH is unset or empty, the new PATH contains only your_path and doesn’t contain a leading :.\nThe alternative solution uses a unique variable as a flag to indicate if its path has been added to PATH.\nReferences\n\nbash(1)\n"},"notes/CLI/Bash/Here-document":{"slug":"notes/CLI/Bash/Here-document","filePath":"notes/CLI/Bash/Here document.md","title":"Here document","links":[],"tags":[],"content":"Parameter expansion\nQuote the word in here-documents to inhibit any expansion.\n&lt;&lt;&#039;word&#039;\n\n\nIf any part of word is quoted, the delimiter is the result of quote removal on word, and the lines in the here-document are not expanded.\tIf word is unquoted, all lines of the here-document are subjected to parameter expansion, command substitution, and arithmetic expansion, the character sequence \\&lt;newline&gt; is ignored, and \\ must be used to quote the characters \\, $, and `.\n"},"notes/CLI/Bash/Line-editing":{"slug":"notes/CLI/Bash/Line-editing","filePath":"notes/CLI/Bash/Line editing.md","title":"Line editing","links":[],"tags":[],"content":"Read man 3 readline for more information."},"notes/CLI/Bash/Read-a-block-of-text-into-a-variable":{"slug":"notes/CLI/Bash/Read-a-block-of-text-into-a-variable","filePath":"notes/CLI/Bash/Read a block of text into a variable.md","title":"Read a block of text into a variable","links":[],"tags":[],"content":"read -r -d &#039;&#039; VAR1 &lt;&lt; EOV\nlorum\nipsum\nEOV\nTo prevent expansions, quote EOV into &#039;EOV&#039;."},"notes/CLI/Bash/Space-to-newline-for-literal-lists-in-Bash":{"slug":"notes/CLI/Bash/Space-to-newline-for-literal-lists-in-Bash","filePath":"notes/CLI/Bash/Space to newline for literal lists in Bash.md","title":"Space to newline for literal lists in Bash","links":[],"tags":[],"content":"printf &quot;%s\\n&quot; {1..10}\nIt works because in printf, the format is re-used as necessary to consume all of the arguments."},"notes/CLI/Check-if-input-is-pure-ASCII":{"slug":"notes/CLI/Check-if-input-is-pure-ASCII","filePath":"notes/CLI/Check if input is pure ASCII.md","title":"Check if input is pure ASCII","links":[],"tags":[],"content":"pbpaste | LC_ALL=C grep -q &#039;[^ -~]&#039; &amp;&amp; echo &quot;Non-ASCII&quot;\n \npbpaste | iconv -f ASCII -t ASCII &gt;/dev/null || echo &quot;Non-ASCII&quot;"},"notes/CLI/Convenient-CLI-tools":{"slug":"notes/CLI/Convenient-CLI-tools","filePath":"notes/CLI/Convenient CLI tools.md","title":"Convenient CLI tools","links":["notes/CLI/namei","notes/Software/Zellij"],"tags":[],"content":"\nnamei (directory permission on path)\ndoggo (DNS resolution)\nxhs, xh (HTTP/S request)\nPARI/GP (simple calculator)\n\nprintf(&quot;0x%X&quot;, %): print latest computed object in hexadecimal notation.\n\n\nnumbat (calculator with support for units) Try online!\n\nwarning: numbat persists command history in data_dir()/numbat/history.\n\n\nZellij (tmux)\neza, lsd (ls)\nfd, bfs (find)\nrg (grep)\npv (pipe viewer)\ndug (DNS propagation checker)\ncroc and ffsend (share files securely)\nage (simple file encryption tool)\nrestic (file backup tool)\nrclone (rsync for cloud)\nnamei (check parent directory permissions)\nncdu (TUI disk usage analyzer)\nlft (Layer Four Traceroute)\n"},"notes/CLI/GNU-Sed":{"slug":"notes/CLI/GNU-Sed","filePath":"notes/CLI/GNU Sed.md","title":"GNU Sed","links":[],"tags":[],"content":"Append line after match\n\\ (backslash followed by spaces) starts the appended line with all space characters that follows the \\. Without it, sed removes all spaces from the line appended.\nsed -i &#039;/files-2.1/a \\                      caches/modules-2/files-2.1/idea&#039; *.yml\nMatch pattern with lots of slashes\n\\|xxx/yyy|\n\nUse \\|...| structure as an alternative to /.../ to reduce escaping."},"notes/CLI/GraphicsMagick":{"slug":"notes/CLI/GraphicsMagick","filePath":"notes/CLI/GraphicsMagick.md","title":"GraphicsMagick","links":[],"tags":[],"content":"# Make thumbnail of an image\ngm convert -size 120x120 a.jpg -resize 120x120 +profile &quot;*&quot; thumbnail.jpg\n \n# Report image info\ngm identify -verbose a.jpg"},"notes/CLI/Neovim":{"slug":"notes/CLI/Neovim","filePath":"notes/CLI/Neovim.md","title":"Neovim","links":[],"tags":[],"content":"History\nNeovim uses shada files located in $HOME/.local/state/nvim/shada instead of .viminfo."},"notes/CLI/Per,-AWK-and-sed-tricks-for-text-file-manipulation":{"slug":"notes/CLI/Per,-AWK-and-sed-tricks-for-text-file-manipulation","filePath":"notes/CLI/Per, AWK and sed tricks for text file manipulation.md","title":"Per, AWK and sed tricks for text file manipulation","links":[],"tags":[],"content":"Selecting a paragraph with first line known\n/^first line content$/,/^$/ works in both AWK and sed for addressing a paragraph, or any content with unique start and end identifiers.\nsed -i -e &#039;/^Package: angie-module-wasmtime$/,/^$/d&#039; debian/control\nPerl paragraph mode\n-00 is a special value that cause Perl to slurp files in paragraph mode. This is very useful if you need to match text in the middle of a paragraph, which is more difficult for a line-oriented editor like sed.\nperl -i -00 -ne &#039;print unless /wasmtime/&#039; debian/rules\nIn AWK, you could use -v RS= to read inputs in paragraph, but you also need -v ORS=&#039;\\n\\n&#039; to set the output separator.\nNote that both Perl paragraph mode and AWK’s -v RS= rewrites the output separators, so if your file has more than three consecutive newlines, they are merged into an empty line, that is, two newlines."},"notes/CLI/StorCLI":{"slug":"notes/CLI/StorCLI","filePath":"notes/CLI/StorCLI.md","title":"StorCLI","links":[],"tags":[],"content":"# RAID controller information\n/opt/MegaRAID/storcli/storcli64 show ctrlcount # number of connected controllers\n/opt/MegaRAID/storcli/storcli64 show all # list controllers\n \n# For controller 0:\n/opt/MegaRAID/storcli/storcli64 /c0 show all # Overall info\n/opt/MegaRAID/storcli/storcli64 /c0/eall/sall show # PD (drive) list\n/opt/MegaRAID/storcli/storcli64 /c0/eall/sall show all # PD (drive) properties\n/opt/MegaRAID/storcli/storcli64 /c0/vall show all # VD properties\n/opt/MegaRAID/storcli/storcli64 /c0/pall show all # PHY info\n/opt/MegaRAID/storcli/storcli64 /c0/bbu show all # Battery info\n#/opt/MegaRAID/storcli/storcli64 /c0/cv show all # Cachevault (battery) info\n \n# Event commands\n/opt/MegaRAID/storcli/storcli64 /c0 show events type=latest=1000 # last 1000 events\n \n# Time commands\n/opt/MegaRAID/storcli/storcli64 /c0 show time\n/opt/MegaRAID/storcli/storcli64 /c0 set time=systemtime # set controller time\n \n# Misc.\n/opt/MegaRAID/storcli/storcli64 /c0 show cc # consistency check state\n \n# Redundant commands\n#/opt/MegaRAID/storcli/storcli64 /c0/eall show all # enclosure info\n#/opt/MegaRAID/storcli/storcli64 /c0/dall show all # topology of drive group\nReferences\n\nwww.broadcom.com/support/knowledgebase/1211161499760/lsi-command-line-interface-cross-reference-megacli-vs-twcli-vs-s\ndocs.broadcom.com/doc/12352476 (StorCLI Reference Manual)\n"},"notes/CLI/Vim":{"slug":"notes/CLI/Vim","filePath":"notes/CLI/Vim.md","title":"Vim","links":[],"tags":[],"content":"Text objects\n\nThe commands that start with “a” select “a”n object including white space, the commands starting with “i” select an “inner” object without white space, or just the white space. Thus the “inner” commands always select less text than the “a” commands.\n\n\nas: “a sentence”\nis: “inner sentence”\nap: “a paragraph”\nip: “inner paragraph”\n\nAlso w and W for words, t for HTML tags, and any pair of symbols: (&lt;{&quot;&#039;[.\nMacro tricks\nUse va{V to select the outer block line-wise.\nScrolling\nz., zt, zb move &quot;cursor line&quot; into respective position\nH, L, M move cursor to respective position\n\nMarks\nm followed by a letter sets a mark. a lowercase letter is local to the current buffer, but an uppercase letter can jump between files.\n&#039; or `  followed by a letter jumps to the respective mark.\nQuit with error\n:cq exits Vim with non-zero status, which could prevent git commit-like operations from finishing.\nRemoving auto-inserted comment leader\nAfter pressing Enter or ‘o’, use CTRL-U to remove the comment leader. See :help fo-table.\no       Automatically insert the current comment leader after hitting &#039;o&#039; or\n        &#039;O&#039; in Normal mode.  In case comment is unwanted in a specific place\n        use CTRL-U to quickly delete it. i_CTRL-U\n\nVisual-block edits\nTips: use gv to re-select the previous area in the same mode.\nWith a blockwise selection, A{string} appends the string to end of block on every line of the block, I{string} inserts the string at the start of block on every line of the block.\nTo paste lines of text to the end of a blockwise selection, first make a blockwise selection of the text to copy and yank it, then insert a placeholder character after the end of block on each line, select the placeholder row and press p or P. Both would delete the placeholder column (end of block) and insert text there.\nMy minimal vimrc\nsource $VIMRUNTIME/defaults.vim\n \nsyntax on\nif has(&#039;termguicolors&#039;)\n    set termguicolors\nendif\n \n&quot; indents\nfiletype plugin indent on\nset softtabstop=4\nset shiftwidth=4\nset shiftround\nset expandtab\nset autoindent\nset smartindent"},"notes/CLI/Zsh-word-splitting":{"slug":"notes/CLI/Zsh-word-splitting","filePath":"notes/CLI/Zsh word splitting.md","title":"Zsh word splitting","links":[],"tags":[],"content":"Use $=VAR instead of $VAR to force parameter expansions to split $VAR into separate words before substitution, using the IFS as a delimiter.\nThis is the default in most other shells."},"notes/CLI/Zsh":{"slug":"notes/CLI/Zsh","filePath":"notes/CLI/Zsh.md","title":"Zsh","links":[],"tags":[],"content":"New user setup\n\nYou should not edit anything between these lines if you intend to run zsh-newuser-install again.  You may, however, edit any other part of the file.\n\n# Lines configured by zsh-newuser-install\nHISTFILE=~/.histfile\nHISTSIZE=1000\nSAVEHIST=1000\nbindkey -e\n# End of lines configured by zsh-newuser-install\n# The following lines were added by compinstall\nzstyle :compinstall filename &#039;/mnt/home/l2dy/.zshrc&#039;\n \nautoload -Uz compinit\ncompinit\n# End of lines added by compinstall\nRun applications in background\nUse &amp;| to run job in background and remove it from the job table in one command.\nIn Fish and Bash, you have to use two commands. For example, firefox &amp;; disown, where disown removes the job from the job table."},"notes/CLI/apt":{"slug":"notes/CLI/apt","filePath":"notes/CLI/apt.md","title":"apt","links":[],"tags":[],"content":"Find reverse dependencies\napt-cache rdepends --installed --recurse &lt;package&gt;\nList packages by prefix\napt search --names-only &#039;^unit-&#039;\n\nPurge residual configuration files\napt purge &#039;~c&#039;\n\n~c is a shorthand for ?config-files, see apt-patterns(7) for more patterns."},"notes/CLI/benchstat":{"slug":"notes/CLI/benchstat","filePath":"notes/CLI/benchstat.md","title":"benchstat","links":[],"tags":[],"content":"Compare go test -bench=... results and print nice statistics.\npkg.go.dev/golang.org/x/perf@v0.0.0-20211012211434-03971e389cd3/cmd/benchstat\n$ benchstat old.txt new.txt\nname        old time/op  new time/op  delta\nGobEncode   13.6ms ± 1%  11.8ms ± 1%  -13.31% (p=0.016 n=4+5)\nJSONEncode  32.1ms ± 1%  31.8ms ± 1%     ~    (p=0.286 n=4+5)\n"},"notes/CLI/col":{"slug":"notes/CLI/col","filePath":"notes/CLI/col.md","title":"col","links":[],"tags":[],"content":"Convert tabs to spaces\nethtool -l eth0 | col -x converts tabs to spaces with proper indentation."},"notes/CLI/conntrack":{"slug":"notes/CLI/conntrack","filePath":"notes/CLI/conntrack.md","title":"conntrack","links":[],"tags":[],"content":"List all tracked connections with TCP destination port 8080.\nconntrack -L -p TCP --orig-port-dst 8080"},"notes/CLI/curl":{"slug":"notes/CLI/curl","filePath":"notes/CLI/curl.md","title":"curl","links":[],"tags":[],"content":"—connect-to\nSyntax: --connect-to &lt;HOST1:PORT1:HOST2:PORT2&gt;\n\n“HOST1” and “PORT1” may be empty, to match any host/port.\n“HOST2” and “PORT2” may also be empty, to use the request’s original host/port.\nAdded in curl 7.49.0.\nExample: curl --connect-to ::&lt;IP&gt; &lt;URL&gt;\n\nCompared to --resolve, it can adapt to the request’s original port.\nwcurl\nwcurl - a simple wrapper around curl to easily download files on Debian 13:\nBy default, wcurl will:\n\nPercent-encode whitespaces in URLs;\nDownload multiple URLs in parallel if the installed curl’s version is &gt;= 7.66.0;\nFollow redirects;\nAutomatically choose a filename as output;\nAvoid overwriting files if the installed curl’s version is &gt;= 7.83.0 (—no-clobber);\nPerform retries;\nSet the downloaded file timestamp to the value provided by the server, if available;\nDisable curl’s URL globbing parser so {} and [] characters in URLs are not treated specially;\nPercent-decode the resulting filename;\nUse “index.html” as default filename if there’s none in the URL.\n"},"notes/CLI/dig":{"slug":"notes/CLI/dig","filePath":"notes/CLI/dig.md","title":"dig","links":[],"tags":[],"content":".digrc\n+noall +answer\n"},"notes/CLI/du":{"slug":"notes/CLI/du","filePath":"notes/CLI/du.md","title":"du","links":[],"tags":[],"content":"Linux-specific flags\nList top 10 directories with most files (inodes) in the root filesystem.\ndu --inodes -xS / | sort -nr | head\n \n# Less efficient version:\nfind / -xdev -printf &#039;%h\\n&#039; | sort | uniq -c | sort -k1 -n"},"notes/CLI/ffmpeg":{"slug":"notes/CLI/ffmpeg","filePath":"notes/CLI/ffmpeg.md","title":"ffmpeg","links":[],"tags":[],"content":"One-liners\nDetect encoding errors\nffmpeg -err_detect explode -i &lt;infile&gt; -f null -\nConvert music file to Opus format\nfind . -type f -name &#039;*.flac&#039; | parallel &#039;test -f {.}.opus || ffmpeg -i {} -vn -c:a libopus -b:a 192k {.}.opus&#039;\nKeep display aspect ratio when downsampling\nffmpeg -i in.mp4 -vf &quot;setsar=&#039;if(sar,sar,1)&#039;,scale=640x480&quot; out.mp4"},"notes/CLI/fio":{"slug":"notes/CLI/fio","filePath":"notes/CLI/fio.md","title":"fio","links":[],"tags":[],"content":"Automated test scripts\nYABS\ngithub.com/masonr/yet-another-bench-script\nOn x64 hosts, --numjobs=2 --size=2G.\ncurl -LO raw.githubusercontent.com/l2dy/yet-another-bench-script/0958b7fcf382a2e3ddfb23a26df3cb05067f1367/yabs.sh\nchmod +x yabs.sh\n \nsudo apt install fio iperf3\n./yabs.sh -g\nfio\nBasic examples\n[random-writers]\nsize=64m\n# 1 job per available CPU thread\nnumjobs=4\nThe result is 4 processes each randomly writing to their own 64MiB file.\nPostgreSQL performance test\n[read-write]\nrw=rw\nrwmixread=75\n# 18g for more space or less CPU thread\nsize=13g\ndirectory=/home\nfadvise_hint=0\nblocksize=8k\ndirect=0\n# 1 job per available CPU thread\nnumjobs=112\nnrfiles=1\nruntime=1h\ntime_based\nexec_prerun=echo 3 &gt; /proc/sys/vm/drop_caches\nIOPS performance test\n# Test disk random read\nsudo fio --filename=&lt;device name&gt; --direct=1 --rw=randread --bs=4k --ioengine=libaio --iodepth=256 --runtime=120 --numjobs=4 --time_based --group_reporting --name=iops-test-job --eta-newline=1 --readonly\n \n# Test file random read/writes, 2T\nsudo fio --filename=/&lt;custom mount point&gt;/file --size=500GB --direct=1 --rw=randrw --bs=4k --ioengine=libaio --iodepth=256 --runtime=120 --numjobs=4 --time_based --group_reporting --name=iops-test-job --eta-newline=1\n \n# Test disk random read/writes (dangerous)\nsudo fio --filename=&lt;device name&gt; --direct=1 --rw=randrw --bs=4k --ioengine=libaio --iodepth=256 --runtime=120 --numjobs=4 --time_based --group_reporting --name=iops-test-job --eta-newline=1\nTo see the final report per-group instead of per-job, use --group_reporting.\nReferences\n\ndocs.oracle.com/en-us/iaas/Content/Block/References/samplefiocommandslinux.htm\n"},"notes/CLI/git/Git-partial-clone":{"slug":"notes/CLI/git/Git-partial-clone","filePath":"notes/CLI/git/Git partial clone.md","title":"Git partial clone","links":[],"tags":[],"content":"Blobless clone\ngit clone --filter=blob:none &lt;url&gt; creates a blobless clone. These clones download all reachable commits and trees while fetching blobs on-demand. These clones are best for developers and build environments that span multiple builds.\nGit downloads blobs on demand when you do a git checkout. This includes the first checkout inside the git clone operation.\nblobless clones can perform commands like git merge-base, git log, or even git log -- &lt;path&gt; with the same performance as a full clone.\nCommands like git diff or git blame &lt;path&gt; require the contents of the paths to compute diffs, so these commands trigger blob downloads. However, the good news is that after the first run you have those blobs in your local repository and don’t need to download them again. Most developers only need to run git blame on a small number of files, so this tradeoff of a slightly slower git blame command is worth the faster clone and fetch times.\nOn the other hand, git log -p without a path constraint is risky and could fetch all the blobs in history.\nReferences\n\ngithub.blog/2020-12-21-get-up-to-speed-with-partial-clone-and-shallow-clone/\n"},"notes/CLI/git/Pronouns-in-Git-commit-message-body":{"slug":"notes/CLI/git/Pronouns-in-Git-commit-message-body","filePath":"notes/CLI/git/Pronouns in Git commit message body.md","title":"Pronouns in Git commit message body","links":[],"tags":[],"content":"Linux kernel\nAn incomplete summary:\nMost used pronouns in commit messages:\n----------------------------------------\nit              714326 occurrences\nwe              460429 occurrences\ni               163312 occurrences\nthem            73525 occurrences\nits             73103 occurrences\nthey            65146 occurrences\nus              50573 occurrences\ntheir           31527 occurrences\nour             19763 occurrences\nyou             18214 occurrences\nitself          16434 occurrences\nme              15390 occurrences\nmy              14199 occurrences\nhe               7317 occurrences\nyour             2835 occurrences\nhis              2682 occurrences\nthemselves       2348 occurrences\nmyself           2270 occurrences\nourselves        1071 occurrences\nhim               596 occurrences\nmine              231 occurrences\nours              126 occurrences\nshe               109 occurrences\nher                94 occurrences\nyourself           84 occurrences\nhimself            70 occurrences\nyours              55 occurrences\ntheirs             37 occurrences\nherself            13 occurrences\n----------------------------------------\nTotal pronouns: 1735879\n\nNote that us may contain mistakenly counted use of US.\nSearch for a particular pronoun:\ngit log --grep &#039;\\bwe\\b&#039;"},"notes/CLI/git/Show-staged-file-content-in-Git":{"slug":"notes/CLI/git/Show-staged-file-content-in-Git","filePath":"notes/CLI/git/Show staged file content in Git.md","title":"Show staged file content in Git","links":[],"tags":[],"content":"git show :&lt;path/to/file&gt;"},"notes/CLI/git/git-filter-repo":{"slug":"notes/CLI/git/git-filter-repo","filePath":"notes/CLI/git/git-filter-repo.md","title":"git-filter-repo","links":[],"tags":[],"content":"Remove matching files from a branch\ngit filter-repo --refs &lt;branch&gt; --invert-paths --path-glob &#039;*.res.js&#039;"},"notes/CLI/git/git-status":{"slug":"notes/CLI/git/git-status","filePath":"notes/CLI/git/git-status.md","title":"git-status","links":[],"tags":[],"content":"git status taking too long\nMay affect interactivity of custom shell prompts like Starship that check git status.\nTo reduce prompt latency, turn off scanning of untracked files in big repositories.\ngit config status.showUntrackedFiles no\ngit status during a interactive rebase\n“Last commands done” is tail -n 2 of .git/rebase-merge-done, which is an append-only file during a rebase.\nIn case of a merge conflict, the last line of the “done” file is the commit applied that caused the conflict."},"notes/CLI/gpg":{"slug":"notes/CLI/gpg","filePath":"notes/CLI/gpg.md","title":"gpg","links":[],"tags":[],"content":"Consider using sq instead. crates.io/crates/sequoia-sq"},"notes/CLI/grep":{"slug":"notes/CLI/grep","filePath":"notes/CLI/grep.md","title":"grep","links":[],"tags":[],"content":"You can specify multiple patterns via -e. This is very helpful when you need to grep command output for something and preserve the header.\nps aux | grep -e TLS -e crypto\n"},"notes/CLI/ip":{"slug":"notes/CLI/ip","filePath":"notes/CLI/ip.md","title":"ip","links":[],"tags":[],"content":"Global options\n-s for more verbose output (s for statistics). -s -s increases verbosity. Add -h for human readable stats and add -iec to print data size in IEC units (e.g. 1Ki = 1024).\nNote: don’t stack options. For example, ip complains if you attempt to use -hs:\nOption &quot;-hs&quot; is unknown, try &quot;ip -help&quot;.\n"},"notes/CLI/iptraf":{"slug":"notes/CLI/iptraf","filePath":"notes/CLI/iptraf.md","title":"iptraf","links":[],"tags":[],"content":"github.com/iptraf-ng/iptraf-ng\niptraf -s &lt;interface&gt; # monitor TCP and UDP traffic on the specified interface, group by port"},"notes/CLI/journalctl":{"slug":"notes/CLI/journalctl","filePath":"notes/CLI/journalctl.md","title":"journalctl","links":[],"tags":[],"content":"Useful options\n-b (show logs from the current boot only)\n-e (jump to end in pager mode)\n-x (augment log lines with catalog info, don&#039;t use for bug reports)\n\nReset and clear all logs\njournalctl --rotate\nsleep 1\njournalctl --vacuum-time=1s\n"},"notes/CLI/less":{"slug":"notes/CLI/less","filePath":"notes/CLI/less.md","title":"less","links":[],"tags":[],"content":"Keys\n\nu / d: move backward/forward one half-window.\nb / f: move backward/forward one window.\nESC u: toggle search highlighting.\nn / N: repeat last search in normal/reverse direction. Add ESC prefix to search spanning files.\n:n / :p: examine the next/previous file.\n:e [file]: examine a new file.\n\nDon’t clear the screen on exit\n       -X or --no-init\n\t      Disables sending the termcap initialization and deinitialization\n\t      strings to the terminal.\tThis is  sometimes  desirable  if  the\n\t      deinitialization\tstring does something unnecessary, like clear-\n\t      ing the screen.\n\nUsually used with -F for direct output in one screen, and -R to show colors.\n       -F or --quit-if-one-screen\n\t      Causes less to automatically exit if the entire file can be\n\t      displayed on the first screen.\n"},"notes/CLI/lsof":{"slug":"notes/CLI/lsof","filePath":"notes/CLI/lsof.md","title":"lsof","links":["notes/CLI/procstat"],"tags":[],"content":"List open files and sockets. On FreeBSD, use procstat instead.\nList deleted files\n# For all filesystems\nlsof +L1\n# For the filesystem at mountpoint /home\nlsof +aL1 /home\nList network connections of a process by PID\nlsof -nPi -a -p &lt;PID&gt;"},"notes/CLI/mise":{"slug":"notes/CLI/mise","filePath":"notes/CLI/mise.md","title":"mise","links":[],"tags":[],"content":"echo &#039;eval &quot;$(mise activate bash)&quot;&#039; &gt;&gt; ~/.bashrc\n\nmise use -g node@24\nmise use -g pnpm\npnpm -v\n"},"notes/CLI/namei":{"slug":"notes/CLI/namei","filePath":"notes/CLI/namei.md","title":"namei","links":[],"tags":[],"content":"namei -l &lt;path&gt; displays Unix permissions of each path segment and prints their modes and owners. This is very useful when troubleshooting file permission issues."},"notes/CLI/nc":{"slug":"notes/CLI/nc","filePath":"notes/CLI/nc.md","title":"nc","links":[],"tags":[],"content":"OpenBSD nc\nTerminate on EOF\nTerminate the TCP connection 60 seconds after receiving an EOF on stdin.\nnc &lt;IP&gt; &lt;port&gt; -q 60\n"},"notes/CLI/nstat":{"slug":"notes/CLI/nstat","filePath":"notes/CLI/nstat.md","title":"nstat","links":[],"tags":[],"content":"nstat is part of the iproute2 collection, replacing the old netstat --statistics command."},"notes/CLI/numactl":{"slug":"notes/CLI/numactl","filePath":"notes/CLI/numactl.md","title":"numactl","links":[],"tags":[],"content":"numactl --hardware\n \nnumastat -m\nUnits\n#define KILOBYTE (1024)\n#define MEGABYTE (1024 * 1024)\nReferences\n\ngithub.com/numactl/numactl/blob/63e02235bdbcf5aa334903be2111a82b27c8c155/numastat.c#L48\n"},"notes/CLI/procstat":{"slug":"notes/CLI/procstat","filePath":"notes/CLI/procstat.md","title":"procstat","links":["maps/FreeBSD-Map"],"tags":[],"content":"On FreeBSD Map, use procstat -f &lt;PID&gt; to list open files and sockets."},"notes/CLI/ps":{"slug":"notes/CLI/ps","filePath":"notes/CLI/ps.md","title":"ps","links":[],"tags":[],"content":"List processes by user\nShow every process running as root in user format:\nps -U root -u root u\n\n-U is for real ID and -u is for effective ID.\nTo show numeric id in the USER column, add n.\nList processes by PIDs\nShow PID 1 and 2 processes in virtual memory format:\nps -q 1,2 v\n\nProcess tree on FreeBSD\n-d arranges processes into a tree representing parent and child relationships.\nps aux -d"},"notes/CLI/rsync":{"slug":"notes/CLI/rsync","filePath":"notes/CLI/rsync.md","title":"rsync","links":[],"tags":[],"content":"Only copy certain types of files\n(dry-run)\nrsync -rvn --include=&quot;*/&quot; --include=&quot;*.wav&quot; --exclude=&quot;*&quot; from/ to/\n"},"notes/CLI/sgdisk":{"slug":"notes/CLI/sgdisk","filePath":"notes/CLI/sgdisk.md","title":"sgdisk","links":[],"tags":[],"content":"# print partition summary\nsgdisk -p /dev/nvme0n1\n# print 4th partition info\nsgdisk -i4 /dev/nvme0n1"},"notes/CLI/smartctl":{"slug":"notes/CLI/smartctl","filePath":"notes/CLI/smartctl.md","title":"smartctl","links":[],"tags":[],"content":"For NVMe, -a is equivalent to -H -i -c -A -l error. The expanded full command is\nsmartctl --health --info --capabilities --attributes --log=error"},"notes/CLI/snmpwalk":{"slug":"notes/CLI/snmpwalk","filePath":"notes/CLI/snmpwalk.md","title":"snmpwalk","links":[],"tags":[],"content":"Perl\nperl -pi.bak -e &#039;$from=&#039;\\&#039;&#039;fixed string&#039;\\&#039;&#039;; $to=&#039;\\&#039;&#039;replacement string&#039;\\&#039;&#039;; s/\\Q$from\\E/$to/g&#039; &lt;file&gt;\n \n# or\n \nperl -s -pi.bak -e &#039;s/\\Q$from\\E/$to/g&#039; -- -from=&#039;fixed string&#039; -to=&#039;replacement string&#039; files/mini_snmpd.init\nperldoc perlrun says that with -s, Perl does rudimentary switch parsing for switches before an argument of -- or any filename arguments like files/mini_snmpd.init. But in practice, you have to add -- before the from and to arguments in this example."},"notes/CLI/ss":{"slug":"notes/CLI/ss","filePath":"notes/CLI/ss.md","title":"ss","links":[],"tags":[],"content":"ss -ntl sport :443 # list sockets lisenting on port 443\nss -ntl src :443 # same as above and can additionally filter by IP address\n\nss -tunap # list all TCP and UDP sockets, including both listening and non-listening sockets, and show the associated processes\n\nFor ss -tiepm output,\n\n\napp_limited, rwnd_limited or sndbuf_limited could indicated if the connection bandwidth is limited by the send buffer or not.\n\n\nSend-Q is READ_ONCE(tp-&gt;write_seq) - tp-&gt;snd_una, which means \\text{Tail(+1) of data held in tcp send buffer} - \\text{First byte we want an ack for}.\n\n\nnotsent is bytes not yet sent to the peer, which is part of Send-Q. It is calculated from max_t(int, 0, tp-&gt;write_seq - tp-&gt;snd_nxt), which means \\text{Tail(+1) of data held in tcp send buffer} - \\text{Next sequence we send}.\n\n\nThe difference between Send-Q and notsent is snd_nxt - snd_una, representing all sent and yet unacknowledged data.\n\n\nskmem:(t&lt;wmem_alloc&gt;) includes qdisc queues and NIC tx queue. Why is it often 0 during active transmission?\n\n\nskmem:(w&lt;wmem_queued&gt;) is total memory allocated for unsent or unacknowleged packets. It is incremented in tcp_sendmsg_locked() and decremented in either tcp_trim_head() or tcp_wmem_free_skb().\n\n\nskmem:(tb&lt;snd_buf&gt;) is the total send buffer size, including unused bytes.\n\n\nrtt:&lt;rtt&gt;/&lt;rttvar&gt; and bbr:(&lt;bw&gt;,&lt;mrtt&gt;) could be used to estimate your BDP.\n\n\nsnd_wnd is peer’s advertised receive window after scaling (bytes).\n\n\nrcv_wnd is local advertised receive window after scaling (bytes), supported since iproute2-6.6.0 with linux-6.2 kernel.\n\n\ncwnd is congestion window in MSS units. You need to multiply it by mss before comparing it with snd_wnd.\n\n\nWith an iperf3 test, you could use the following Bash script to trace the statistics in ~ 1 second interval. You should replace dst with src where appropriate:\nfor i in {0..1000}; do ss -ntim dst :5201 | grep -B1 --color=always _limited; sleep 1; done"},"notes/CLI/ssh":{"slug":"notes/CLI/ssh","filePath":"notes/CLI/ssh.md","title":"ssh","links":[],"tags":[],"content":"Session persistence\nAdd the following Control* parameters to your OpenSSH client configuration file:\nHost devbox\n\tHostname x.x.x.x\n\t[...]\n\tServerAliveInterval 3600\n\tControlPersist 1h\n\tControlMaster auto\n\tControlPath ~/.ssh/control/%C\n\nand create the directory for control sockets with secured permissions:\nmkdir -m 0700 ~/.ssh/control\nNote: %C is used to avoid path too long for Unix domain socket errors and is a hash of %l%h%p%r%j."},"notes/CLI/starship":{"slug":"notes/CLI/starship","filePath":"notes/CLI/starship.md","title":"starship","links":[],"tags":[],"content":"Configuration\nSet format to skip slow modules, instead of disabling them individually. For example, I’m using\n# ~/.config/starship.toml\nformat = &#039;$username$hostname$directory$git_branch$git_commit$git_state$git_metrics$git_status$hg_branch$character&#039;"},"notes/CLI/systemd-analyze":{"slug":"notes/CLI/systemd-analyze","filePath":"notes/CLI/systemd-analyze.md","title":"systemd-analyze","links":[],"tags":[],"content":"Subcommands\n\ntime: analyze startup time\nset-log-level: set systemd log level\n"},"notes/CLI/tcpdump":{"slug":"notes/CLI/tcpdump","filePath":"notes/CLI/tcpdump.md","title":"tcpdump","links":[],"tags":[],"content":"On macOS 15.7, you may use\ntcpdump -i &lt;device&gt; -s 64 -w &lt;filename&gt; host &lt;server IP&gt; and tcp port &lt;port&gt;\nto capture all TCP header information including the handshake packets in full. The default -s snaplen of 262144 bytes is too expensive for capturing TCP connections transferring a large amount of data."},"notes/CLI/top":{"slug":"notes/CLI/top","filePath":"notes/CLI/top.md","title":"top","links":[],"tags":[],"content":"Keys\n\ne / E, :Enforce-Task-Memory-Scale and :Enforce-Summary-Memory-Scale. Cycle through the available memory scaling which ranges from KiB through EiB.\nf, :Fields-Management. Display a separate screen to change which fields to display, ordering and the sort field.\no, :Other-Filtering. With COMMAND=gcc you can filter for gcc processes.\nc, :Command-Line/Program-Name. Switch between command lines and program names display.\n\nCommand-line options\n\n-u &lt;user&gt;, :User-filter-mode. Display only processes with a user id or user name matching that given.\n\nAlternatives\nYou may want to also use systemd-cgtop to observe containers."},"notes/CLI/virt-copy-out":{"slug":"notes/CLI/virt-copy-out","filePath":"notes/CLI/virt-copy-out.md","title":"virt-copy-out","links":[],"tags":[],"content":"virt-copy-out is a simple shell script wrapper around guestfish copy-out to copy files and directories out of a virtual machine disk image. guestfish(3) supports (including but not limited to) ext2/3/4, XFS and BTRFS filesystems on raw or qcow2 VM disk images."},"notes/CLI/vmstat":{"slug":"notes/CLI/vmstat","filePath":"notes/CLI/vmstat.md","title":"vmstat","links":[],"tags":[],"content":"r: The number of runnable processes (running or waiting for run time).\nb: The number of processes blocked waiting for I/O to complete.\n\nTo view number of processes waiting in run queue only, use runqlen from BCC or bpftrace."},"notes/Cloud/AWS/AWS-Nitro-System":{"slug":"notes/Cloud/AWS/AWS-Nitro-System","filePath":"notes/Cloud/AWS/AWS Nitro System.md","title":"AWS Nitro System","links":[],"tags":[],"content":"Nitro Controller\nPacket encapsulation\nNitro cards handle packet encapsulation and decapsulation on VM hosts.\nOn receipt of an encapsulated packet, Nitro checks if the source is valid for the encapsulated VPC packet. If not, Nitro drops the packet and triggers an alarm internally in AWS.\nARP interception\nNitro cards intercept ARP requests, and handle destinations within and outside of the subnet differently.\n\nFor EC2 instances communicating in the same subnet, ARP requests from one VM will get the MAC address of the other VM’s ENI.\nFor EC2 instances sending packets to the gateway (across subnets), ARP returns a “fake” address for the gateway. During decapsulation, packets from a different subnet has its source and destination MAC addresses rewritten to “fake” addresses of the respective gateways.\n"},"notes/Cloud/AWS/AWS-VPC":{"slug":"notes/Cloud/AWS/AWS-VPC","filePath":"notes/Cloud/AWS/AWS VPC.md","title":"AWS VPC","links":["notes/Cloud/AWS/AWS-Nitro-System","notes/Cloud/Google-Cloud/Andromeda"],"tags":[],"content":"Addressing and routing\nPhysical addresses are separate from VPC addresses, to enable independent scaling of the virtual network and the physical network.\nA proprietary encapsulation format is used to carry VPC information to the destination. It includes 3 layers of headers: IP packet from the payload, VPC encapsulation, and IP on physical network. On VM hosts, encapsulation is handed by the AWS Nitro System.\nMulticast and broadcast routing are not supported in a regular VPC.\nMapping service\nThe mapping service is a distributed web service that handles mappings between (VPC ID, IP address) and physical destinations like target physical host IP.\nThere are two kinds of mappings, /32 host mappings and routes (CIDR mappings) for Blackfoot edge devices.\nMappings are cached, pushed out and pre-loaded to memory, and proactively invalidated when they change.\nMappings from the mapping service are 100% cached on the physical host, and the cache miss path isn’t implemented, that is, drop all cache misses, to ensure predictable performance (especially latency) and mitigate a bunch of availability concerns for the mapping service. This is the Preprogrammed Model described in Andromeda’s paper.\nFor EC2 instances communicating within the same subnet, the fake ARP response from VM hosts will return the actual but virtual MAC address of the other instance. Other packets are sent to the subnet gateway, for which a fake MAC address is assigned and VM host parses the IP header to find the destination for those packets.\nOn receipt of an encapsulated packet, VM hosts check if the source is valid, and an alert is triggered if invalid packets are found, which could be caused by a program error or an attack.\nFlow tracking\nNot all flows are tracked on VM hosts. See docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-group-connection-tracking.html.\nEdge gateway\nBlackfoot Edge devices handles VPC ingress and egress, including Internet traffic, Direct Connect, VPN and S3 &amp; DynamoDB Endpoints. It’s horizontally scaled, redundant, high available and stateless.\nBlackfoot encapsulates ingress traffic for VPC and decapsulates egress traffic. it also operates NAT in a stateless manner, mapping private and public IPs (EIPs) one-to-one.\nVPC services\nAWS exposes a set of supporting services within customer VPCs at well-known or reserved addresses. These services are traditionally exposed from the IPv4 link-local address range (169.254.0.0/16). For AWS Nitro System instances, AWS also provides these services using IPv6 ULAs.\nServices include\n\nInstance Metadata Service (IMDS)\nRoute 53 DNS resolver\nNetwork Time Protocol server\n\nVPC quotas\nEach VPC can have up to 256,000 NAU units (think of it as IP addresses in use), and the maximum number of NAU units for a VPC and all of its intra-Region peered VPCs is up to 512,000.\nPreviously, only around 50k NAU units are supported. It was likely because of the Preprogrammed Model in local mapping service cache.\nNaming preference\nCredits: www.trendmicro.com/cloudoneconformity/knowledge-base/aws/VPC/vpc-naming-conventions.html\nDefault Pattern Examples\nvpc-us-east-1-p-web-app-stack\nvpc-us-west-2-p-big-data-app-stack\nDefault Pattern Format\nvpc-RegionCode-EnvironmentCode-ApplicationStackCode\nDefault Pattern Components\nRegionCode\n(ue1|uw1|uw2|ew1|ec1|an1|an2|as1|as2|se1) for us-east-1, us-west-1, us-west-2, eu-west-1, eu-central-1, ap-northeast-1, ap-northeast-2, ap-southeast-1, ap-southeast-2, sa-east-1.\nEnvironmentCode\n(d|t|s|p) for development, test, staging, production.\nApplicationCode\n([a-z0-9\\-]+) for the application stack that runs within the VPC network.\nReferences\n\nwww.youtube.com/watch\nwww.youtube.com/watch\ncodezine.jp/article/detail/9790\ndocs.aws.amazon.com/whitepapers/latest/ipv6-on-aws/supporting-amazon-vpc-services.html\ndocs.aws.amazon.com/vpc/latest/userguide/amazon-vpc-limits.html\n"},"notes/Cloud/AWS/AWS-backbone-network":{"slug":"notes/Cloud/AWS/AWS-backbone-network","filePath":"notes/Cloud/AWS/AWS backbone network.md","title":"AWS backbone network","links":[],"tags":[],"content":"Regions\nEach Region provides AWS services independently.\nAvailability Zones\nAZs are less than 2 ms apart and highly connected with redundant paths inter-AZ and to transit centers.\n\nTransit Center\nTransit centers handle connections to other AWS Regions, Direct Connect private links, and Internet through peering and paid transit.\nReferences\n\nwww.youtube.com/watch\n"},"notes/Cloud/AWS/AWS-documentation-excerpts":{"slug":"notes/Cloud/AWS/AWS-documentation-excerpts","filePath":"notes/Cloud/AWS/AWS documentation excerpts.md","title":"AWS documentation excerpts","links":[],"tags":[],"content":"Aurora MySQL\nJDBC drivers\nAmazon Web Services (AWS) JDBC Driver for MySQL\ngithub.com/awslabs/aws-mysql-jdbc\n\nThe AWS JDBC Driver for MySQL supports fast failover for Amazon Aurora with MySQL compatibility.\n\nCaveats and gotchas\nrepost.aws/knowledge-center/aurora-mysql-db-cluser-read-only-error\nSmart driver\nSeptember 2023 update: Version 3.0.3 of the MariaDB JDBC Driver (Connector/J) no longer supports Amazon Aurora. We recommend using the AWS Advanced JDBC Wrapper Driver\nThe Amazon Aurora DB cluster endpoints propagate DNS record updates automatically, but the process doesn’t happen instantly. This can cause delays in responding to an event that occurred on the database and the event might be handled by the application. A Smart Driver uses the DB cluster topography through the INFORMATION_SCHEMA.REPLICA_HOST_STATUS metadata table, which is in near-real-time. This helps to route connections to the appropriate role, and helps load-balance across the existing replicas. MariaDB Connector/J is an example of a third party Smart Driver that has native support for Aurora MySQL.\nNote: even Smart Drivers might be affected by excessive DNS caching.\nDNS caching\nIf you are not using a smart driver, then you depend on the DNS record updates and propagation after a failover event occurs. Aurora DNS zones use a short time-to-live (TTL) of 5 seconds, so it is important that your network and client configurations don’t further increase this. DNS caching can occur at multiple layers of an architecture, such as the operating system (OS), the network layer and the application container. It is important that you understand how each of these layers is configured. If there is unintended DNS caching beyond the TTL of 5 seconds, it is possible that you will re-connect to the old writer after a failover.\nJava Virtual Machines (JVM) can excessively cache DNS, indefinitely. When the JVM resolves a hostname to an IP address, it caches the IP address for a specified period of time (TTL). On some configurations, the JVM default TTL is set to never refresh DNS entries until the JVM is restarted. This can lead to read-only errors after a failover. In this case, it is important to manually set a small TTL so that it will periodically refresh.\nInterface Endpoint\nPrivate DNS for interface endpoints\nIf the private DNS option is enabled, an interface endpoint is created with a hidden private hosted zone attached to the associated VPC. Records in this hosted zone point the default service domain to ENIs of the interface endpoint, which have private IPs that isolated subnets can connect to.\nDetaching a private hosted zone can take a few minutes, so it is not possible to recreate a deleted AWS service interface endpoint immediately.\nprivate-dns-enabled cannot be set because there is already a conflicting DNS domain for ssm.&lt;region&gt;.amazonaws.com in the VPC\n\nCloud9\nAWS managed temporary credentials\nSome Cloud9, IAM and STS actions are restricted. See Actions supported by AWS managed temporary credentials.\n\n\nCurrently, if your environment’s EC2 instance is launched into a private subnet, you can’t use AWS managed temporary credentials to allow the EC2 environment to access an AWS service on behalf of an AWS entity (an IAM user, for example).\n\ndocs.aws.amazon.com/cloud9/latest/user-guide/security-iam.html#auth-and-access-control-temporary-managed-credentials\nGraviton processor\nAWS Graviton Technical Guide\nProcessor specifications\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProcessorGraviton2Graviton3(E)InstancesM6g/M6gd, C6g/C6gd/C6gn, R6g/R6gd, T4g, X2gd, G5g, and I4g/Im4gn/Is4genC7g/C7gd/C7gn, M7g/M7gd, R7g/R7gd, and HPC7gCoreNeoverse-N1Neoverse-V1Frequency2500MHz2600MHzTurbo supportedNoNoInstruction latenciesInstruction LatenciesInstruction LatenciesInterconnectCMN-600CMN-650Architecture revisionARMv8.2-aARMv8.4-aAdditional  featuresfp16, rcpc, dotprod, cryptosve, rng, bf16, int8, cryptoRecommended -mcpu flagneoverse-n1neoverse-512tvbRNG InstructionsNoYesSIMD instructions2x Neon 128bit vectors4x Neon 128bit vectors / 2x SVE 256bitLSE (atomic mem operations)yesyesPointer AuthenticationnoyesCores6464L1 cache (per core)64KB inst / 64KB data64KB inst / 64KB dataL2 cache (per core)1MB1MBLLC (shared)32MB32MBDRAM8x DDR48x DDR5DDR Encryptionyesyes\nC/C++ on Graviton\nSource\nOptimal processor features\nOn arm64 -mcpu= acts as both specifying the appropriate\narchitecture and tuning and it’s generally better to use that vs -march if\nyou’re building for a specific CPU.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCPUFlagGCC versionLLVM verisonGraviton2-mcpu=neoverse-n1*GCC-9^Clang/LLVM 10+Graviton3(E)-mcpu=neoverse-512tvb%GCC 11+Clang/LLVM 14+\n^ Also present in Amazon Linux2 GCC-7\n* Requires GCC-9 or later; otherwise we suggest using -mcpu=cortex-a72\n% If your compiler doesn’t support neoverse-512tvb, please use the Graviton2 tuning.\nUsing SVE\nThe scalable vector extensions (SVE) require both a new enough tool-chain to\nauto-vectorize to SVE (GCC 11+, LLVM 14+) and a 4.15+ kernel that supports SVE.\nOne notable exception is that Amazon Linux 2 with a 4.14 kernel doesn’t support SVE;\nplease upgrade to a 5.4+ AL2 kernel.\nIAM\nPolicy limits\naws.amazon.com/premiumsupport/knowledge-center/iam-increase-policy-size/\nManaged policy limit\nYou can assign IAM users to up to 10 groups. You can also attach up to 10 managed policies to each group, for a maximum of 120 policies (20 managed policies attached to the IAM user, 10 IAM groups, with 10 policies each).\nInline policy character quota\nYou can add as many inline policies as you want to an IAM user, role, or group. But the total aggregate policy size (the sum size of all inline policies) per entity cannot exceed the following quotas:\n\nUser policy size cannot exceed 2,048 characters.\nRole policy size cannot exceed 10,240 characters.\nGroup policy size cannot exceed 5,120 characters.\n"},"notes/Cloud/AWS/AWS-pitfalls":{"slug":"notes/Cloud/AWS/AWS-pitfalls","filePath":"notes/Cloud/AWS/AWS pitfalls.md","title":"AWS pitfalls","links":["notes/Network/DNS-caching"],"tags":[],"content":"Security\nIAM\nNumber of policies attached to an IAM role or user and the size of each policy is limited. With workarounds, at most 120 managed policies and a set of inline policies can be added.\nCloudTrail\n\nCertain types of CloudTrail events aren’t associated with related resources. In this case, filter by event names to reduce number of events to skim through.\nEvents may take several minutes to show up in CloudTrail. Be patient.\n\nNetworking\nAvailability Zones\nAvailability Zone names don’t map to the same location across accounts. Only AZ IDs from Resource Access Manager (RAM) uniquely identify Availability Zones.\nNAT Gateway\nIf a connection that’s using a NAT gateway is idle for 350 seconds or more, the connection times out.\nInterface Endpoint\nDetach of a private hosted zone in a VPC (e.g. ssm.&lt;region&gt;.amazonaws.com) can take a few minutes, so it is not possible to recover a deleted AWS service interface endpoint immediately.\nNetwork Load Balancer\n\nYou cannot change the health check interval for a target group with the TCP protocol.\nRegistration and de-registration of a target in a Network Load Balancer is expected to take between 90 and 180 seconds to complete.\nTarget security groups: NLB does not have associated security groups, so firewall rules should be configured directly on the target instances.\nYou can created at most 20 NLBs per region by default.\n\nPaaS\nAurora MySQL\nTo improve reconciliation of cluster topology changes, use a smart driver like the AWS JDBC Driver and know your DNS caching behavior.\nRDS Proxy\nYou can’t use RDS Proxy with custom DNS.\nEMR\n\nAn Amazon EMR cluster with multiple primary nodes can reside only in one Availability Zone or subnet.\nIf any two primary nodes fail simultaneously, Amazon EMR can’t recover the cluster.\n\nECS\nIn the awsvpc network mode, each task receives its own ENI. These task ENIs aren’t given public IP addresses, so tasks must be launched in a private subnet to access the internet using a NAT gateway.\nSaaS\nS3\nEach partitioned prefix in a bucket can support 3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second.\n\nDistribute your files and access pattern across prefixes to avoid this limit. You may use a randomized or sequential prefix pattern.\nAmazon S3 automatically scales to accommodate higher request rates, but this scaling happens gradually. Either gradually increase your traffic over time or contact AWS support in advance.\nImplement retry logic. Use of the token bucket algorithm is recommended, which is the default in AWS SDKs.\n\nCloud9\nSome Cloud9, IAM and STS actions are restricted with the default managed credentials. Managed credentials also does not work on EC2 instances in private subnets."},"notes/Cloud/AWS/Accessing-RHKB-via-AWS":{"slug":"notes/Cloud/AWS/Accessing-RHKB-via-AWS","filePath":"notes/Cloud/AWS/Accessing RHKB via AWS.md","title":"Accessing RHKB via AWS","links":[],"tags":[],"content":"Running an on-demand instance of Red Hat Enterprise Linux (RHEL) for at least 24 to 48 hours to get access to the Red Hat knowledge base via console.aws.amazon.com/entitlement/rhel/home."},"notes/Cloud/AWS/Amazon-Linux-2023-on-KVM":{"slug":"notes/Cloud/AWS/Amazon-Linux-2023-on-KVM","filePath":"notes/Cloud/AWS/Amazon Linux 2023 on KVM.md","title":"Amazon Linux 2023 on KVM","links":[],"tags":[],"content":"Use an empty meta-data file like so to avoid json.decoder.JSONDecodeError from cc_set_hostname.py:\n#cloud-config"},"notes/Cloud/AWS/Amazon-Managed-Service-for-Prometheus":{"slug":"notes/Cloud/AWS/Amazon-Managed-Service-for-Prometheus","filePath":"notes/Cloud/AWS/Amazon Managed Service for Prometheus.md","title":"Amazon Managed Service for Prometheus","links":[],"tags":[],"content":"Free Tier usage\n40 million metric samples can be ingested for free each month. Given a coefficient of 1.15 and 1 data point per minute, you should keep the number of series below 779.\n? 40000000/1.15/31/24/60\n%1 = 779.18\n"},"notes/Cloud/AWS/Amazon-S3":{"slug":"notes/Cloud/AWS/Amazon-S3","filePath":"notes/Cloud/AWS/Amazon S3.md","title":"Amazon S3","links":[],"tags":[],"content":"Partitioned prefixes\n\nThe purpose of the prefix and delimiter parameters is to help you organize and then browse your keys hierarchically. To do this, first pick a delimiter for your bucket, such as slash (/), that doesn’t occur in any of your anticipated key names. You can use another character as a delimiter. There is nothing unique about the slash (/) character, but it is a very common prefix delimiter.\n\nNote that delimiters do not affect prefix partitioning, so you don’t have to add a “folder structure” to get partitioned Amazon S3 prefixes. A prefix is just a string of characters at the beginning of the object key name, and it can end at any position in the key name string.\n\nWhen a specific partition runs cold, the partitioning process would need to start over when request rates are high again. Thus, to fully benefit from S3’s partitioning capabilities, it is crucial to consistently utilize prefixes that have already been partitioned to achieve higher transactions per second (TPS).\n\nThe key point is to gradually increase your traffic over time to let partitioning happen, and consistently utilize the partitioned Amazon S3 prefixes to keep them hot.\nTherefore, I think prefixes with lower entropy per character (e.g. numbers) are favorable in S3 because there are fewer variations on each character position and request rates aggregate better to keep a partitioned prefix hot.\nDelimiters\nDelimiters have limited use cases:\n\nIf you issue a list request with a delimiter, you can browse your hierarchy at only one level, skipping over and summarizing the (possibly millions of) keys nested at deeper levels.\nIndicate each level within your prefixes for Amazon S3 Storage Lens dashboards to aggregate prefix statistics. Along with the prefix depth settings, it can prevent deep levels of prefixes from showing up on the dashboard.\n\nReferences\n\nrepost.aws/knowledge-center/s3-prefix-nested-folders-difference (confusing article, wait for clarification)\nzerodha.tech/blog/1-5-million-pdfs-in-25-minutes/\ndocs.aws.amazon.com/AmazonS3/latest/userguide/optimizing-performance-design-patterns.html#optimizing-performance-high-request-rate\ndocs.aws.amazon.com/AmazonS3/latest/userguide/using-prefixes.html#prefixes-list-example\ndocs.aws.amazon.com/AmazonS3/latest/userguide/storage_lens_editing.html\n"},"notes/Cloud/AWS/Application-Load-Balancer":{"slug":"notes/Cloud/AWS/Application-Load-Balancer","filePath":"notes/Cloud/AWS/Application Load Balancer.md","title":"Application Load Balancer","links":[],"tags":[],"content":"Limitations\n\nELB IP address: up to 100\n\nReferences\n\nwww.youtube.com/watch\n"},"notes/Cloud/AWS/EC2-Performance-Benchmarks":{"slug":"notes/Cloud/AWS/EC2-Performance-Benchmarks","filePath":"notes/Cloud/AWS/EC2 Performance Benchmarks.md","title":"EC2 Performance Benchmarks","links":[],"tags":[],"content":"Single-core CPU performance\nruns-on.com/reference/benchmarks-ec2-instances/"},"notes/Cloud/AWS/Elastic-Network-Interface":{"slug":"notes/Cloud/AWS/Elastic-Network-Interface","filePath":"notes/Cloud/AWS/Elastic Network Interface.md","title":"Elastic Network Interface","links":[],"tags":[],"content":"MAC Address\nAWS allocates locally administered MAC addresses to each ENI, which means that the second digit in the human-friendly form of MAC addresses is always 2, 6, A, or E.\nThese addresses aren’t globally unique. EC2 instances in different subnets can reuse the same MAC address."},"notes/Cloud/AWS/Hyperplane":{"slug":"notes/Cloud/AWS/Hyperplane","filePath":"notes/Cloud/AWS/Hyperplane.md","title":"Hyperplane","links":["notes/Cloud/AWS/Network-Load-Balancer","notes/Network/Direct-Server-Return"],"tags":[],"content":"Architecture overview\nHyperplane is a platform that powers networking services like Network Load Balancer (NLB), NAT gateway (NATGW), PrivateLink, Gateway Load Balancer (GWLB), and Transit Gateway (TGW), and many other AWS services use it internally.\nOne AWS region has many Hyperplane clusters (a.k.a. Hyperplane cells) handling slices of workload. See Design Principles for details.\n\nNodes\nHyperplane nodes are just regular EC2 instances running in a VPC.\nFlow tracker\nFlow tracker is a horizontally scalable database that tracks all flows going through a Hyperplane cluster. It is custom built for flow tracking because no existing database solutions has the desired scale, latency and availability characteristics.\nThe data store maintains 1:1 redundancy of the flow state. When a nodes goes down in case of software deployments or failures, state is replicated to other nodes, repopulating the primary and secondary nodes for each connection involved.\nPacket processor\nPacket processor is a horizontally scalable layer that handles packet processing and forwarding.\nThe packet processing happens in user space.\nControl plane\nControl plane distributes configuration updates to flow trackers and packet processors, and manages Hyperplane capacity dynamically in response to change in demand by provisioning and de-provisioning EC2 nodes.\nContinuous testing\nAWS runs tests in each AZ continuously to monitor latency, availability and functional correctness.\nService monitoring\nHyperplane exports customer-facing metrics to CloudWatch via Kinesis.\nEstablishing a connection\nFirst, let’s zoom in and look at a more detailed architecture of Hyperplane. The packet processors are called Tops internally, and the flow trackers are composed of two components, Flow Masters and Deciders.\nTheir functionality is:\n\nTop layer handles packet forwarding and rewriting.\nFlow Master layer performs connection tracking.\nDecider layer chooses LB targets and assigns NAT source ports.\n\n\nWhen a client on the Internet tries to establish a TCP connection to a public NLB:\n\nThe client sends a TCP SYN packet to establish a connection with a NLB’s public IP address.\nThe packets ends up on a Blackfoot Edge fleet, which rewrites and forwards the packet to a particular Hyperplane cell.\nWhen packets arrives at Hyperplane, the flow is hashed to select a Top. Likely with ECMP or similar protocols.\nThe Top does not have state information about the connection yet, so it asks the primary Flow Master, selected by hashing, and runs through the backend selection process described below.\nThe Top saves connection state in memory, rewrites and delivers the packet to the target selected, keeping the source IP and port.\nThe target receives the packet, and its Nitro controller remembers to redirect packets to the client IP and port back to Hyperplane.\nThe target sends a SYN-ACK packet, which is routed to the same Hyperplane cell via Nitro and VPC networking.\nThe flow is again hashed to select a Top. However, the return path is likely going to hit a different set of nodes in all three layers because the hash ends up differently when you reverse the source and destination. AWS calls it hashing on an ordered flow basis.\nThe Top selected forwards the packet to the client, and the TCP connection is established after 3-way handshake completes.\n\nOnce the flow is established, all Tops involved remember the connection, so only the Top is involved in normal operation. In this mode, the performance penalty is on the orders of tens of microseconds.\nBackend selection\nPackets are chain-replicated between packets processors and flow tracker nodes, such that there is no buffering or retries when packets processors wait for a decision from flow trackers.\n\nThe chain also implements 1:1 redundancy. A pair of secondary decider and flow master is selected with a second set of hashes.\nDesign principles\nThe primary design goals are:\n\nCost efficiency (compared to fleets of commercial load balancers)\nScalability\nAvailability\nHigh throughput\nLong-lasting stateful connections (keep track of connections for years, e.g. for EFS connections)\nFault-tolerant\n\nConstant work\nThe system should be simple and consistent, especially when facing failures. There should be as few modes of operations as possible, to avoid combinatorial explosions of complexity.\nOne example is that cells have a fixed design capacity to test against. When scaling up, more cells are deployed instead of scaling up a particular cell.\nAnother example is the S3 Configuration Loop, as shown below.\nDesign for failures\nFail fast\nNo packet buffering or retries. Rely on TCP retransmission from the clients.\nSelf-healing\nPacket processors sends periodic heartbeats to flow trackers to update flow information, so that a failure in the redundancy of flow trackers can be recovered from and doesn’t break existing connections.\nIn many occasions, automation system can mitigate customer impact quickly in respond to an alarm.\nS3 configuration loop\n\nAWS Hyperplane nodes fetch, process and load configuration files from Amazon S3 every few seconds, even if nothing has changed.\nThe configuration file is sized to its maximum size right from the beginning to ensure the system is always processing and loading the maximum number of configuration changes.\nSuch that,\n\nThe control plane scales independently of the data plane fleet, and a storm of configuration changes does not overload the data plane.\nif AWS Hyperplane nodes are lost, the amount of work in the system goes down, not up.\n\nShuffle sharding\nAWS uses shuffle sharding for heat management, as shown in the diagram below.\n\nWith 100 nodes, there is only 2% chance for 5-node random selections to overlap more than 1 node. AWS also employs algorithmic measures to avoid overlap of more than 2 or half of the nodes between two tenants. This provides good isolation between tenants.\nCell-based\nHyperplane is a cellular and zonal service, which means that Hyperplane has its own control plane and data plane for each availability zone (AZ), and within each AZ Hyperplane operates a series of isolated cells, including a control plane for each cell. This limits blast radius and prevents single point of failure.\nPerformance\nAs of 2018, a single cell of Hyperplane can support terabits per second of throughput, hundreds of millions of connections, and tens of millions of transactions per second.\nSymmetric flows\nFlows have symmetric network path (i.e. no DSR) to enable collecting metrics from traffic in both directions on Hyperplane nodes. In case of NATGW, the packets have to be rewritten in both directions, so all packets has to go through Hyperplane.\nGoing through a Blackfoot or Hyperplane node have almost the same latency, so there is little negative impact.\nSecurity\nVPC mappings are abstracted away from Hyperplane nodes and the mappings are built and enforced in hardware instead. This protects Hyperplane from certain vulnerabilities like spoofing attack.\nCI/CD\nHyperplane’s development model is CI/CD. The CI/CD system extensively tests code as part of the deployment pipeline, and when the monitoring system detects a failure, rolls back the deployment automatically to the last know good version of that code.\nHistory\nBefore Hyperplane, AWS have also built a custom-made load balancer for S3. Hyperplane is based on the architecture of the S3 Load Balancer. S3 did not migrate to Hyperplane, so don’t worry about circular dependency here.\nThe chronological order of services built on top of Hyperplane is as follows:\n\nEFS (2015)\nNATGW (2016)\nNLB (2017)\nPrivateLink (2017)\nand more\n\nReferences\n\naws.amazon.com/builders-library/avoiding-overload-in-distributed-systems-by-putting-the-smaller-service-in-control/\naws.amazon.com/builders-library/reliability-and-constant-work/\nwww.youtube.com/watch (2017)\nwww.facebook.com/atscaleevents/videos/networking-scale-2018-load-balancing-at-hyperscale/2090077214598705/ (2018)\nAWS EC2N Hyperplane: A Deep Dive www.youtube.com/watch (2021)\n"},"notes/Cloud/AWS/Network-Load-Balancer":{"slug":"notes/Cloud/AWS/Network-Load-Balancer","filePath":"notes/Cloud/AWS/Network Load Balancer.md","title":"Network Load Balancer","links":["notes/Cloud/AWS/Hyperplane"],"tags":[],"content":"Overview\nNetwork Load Balancer (NLB) is a L4 load balancer built on Hyperplane that is more elastic than other ELB products from AWS.\nClient IP preservation\nUnlike a typical load balancer that terminates incoming connections and initiates outbound connections to targets, Hyperplane operates in a transparent mode and the target resource sees IP information about the client directly from the packets received.\nThere are several considerations I want to highlight when client IP preservation is enabled:\n\nNAT loopback, also known as hairpinning, is not supported when client IP preservation is enabled. If an instance is a client of a load balancer that it’s registered with, and it has client IP preservation enabled, the connection succeeds only if the request is routed to a different instance.\nYou might encounter TCP/IP connection limitations related to observed socket reuse on the targets. These connection limitations can occur when a client, or a NAT device in front of the client, uses the same source IP address and source port when connecting to multiple load balancer nodes (e.g. client connects to one IP in each AZ) simultaneously. If the load balancer routes these connections to the same target, the connections appear to the target as if they come from the same source socket, which results in connection errors.\nWhen client IP preservation is enabled, targets must be in the same VPC as the Network Load Balancer, and traffic must flow directly from the Network Load Balancer to the target.\nClient IP preservation is not supported when a target group contains AWS PrivateLink ENIs, or the ENI of another Network Load Balancer. This will cause loss of communication to those targets.\nClient IP preservation can’t be disabled for instance and IP type target groups with UDP and TCP_UDP protocols.\n\nHealth checks\nNLB uses active and passive health checks to determine whether a target is available to handle requests. Other AWS load balancers does not support passive health checks, so this is a feature unique to NLB and Hyperplane, on a scale of tens of milliseconds for a failover to happen.\nFail open\nIf all targets fail health checks at the same time in all enabled Availability Zones, the load balancer fails open. The effect of the fail open is to allow traffic to all targets in all enabled Availability Zones, regardless of their health status.\nUDP\nUDP health checks are not supported. For a UDP service, target availability can be tested using non-UDP health checks on your target group.\nTCP RST packets\nIf no data is sent through a TCP connection by either the client or the target for longer than the idle timeout, the connection is closed. If a client or a target sends data after the idle timeout period elapses, it receives a TCP RST packet to indicate that the connection is no longer valid.\nThe idle timeout value is 350 seconds for TCP flows, and 120 seconds for UDP flows.\nAdditionally, if a target becomes unhealthy, the load balancer sends a TCP RST for packets received on the client connections associated with the target, unless the unhealthy target triggers the load balancer to fail open. The behavior can be switched off with the target_health_state.unhealthy.connection_termination.enabled target group attribute, but connections are still subject to idle timeout.\nNumber of TCP RST packets generated per NLB can be tracked with the TCP_ELB_Reset_Count metric.\nAvailability Zone isolation\nBy default, each load balancer node routes requests only to the healthy targets in its Availability Zone. If you enable cross-zone load balancing, each load balancer node routes requests to the healthy targets in all enabled Availability Zones. See Cross-zone load balancing for an example of traffic distribution comparison.\nAvailability Zone DNS affinity\nWhen using the default client routing policy, client connections are distributed across the load balancer AZs.\nIf you are using the Route 53 resolver, you can configure the percentage of zonal affinity, favoring load balancer IP addresses from the same AZ.\nIf you are not using the Route 53 resolver, you could still implement this in your application with AZ-specific DNS names [az].[name]-[id].elb.[region].amazonaws.com, for example:\nus-east-2b.my-load-balancer-1234567890abcdef.elb.us-east-2.amazonaws.com\nNote that when using Availability Zone DNS affinity, cross-zone load balancing should be turned off, otherwise traffic from load balancer nodes to targets are still\nReferences\n\ndocs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-target-groups.html#client-ip-preservation\ndocs.aws.amazon.com/elasticloadbalancing/latest/network/target-group-health-checks.html\n"},"notes/Cloud/Azure/Acceleration-mechanisms-on-NVIDIA-ConnectX-5-NICs":{"slug":"notes/Cloud/Azure/Acceleration-mechanisms-on-NVIDIA-ConnectX-5-NICs","filePath":"notes/Cloud/Azure/Acceleration mechanisms on NVIDIA ConnectX-5 NICs.md","title":"Acceleration mechanisms on NVIDIA ConnectX-5 NICs","links":[],"tags":[],"content":"List of mechanisms with dedicated counters\n\nTSO (TCP Segmentation Offload) - increasing outbound throughput and reducing CPU utilization by allowing the kernel to buffer multiple packets in a single large buffer. The NIC split the buffer into packet and transmits it\nLRO (Large Receive Offload) - increasing inbound throughput and reducing CPU utilization by aggregation of o multiple incoming packet of a single stream to a single buffer\n\nThere is also GRO (Generic Receive Offload), which is considered less broken according to a blog post (2009).\n\n\nCHECKSUM (Checksum) – calculation of TCP checksum (by the NIC). The following CSUM offload are available (refer to skbuff.h for detailed explanation)\n\nCHECKSUM_UNNECESSARY\nCHECKSUM_NONE – no CSUM acceleration was used\nCHECKSUM_COMPLETE – Device provided CSUM on the entire packet\nCHECKSUM_PARTIAL – Device provided CSUM\n\n\nCQE Compress – compression of Completion Queue Events (CQE) used for sparing bandwidth on PCIe and hence achieve better performance.\n\nLRO\nRequirements\n\nLRO is only enabled in Striding RQ (a.k.a. Multi-Packet Rx Queue, or MPRQ)\nMinimal hardware version is ConnectX-5\n\nHow to enable Striding RQ\n# ethtool --set-priv-flags eno0 rx_striding_rq on\n# ethtool --show-priv-flags eno0\nPrivate flags for eno0:\n...\nrx_striding_rq : on\n... \nHow to enable LRO\nLRO on a new kernel can be configured using ethtool commands:\n\nTo check LRO config, run:\n\n# ethtool -k ens801f1 | grep large-receive-offload\nlarge-receive-offload: off\n\nTo enable LRO, run:\n\n# ethtool -K eth1 lro on\n\nTo disable LRO, run:\n\n# ethtool -K eth1 lro off\n\nTo verify LRO configuration, run:\n\n# ethtool -k ens801f1 | grep large-receive-offload\nlarge-receive-offload: on\nTSO\nRequirements\n\nMinimal hardware version is ConnectX-4\n\nHow to enable TSO\n\nTo check TSO config, run:\n\n# ethtool -k ens801f1 | grep tcp-segmentation-offload\ntcp-segmentation-offload: on\nFollowing steps are similar to LRO.\nethtool configuration persistence\nRHEL 9\n\nTo set persistent LRO configuration in the ens801f1 connection profile, run:\n\nnmcli con modify ens801f1 ethtool.feature-rx on\n\nTo remove persistent LRO configuration, run:\n\nnmcli con modify ens801f1 ethtool.feature-rx &quot;&quot;\nRHEL 8\nTo persist LRO configuration on RHEL 8, add the following to /etc/sysconfig/network-scripts/ifcfg-* (replace * with interface name):\nETHTOOL_OPTS=&quot;-K ${DEVICE} lro on&quot;\n\nReferences\n\ngithub.com/torvalds/linux/commit/6c3a823e1e9c645f30c5b03fefe87fea8881060b\ndoc.dpdk.org/guides/nics/mlx5.html\nwww.ibm.com/docs/en/linux-on-systems#d7439e143\nenterprise-support.nvidia.com/s/article/how-to-enable-large-receive-offload—lro-x\nenterprise-support.nvidia.com/s/article/understanding-mlx5-ethtool-counters\nwww.redhat.com/en/blog/rhel-9-networking-say-goodbye-ifcfg-files-and-hello-keyfiles\naccess.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_networking/configuring-ip-networking-with-ifcfg-files_configuring-and-managing-networking\naccess.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_networking/configuring-ethtool-settings-in-networkmanager-connection-profiles_configuring-and-managing-networking\n"},"notes/Cloud/Azure/Ananta":{"slug":"notes/Cloud/Azure/Ananta","filePath":"notes/Cloud/Azure/Ananta.md","title":"Ananta","links":["notes/Network/Direct-Server-Return","notes/Cloud/Azure/Azure-Load-Balancer"],"tags":[],"content":"Architecture\n\nEach instance of Ananta is comprised of three main components, Ananta Manager (AM), Multiplexer (Mux) and Host Agent (HA).\nA set of Annata instances could broadcast the same /21 prefix to reduce impact of single instance failures.\nAnanta Manager\nAnanta Manager (AM) implements the control plane of Ananta. It achieves HA using the Paxos consensus protocol with 5 replicas per instance.\nMux Pool\nAn instance of Ananta has one or more sets of Muxes called Mux Pools.\nLost or addition of Muxes in a Mux Pool will cause ongoing connections to be redistributed among the currently live Muxes based on router’s ECMP implementation. When this happens, these connections may get misdirected, subject to mapping entry changes.\nMux\nMux only handles incoming traffic. The other direction is handled by DSR.\nMux is responsible for receiving traffic for all configured VIPs from the router and forwarding it to appropriate DIPs.\nMux makes use of consistent hashing of the five-tuple (source IP, destination IP, IP Protocol, source port and destination port) to balance new flows across DIPs.\nMux maintains a mapping table, where each entry maps a VIP endpoint to a list of DIPs.\nEach Mux node has its own memory quota for trusted and untrusted flows. Once memory quota for trusted flow queue is exhausted, new flow states will not be created, and Mux falls back to using the hash to lookup DIP. This provides a degraded service, during which untracked connections may get misdirected if a change was made in the mapping entry (VIP, IP Protocol, port) → DIPs.\nDo not confuse untracked connections with stateless mapping entries. Stateless mapping entries are used for SNAT and is a stateless rule that maps a port on VIP to the requesting DIP, which can be reused for multiple connections, that is, port reuse.\nHost Agent\nHost Agent (HA) is responsible for Inbound NAT, Source NAT and checking health of DIPs.\n\nInbound NAT: decapsulate packets from Mux.\nSource NAT: See Outbound Rules (SNAT).\nDIP Health Monitoring: Run health probes for Azure Load Balancer and push status updates to AM, which relays them to all related Muxes.\n\nDesign Principles\nScale\nAnanta needs to configure HAs and Muxes during each VIP configuration change, and its programming time could be delayed due to data plane overload, network interruptions, and other real-world failure patterns. The resulting latency generally fits in Azure’s API SLAs, but in case of failure it’s prone to get worse.\nThe data plane relies on industry-standard ECMP at the routers to spread load across Muxes, and RSS at the NICs to spread load across multiple CPU cores.\nHandling Failures\nEach Mux is a BGP speaker. If a Mux fails or shuts down unexpectedly, the router detects the failure via the BGP protocol and automatically drops routes to that Mux."},"notes/Cloud/Azure/Azure-Accelerated-Networking":{"slug":"notes/Cloud/Azure/Azure-Accelerated-Networking","filePath":"notes/Cloud/Azure/Azure Accelerated Networking.md","title":"Azure Accelerated Networking","links":["notes/Cloud/Azure/Virtual-Filtering-Platform","notes/Cloud/Azure/Receive-segment-coalescing","notes/Cloud/Azure/Microsoft-Azure-Network-Adapter"],"tags":["networking"],"content":"Overview\nBenefits\n\nMore deterministic performance, that is, reduced jitter and latency inconsistency\nDecreased CPU utilization\nHigher packets per second (pps) on the datapath\n\nLatency improvement is very minimal when VMs communicate across virtual networks or connect to on-premises and the Internet.\nLimitations\n\nThe Azure platform does not update the Mellanox NIC drivers in the VM. The driver is known to have bugs on old kernels.\n\nTechnical details\nAzure SmartNIC\nBased on FPGAs, AccelNet offloads packet forwarding to SmartNIC hardware with Generic Flow Tables. GFT is a match-action language that defines specific operations on packets for one specific network flow.\nIf GFT does not match a given packet, the SmartNIC hardware will send the packet to the software layer (VFP) as an Exception Packet, which are most common on the first packet of each flow. After the first packet of each flow, all forwarding can be offloaded, providing the full performance of a native SR-IOV hardware solution.\nServiceability\nAccelNet is transparent to user space applications via NetVSC service in VM, which switches I/O back to synthetic vNICs during a service event to maintain connectivity.\n\nSupported VM instances\nSee Linux VM sizes, where each “series” has its own page describing Accelerated Networking support among other information.\nAccelerated Networking is required and turned on by default on some series, including all v5 and above Intel processor general purpose sizes.\nOther networking acceleration mechanisms on Azure\n\nReceive segment coalescing\nThe next-generation MANA\n\nReferences\n\nwww.microsoft.com/en-us/research/uploads/prod/2018/03/Azure_SmartNIC_NSDI_2018.pdf\nlearn.microsoft.com/en-us/azure/site-recovery/azure-vm-disaster-recovery-with-accelerated-networking#supported-vm-instances-1\n"},"notes/Cloud/Azure/Azure-Blob-Storage":{"slug":"notes/Cloud/Azure/Azure-Blob-Storage","filePath":"notes/Cloud/Azure/Azure Blob Storage.md","title":"Azure Blob Storage","links":[],"tags":[],"content":"Partitioning\n\nBlob storage uses a range-based partitioning scheme for scaling and load balancing. Each blob has a partition key comprised of the full blob name (account+container+blob). The partition key is used to partition blob data into ranges. The ranges are then load-balanced across Blob storage.\n\n\nIf your naming scheme uses timestamps or numerical identifiers, it can lead to excessive traffic to one partition. It prevents the system from effectively load balancing. For instance, if you have daily operations that use a blob object with a timestamp, such as yyyy-mm-dd, all the traffic for that operation goes to a single partition server. Instead, prefix the name with a three-digit hash.\n\nConsistency\n\nThe actions of writing a single block or page are atomic, but operations that span blocks, pages, or blobs aren’t. If you need to ensure consistency when write operations are performed across blocks, pages, and blobs, take out a write lock by using a blob lease.\n\nReferences\n\nlearn.microsoft.com/en-us/azure/well-architected/reliability/partition-data#partition-in-azure-blob-storage\nlearn.microsoft.com/en-us/azure/storage/blobs/storage-performance-checklist#partitioning\nsigops.org/s/conferences/sosp/2011/current/2011-Cascais/printable/11-calder.pdf\n"},"notes/Cloud/Azure/Azure-Data-Lake-Storage-best-practices":{"slug":"notes/Cloud/Azure/Azure-Data-Lake-Storage-best-practices","filePath":"notes/Cloud/Azure/Azure Data Lake Storage best practices.md","title":"Azure Data Lake Storage best practices","links":[],"tags":[],"content":"File size\nLarger files lead to better performance and reduced costs.\nTypically, analytics engines have a per-file overhead that involves tasks such as listing, checking access, and performing various metadata operations. If you store your data as many small files, this can negatively affect performance. In general, organize your data into larger sized files for better performance (256 MB to 100 GB in size). Some engines and applications might have trouble efficiently processing files that are greater than 100 GB in size."},"notes/Cloud/Azure/Azure-Load-Balancer":{"slug":"notes/Cloud/Azure/Azure-Load-Balancer","filePath":"notes/Cloud/Azure/Azure Load Balancer.md","title":"Azure Load Balancer","links":["notes/Cloud/Azure/Ananta","notes/Network/Direct-Server-Return","notes/Network/Strong-and-weak-host-models"],"tags":["networking"],"content":"Ananta\nAzure Load Balancer is based on the Ananta design.\nFastpath\nIntra-DC traffic seen on internal load balancers is mostly offloaded to end systems. Packets are delivered directly to the DIP, bypassing Mux in both directions, thereby enabling communication at full network capacity.\nDirect Server Return (DSR)\nSee Direct Server Return for comparison with other cloud providers.\nFaireness\nIf a flow attempts to steal more than its fair share of bandwidth, Mux starts to drop its packets with a probability directly proportional to the excess bandwidth it’s using.\nIf there is packet drop due to overload, Mux creates a black hole for the offending VIP by withdraw BGP advertisements, and traffic for the VIP may be routed to DoS protection services in several minutes.\nMultiple frontends\nAzure Load Balancer does not allow reusing backend ports by default. Each rule must produce flows with an exclusive combination of destination IP address and destination port. Multiple load balancing rules can deliver flows to the same backend instance IP on different ports by varying the destination port of the flow.\nIf you want to reuse a backend port across multiple rules, you must enable Floating IP in the load balancing rule definition. Floating IP is Azure’s terminology for a portion of what is known as Direct Server Return (DSR). Note that Floating IP for IPv6 doesn’t work for Internal Load Balancers. Floating IP also relies on the weak host model.\nLimitations\n\nLoad Balancer backend pool can’t consist of a Private Endpoint.\nOutbound flow from a backend VM to a frontend of an internal Load Balancer fails silently.\nA load balancer rule can’t span two virtual networks. All load balancer frontends and their backend instances must be in a single virtual network.\nYou can only have one NIC-based Public Load Balancer and one NIC-based internal Load Balancer per availability set. Note that this constraint doesn’t apply to IP-based load balancers.\n\nAvailability set is a special feature around fault domain placement and provides fault isolation to some degree.\n\n\n\nOutbound rules (SNAT)\nAnanta also implements a distributed NAT for outbound connections, besides processing inbound connections. This allows backend instances to use the public IPs of a load balancer to provide outbound internet connectivity.\nAM allocates an externally routable (VIP, port) tuple and configures each Mux in the associated Mux Pool with this allocation. This ensures that returning packets sent to Mux can be routed back to DIP.\n\nReferences\n\nlearn.microsoft.com/en-us/azure/load-balancer/load-balancer-multivip-overview\nlearn.microsoft.com/en-us/azure/load-balancer/outbound-rules\nconferences.sigcomm.org/sigcomm/2013/papers/sigcomm/p207.pdf\n"},"notes/Cloud/Azure/Azure-NAT-Gateway":{"slug":"notes/Cloud/Azure/Azure-NAT-Gateway","filePath":"notes/Cloud/Azure/Azure NAT Gateway.md","title":"Azure NAT Gateway","links":[],"tags":[],"content":"Azure’s NAT gateway (NATGW)\n\nLimitations\nEach NAT gateway can provide up to 50 Gbps of throughput.\nA NAT gateway can support up to 50,000 concurrent connections per public IP address to the same destination endpoint over the internet for TCP and UDP. The NAT gateway can process 1M packets per second and scale up to 5M packets per second."},"notes/Cloud/Azure/Azure-Network-idle-timeout":{"slug":"notes/Cloud/Azure/Azure-Network-idle-timeout","filePath":"notes/Cloud/Azure/Azure Network idle timeout.md","title":"Azure Network idle timeout","links":[],"tags":[],"content":"\npublic IP: 4-30 minutes adjustable inbound, 4 minutes fixed outbound.\nLB: adjustable, 4-100 minutes. Default is 4 minutes.\n\nIf you set idle timeout to a large value, you risk reaching the VM connection limit. On the other hand, a very short idle time out could drop valid connections.\nFor SSH, Azure recommends ClientAliveInterval 180, which corresponds to 75% of default idle timeout, or 30-235 if there are special requirements.\nReferences\n\nlearn.microsoft.com/en-us/azure/load-balancer/load-balancer-tcp-idle-timeout\nlearn.microsoft.com/en-us/azure/virtual-network/ip-services/public-ip-addresses\nlearn.microsoft.com/en-us/azure/virtual-machines/linux/redhat-create-upload-vhd\nlearn.microsoft.com/en-us/partner-center/marketplace/azure-vm-certification-faq\n"},"notes/Cloud/Azure/Azure-VM-size-series-naming":{"slug":"notes/Cloud/Azure/Azure-VM-size-series-naming","filePath":"notes/Cloud/Azure/Azure VM size series naming.md","title":"Azure VM size series naming","links":[],"tags":[],"content":"Dpsv6 is the base name of the Azure Cobalt 100 processor series.\n\nThe D family of VM sizes are one of Azure’s general purpose VM sizes. The standard general purpose VMs offer 4 GiB of memory per vCPU and come without local disk.\nLetter p represents the processor series. Here it’s Azure’s first-generation Cobalt 100 processor.\nLetter s represents Premium SSD or Ultra Disk storage support.\nv6 represents the sixth generation.\n\nDplsv6-series offer 2 GiB of memory per vCPU. l for less memory?\nDpdsv6-series offer local NVMe temporary storage. d for local disk?"},"notes/Cloud/Azure/Hyper-V-guest-features":{"slug":"notes/Cloud/Azure/Hyper-V-guest-features","filePath":"notes/Cloud/Azure/Hyper-V guest features.md","title":"Hyper-V guest features","links":["notes/Cloud/Azure/Receive-Side-Scaling-on-Azure","notes/Cloud/Azure/Acceleration-mechanisms-on-NVIDIA-ConnectX-5-NICs","notes/Cloud/Azure/Azure-Accelerated-Networking"],"tags":[],"content":"Networking\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureDescriptionJumbo framesWith this feature, an administrator can increase the size of network frames beyond 1500 bytes, which leads to a significant increase in network performance.VLAN tagging and trunkingThis feature allows you to configure virtual LAN (VLAN) traffic for virtual machines.Live MigrationWith this feature, you can migrate a virtual machine from one host to another host.Static IP InjectionWith this feature, you can replicate the static IP address of a virtual machine after it has been failed over to its replica on a different host. Such IP replication ensures that network workloads continue to work seamlessly after a failover event.vRSS (Virtual Receive Side Scaling)Spreads the load from a virtual network adapter across multiple virtual processors in a virtual machine. For more information, see Receive Side Scaling on Azure.TCP Segmentation and Checksum OffloadsTransfers segmentation and checksum work from the guest CPU to the host virtual switch or network adapter during network data transfers. For more information, see Acceleration mechanisms on NVIDIA ConnectX-5 NICs.Large Receive Offload (LRO)Increases inbound throughput of high-bandwidth connections by aggregating multiple packets into a larger buffer, decreasing CPU overhead. The feature is enabled by default on VMs running on Windows Server 2019 and later. For more information, see Acceleration mechanisms on NVIDIA ConnectX-5 NICs.SR-IOVSingle Root I/O devices use DDA to allow guests access to portions of specific NIC cards allowing for reduced latency and increased throughput. SR-IOV requires up to date physical function (PF) drivers on the host and virtual function (VF) drivers on the guest. For more information, see also Azure Accelerated Networking.\nReferences\n\nlearn.microsoft.com/en-us/windows-server/virtualization/hyper-v/feature-descriptions-for-linux-and-freebsd-virtual-machines-on-hyper-v\ndocs.kernel.org/networking/device_drivers/ethernet/microsoft/netvsc.html\n"},"notes/Cloud/Azure/Linux-Integration-Services":{"slug":"notes/Cloud/Azure/Linux-Integration-Services","filePath":"notes/Cloud/Azure/Linux Integration Services.md","title":"Linux Integration Services","links":["notes/Cloud/Azure/Hyper-V-guest-features","notes/Operating-System/Linux/List-Out-of-Tree-modules-in-Linux"],"tags":["deprecated"],"content":"Overview\nLinux Integration Services is a set of drivers that enable synthetic device support in Linux VMs under Hyper-V.\nYou can install the stand-alone LIS package as an upgrade in older Linux distributions with LIS built-in, but the package hasn’t been updated since March 2020 and development is mostly stalled. If you are experiencing problems on newer distribution versions, update the kernel instead.\nSupported Linux distributions\n\nRHEL 5.2 to 7.6\nCentOS 5.2 to 7.6\nOracle Linux 6.4 to 7.6, with Red Hat Compatible Kernel\n\nFeatures\n\nSRIOV (for example, Azure Accelerated Networking) capability for Red Hat Enterprise Linux, CentOS, and Oracle Linux with the Red Hat Compatible Kernel versions 6.7-6.10 (64-bit only)\nUpdated mlx4 and mlx5 drivers for Red Hat Enterprise Linux, CentOS, and Oracle Linux with the Red Hat Compatible Kernel versions 7.3-7.4.\nLinux Integration Services uses the Hyper-V TimeSync protocol to implement a Precision Time Protocol service with this time source.\n\nSee Hyper-V guest features for recent feature development that might not be available in the LIS package.\nUsage\nValidate installation\nLinux Integration Services kernel modules can be listed with the modinfo command.\n# modinfo hv_vmbus\nfilename:    /lib/modules/2.6.32-71.el6.x86_64/extra/microsoft-hyper-v/hv_vmbus.ko\nversion:     4.3.5\n...\nThis command can be repeated for all kernel modules (hv_vmbus, hv_netvsc, hv_storvsc, hv_blkvsc, and hv_utils), but only out-of-tree modules have useful version information. See also List Out-of-Tree modules in Linux.\nTo verify that all subcomponents are running in the kernel, execute the following command:\n/sbin/lsmod | egrep -i &quot;^hv|hyperv&quot;\nTimeSync PTP service\nTo verify the device is the TimeSync device, check the clock name:\n$ ls /sys/class/ptp\nptp0  ptp1\n$ cat /sys/class/ptp/ptp0/clock_name\nhyperv\nTo switch to the host clock when using chronyd, enable TimeSync as a source in /etc/chrony.conf:\nrefclock PHC /dev/ptp0 poll 3 dpoll -2 offset 0\n\nLatest documentation for TimeSync is available at learn.microsoft.com/en-us/azure/virtual-machines/linux/time-sync#tools-and-resources. Note the udev rule requirement and stratum 2 configuration.\nReferences\n\nLinux Integration Services v4-3-5.pdf from www.microsoft.com/en-us/download/details.aspx\n"},"notes/Cloud/Azure/Microsoft-Azure-Linux-Guest-Agent":{"slug":"notes/Cloud/Azure/Microsoft-Azure-Linux-Guest-Agent","filePath":"notes/Cloud/Azure/Microsoft Azure Linux Guest Agent.md","title":"Microsoft Azure Linux Guest Agent","links":["notes/Cloud/Azure/Virtual-Filtering-Platform"],"tags":[],"content":"Conntrack\nWALinuxAgent enables connection tracking for a security feature. You may need to adjust Linux OS configuration to support a large number of connections. If you faced connectivity issues on Azure VMs, check dmesg output and have a lot of connections open. But if you expect more than 500k connections, it could be limited by the Azure networking stack, as described in Virtual Filtering Platform.\nReferences\n\nlearn.microsoft.com/en-us/azure/aks/custom-node-configuration (net.netfilter.nf_conntrack_max)\ngithub.com/Azure/WALinuxAgent/blob/28345a55f9b21dae89472111635fd6e41809d958/azurelinuxagent/common/utils/networkutil.py#L186-L189\n"},"notes/Cloud/Azure/Microsoft-Azure-Network-Adapter":{"slug":"notes/Cloud/Azure/Microsoft-Azure-Network-Adapter","filePath":"notes/Cloud/Azure/Microsoft Azure Network Adapter.md","title":"Microsoft Azure Network Adapter","links":[],"tags":[],"content":"Driver\nThe driver supports Linux and Windows only.\nOn Linux\nLinux v6.6+ is recommended. Example of patches required:\n\ngithub.com/torvalds/linux/commit/a7dfeda6fdeccab4c7c3dce9a72c4262b9530c80 for robustness\ngithub.com/torvalds/linux/commit/b1d13f7a3b5396503e6869ed627bb4eeab9b524f for performance\n\nSource:\n\ngithub.com/microsoft/azurelinux/blob/2.0/SPECS/kernel-azure/kernel-azure.spec\nPatches backported to the CBL-Mariner Linux kernel in 2024\n\nCompatibility\n\nMANA maintains feature-parity with previous Azure networking features. VMs run on hardware with both Mellanox and MANA NICs, so existing ‘mlx4’ and ‘mlx5’ support still need to be present.\n\n\nThe next generation of Azure Boost will introduce the Microsoft Azure Network Adapter (MANA).\n\nSee learn.microsoft.com/en-us/azure/azure-boost/overview#current-availability for the list of compatible VM size families, but beware that compatible VMs may run on Mellanox NICs too.\nCheck traffic flowing through the MANA adapter\nYou can get packet and byte count of the MANA Virtual Function (VF) from the routable ethN interface:\n$ ethtool -S eth0 | grep -E &quot;^[ \\t]+vf&quot;\n     vf_rx_packets: 226418\n     vf_rx_bytes: 99557501\n     vf_tx_packets: 300422\n     vf_tx_bytes: 76231291\n     vf_tx_dropped: 0"},"notes/Cloud/Azure/Receive-Side-Scaling-on-Azure":{"slug":"notes/Cloud/Azure/Receive-Side-Scaling-on-Azure","filePath":"notes/Cloud/Azure/Receive Side Scaling on Azure.md","title":"Receive Side Scaling on Azure","links":[],"tags":[],"content":"\nHyper-V supports receive side scaling. For TCP &amp; UDP, packets can be distributed among available queues based on IP address and port number.\nFor TCP &amp; UDP, we can switch hash level between L3 and L4 by ethtool command. TCP/UDP over IPv4 and v6 can be set differently. The default hash level is L4. We currently only allow switching TX hash level from within the guests.\nOn Azure, fragmented UDP packets have high loss rate with L4 hashing. Using L3 hashing is recommended in this case.\n\nFor example, for UDP over IPv4 on eth0:\nTo include UDP port numbers in hashing:\nethtool -N eth0 rx-flow-hash udp4 sdfn\nTo exclude UDP port numbers in hashing:\nethtool -N eth0 rx-flow-hash udp4 sd\nTo show UDP hash level:\nethtool -n eth0 rx-flow-hash udp4\nReferences\n\ndocs.kernel.org/networking/device_drivers/ethernet/microsoft/netvsc.html\n"},"notes/Cloud/Azure/Receive-segment-coalescing":{"slug":"notes/Cloud/Azure/Receive-segment-coalescing","filePath":"notes/Cloud/Azure/Receive segment coalescing.md","title":"Receive segment coalescing","links":[],"tags":[],"content":"When receiving data, the miniport driver, NDIS, and TCP/IP must all look at each PDU’s header information separately. When the network stack receives a large amount of data, this is a lot of overhead. Receive segment coalescing (RSC) reduces the overhead by coalescing a sequence of received segments and passing them to the host TCP/IP stack in one operation, so that NDIS and TCP/IP need only look at one header for the entire sequence.\nRSC supports coalescing in a way that:\n\n\nDoesn’t interfere with the normal operation of TCP’s congestion and flow control mechanisms.\n\n\nCoalesces packets without discarding information used by the TCP stack.\n\n\nRSC-capable miniport drivers for network cards must:\n\n\nFollow a standard set of rules when coalescing segments.\n\n\nProvide certain out-of-band information to the host TCP/IP stack.\n\n\nAt a high level, the NIC and miniport driver must handle the receipt of a TCP segment over the wire as follows:\n\n\nCheck the incoming segment for an exception as follows:\n\n\nIf no exception was encountered, check whether the segment can be coalesced with the last segment that was received for the same TCP connection per the rules.\n\n\nIf the segment triggered an exception, or if coalescing it with the previously received segment is not possible, then indicate the segment individually.\n\n\n\n\nThe NIC and miniport driver must not indicate coalesced segments until the protocol driver enables RSC.\n\n\nFor a given TCP connection, a data indication from the miniport adapter to the host TCP/IP stack may consist of one or more coalesced segments, separated by one or more individual segments that could not be coalesced.\n\n\nThe NIC and miniport driver must not delay the indication of TCP segments, whether coalesced or not. Specifically, the NIC and miniport driver must not delay the indication of segments from one deferred procedure call (DPC) to the next in order to attempt to coalesce the segments.\n\n\nThe NIC and miniport driver may use timers to determine the end of coalescing. However, the handling of latency sensitive workloads must be as effective as the DPC boundary requirement.\n\n\nReferences\n\nlearn.microsoft.com/en-us/windows-hardware/drivers/network/overview-of-receive-segment-coalescing\n"},"notes/Cloud/Azure/Traceroute-on-Azure":{"slug":"notes/Cloud/Azure/Traceroute-on-Azure","filePath":"notes/Cloud/Azure/Traceroute on Azure.md","title":"Traceroute on Azure","links":["notes/Network/Path-MTU-Discovery"],"tags":[],"content":"github.com/catchpoint/Networking.traceroute\nThis version of traceroute has an “Loose match” mode that allows traceroute to run properly in Azure environments.\nHowever, ICMP isn’t supported on NAT gateways and fails to go through them. But what about Path MTU Discovery?\nReferences\n\nfosdem.org/2024/schedule/event/fosdem-2024-2929—where-the-are-the-packets-going-/\n"},"notes/Cloud/Azure/VL2":{"slug":"notes/Cloud/Azure/VL2","filePath":"notes/Cloud/Azure/VL2.md","title":"VL2","links":["notes/Network/Valiant-Load-Balancing","notes/Cloud/Google-Cloud/Andromeda"],"tags":[],"content":"Valiant Load Balancing\nAzure adopts VLB to cope with traffic volatility. Traffic patterns not exceeding line card speeds don’t cause any interference in the network.\nVL2 agent selects an intermediate switch via one or a set of anycast addresses, each representing a pool of intermediate switches and relies on ECMP to split traffic in equal ratios.\nAddressing\nSeparating AAs (application-specific Addresses) from LAs (location-specific addresses, which identify the ToR switch to which servers are connected) reduces complexity on the intermediate and aggregate switches that implement VLB. These switches only need to know where to forward packets carrying LAs, and LAs are bound to locations, so routes could be aggregated into bigger CIDR blocks, resulting in fewer routes.\nIt also limits the number of AAs a ToR switch needs to know to only servers under it, also reducing number of routes.\nDirectory System\nThe VL2 directory system stores the mappings of AAs to LAs.\nThe directory system replaces ARP broadcast packets with unicast query to the VL2 directory system. The mapping is also cached, just like a host’s ARP cache.\nThe VL2 agent at each server traps packets from the host and encapsulates them with the LA address of the destination ToR. The destination ToR switch then decapsulates the packet and delivers it to the destination AA.\nLayer-2 semantics\nARP is replaced by the directory system, and DHCP messages are intercepted and unicast forwarded to DHCP servers.\nOther general layer-2 broadcast traffic is handled via IP multicast using service-specific multicast address. General broadcast traffic is rate-limited to prevent storms.\nCache invalidation\nA stale host mapping is only corrected when it’s used to deliver traffic. The destination ToR forwards a sample of non-deliverable packets to a directory server, which sends corrections to the source server in samples. This reflects that VL2 follows the On Demand Model described in Andromeda’s paper.\nReferences\n\nwww.microsoft.com/en-us/research/wp-content/uploads/2016/02/vl2-sigcomm09-final.pdf\n"},"notes/Cloud/Azure/Virtual-Filtering-Platform":{"slug":"notes/Cloud/Azure/Virtual-Filtering-Platform","filePath":"notes/Cloud/Azure/Virtual Filtering Platform.md","title":"Virtual Filtering Platform","links":["notes/Operating-System/FreeBSD/PF-firewall","notes/Cloud/Azure/Azure-Accelerated-Networking"],"tags":["networking"],"content":"Programming model\nPorts\nEach port maps to a VM or VNIC (virtual NIC). VFP filters traffic from and to a VNIC by attaching a set of policies to each port.\nEach port can scale up to 500k concurrent TCP connections, after which state tracking is considered prohibitively expensive.\nLayers\nVFP divides a port’s policy into layers.\n\nPackets traverse layers in the opposite order when inbound than when outbound. This implements an address space boundary, with all packets above “VIP→DIP NAT” in DIP Space, and packets below it in VIP Space.\nGroups\nGroups are the atomic unit of policy in VFP, which means transactional update of policy happens at this level.\nGroups can have global conditions, which let packets pass through, traversing further groups.\n\nGroups are processed sequentially within a layer. Usually the last group matched is selected for processing. However, if a rule is marked “terminating,” it’s applied immediately without traversing further groups.\nThis is similar to PF Firewall’s rule evaluation, with the exception that within each group only the highest priority rule that matches the packet is selected.\nUnified Flow Table\nThe action for a UFID (identifier for a unique flow) is relatively stable over the lifetime of a flow, so the UFID can be cached with the resulting HT (Header Transposition). The resulting flow table is the Unified Flow Table (UFT).\nWith the UFT, only the first packet of a TCP flow has to go through the slow path of running the transposition engine. Subsequent packets have the cached HT action applied directly.\nUFT dramatically improves VFP performance, especially with Azure Accelerated Networking offload.\nReconciliation\nEach UF (unified flow) is tagged with the current generation number of the port at creation time. If a matching UF whose generation number is less than the port’s current number, lazy reconciliation is performed.\nReferences\n\nwww.usenix.org/system/files/conference/nsdi17/nsdi17-firestone.pdf\n"},"notes/Cloud/Backblaze-B2-API-pricing":{"slug":"notes/Cloud/Backblaze-B2-API-pricing","filePath":"notes/Cloud/Backblaze B2 API pricing.md","title":"Backblaze B2 API pricing","links":[],"tags":[],"content":"\nThe Backblaze B2 Native API, introduced alongside Backblaze B2 back in 2015, provides a low-level interface to B2 Cloud Storage. We generally recommend that developers use the S3 Compatible API when writing new applications and integrations, as it is supported by a wider range of SDKs and libraries, and many developers already have experience with Amazon S3. You can use the Backblaze B2 web console or the B2 Native API to access functionality, such as application key management and lifecycle rules, that is not covered by the S3 Compatible API.\nwww.backblaze.com/blog/explore-the-backblaze-s3-compatible-api-with-our-new-postman-collection/\n\nThe B2 native API is more efficient at retrieving object metadata in batches with the b2_list_file_names API. The S3-compatible API would require one ListObjectsV2 call, and a HeadObject call for each file.\nThe S3-compatible API is cheaper for HeadObject, unless you are saving the fileId somewhere else. b2_get_file_info requires fileId, which can only be retrieved via b2_list_file_names or b2_list_file_versions, both are Transaction Class C APIs that are 10x more expensive than HeadObject under Transaction Class B. Note that b2_list_file_names already returns file metadata, so you don’t need to make an extra call to b2_get_file_info if you just need those information.\nFor other API calls, the pricing is mostly the same, and according to the general recommendation on their blog, developers should prefer the S3-compatible API."},"notes/Cloud/GitHub-personal-access-token-to-perform-Git-operations-over-HTTPS":{"slug":"notes/Cloud/GitHub-personal-access-token-to-perform-Git-operations-over-HTTPS","filePath":"notes/Cloud/GitHub personal access token to perform Git operations over HTTPS.md","title":"GitHub personal access token to perform Git operations over HTTPS","links":[],"tags":[],"content":"\nCreate a fine-grained personal access token with “Contents” permission to Repositories you have selected.\nConfigure Git to store credentials on disk: git config --global credential.helper store. This stores credentials in plaintext on disk!\nAccess the repo via https with your username and the personal access token as password.\n\n$ git clone github.com/USERNAME/REPO.git\nUsername: YOUR-USERNAME\nPassword: YOUR-PERSONAL-ACCESS-TOKEN\n\nRotate the token before it expires.\n\nReferences\n\nUsing a personal access token on the command line\nRepository permissions for “Contents”\ndocs.github.com/en/get-started/getting-started-with-git/caching-your-github-credentials-in-git\n"},"notes/Cloud/Google-Cloud/Andromeda":{"slug":"notes/Cloud/Google-Cloud/Andromeda","filePath":"notes/Cloud/Google Cloud/Andromeda.md","title":"Andromeda","links":[],"tags":[],"content":"Control plane\nScoped control planes\nThe Andromeda control plane is split into a regionally aware control plane (RACP) and a globally aware control plane (GACP). The RACP programs all intra-region network connectivity, while the GACP manages inter-region connectivity.\nThis approach ensures that intra-region networking in each region is a separate failure domain.\nHoverboard model\nOn the VM host, packets without a matching route goes to Hoverboard gateways, which have forwarding information for all virtual networks.\nOnce a flow exceeds a usage threshold, the Andromeda control plane programs offload flows, which are direct host-to-host flows that bypass the gateways.\n\nUsing gateways for the long tail of low bandwidth flows significantly reduces the number of routes to program on each host, improving scalability by 50x.\nVM host dataplane\n\nFast path\nThe first path in the dataplane is the Fast Path, which is a user-space packet processing path with a per-packet CPU budget of 300 ns.\nThe Fast Path directly accesses both VM virtual NIC and host physical NIC queues via shared memory, bypassing the VMM and host OS to achieve minimal overhead.\nThe Fast Path busy pulls on a dedicated logical CPU. The other logical CPU on the same physical core runs low-CPU control plane work, leaving most of the physical core for Fast Path use. The Fast Path can be scaled to multiple CPUs using multi-queue NICs.\nFast path flow table (FT)\nAll packets pass through the FT for both routing and per-flow packet operations.\nThe FT is a cache of the full vswitchd flow tables. If no match is found, a packet is sent to the Flow Miss Coprocessor, which sends it to vswitchd.\nVM coprocessor\nCPU-intensive work is split to per-VM coprocessors, which enables feature growth without impacting Fast Path performance.\nCoprocessor stages include encryption, DoS and abuse detection, and WAN traffic shaping. CPU time on the coprocessor is attributed to the container of the corresponding VM, providing fairness and isolation between VMs.\nServiceability\nGoogle opted for VM Live Migration to facilitate maintenance, upgrades and placement optimization.\nDuring the migration blackout phase, the VM is paused for a median duration of 65 ms and p99 of 388 ms. After blackout, the VM continues execution and network connections aren’t interrupted.\nReferences\n\nwww.usenix.org/system/files/conference/nsdi18/nsdi18-dalton.pdf\n"},"notes/Cloud/Google-Cloud/Debian-13-upgrade-on-GCP":{"slug":"notes/Cloud/Google-Cloud/Debian-13-upgrade-on-GCP","filePath":"notes/Cloud/Google Cloud/Debian 13 upgrade on GCP.md","title":"Debian 13 upgrade on GCP","links":[],"tags":[],"content":"First, export a copy of the /etc directory on a VM instance freshly created from the image debian-13-trixie-v20251111."},"notes/Cloud/Google-Cloud/GCP-VPC":{"slug":"notes/Cloud/Google-Cloud/GCP-VPC","filePath":"notes/Cloud/Google Cloud/GCP VPC.md","title":"GCP VPC","links":[],"tags":[],"content":"Default firewall actions\n\nEvery network has an implied deny firewall rule for ingress traffic.\nUnless overridden by a higher priority rule, the implied allow rule for egress traffic permits outbound traffic from all instances.\n\nICMP firewall rules\n\nICMP_PROTOCOL: the ICMP protocol type. Specify ICMPv4 by using the protocol name icmp or protocol number 1. Specify ICMPv6 by using protocol number 58.\n\nReferences\n\ncloud.google.com/vpc/docs/vpc#firewall_rules\n"},"notes/Cloud/Google-Cloud/Google-Cloud-Free-Tier":{"slug":"notes/Cloud/Google-Cloud/Google-Cloud-Free-Tier","filePath":"notes/Cloud/Google Cloud/Google Cloud Free Tier.md","title":"Google Cloud Free Tier","links":[],"tags":[],"content":"Creating a Free Tier VM\n\nCreate a VPC and subnet with IPv6 enabled.\nConfigure VPC Firewall.\nCreate Instance Template for reuse.\n\nSelect Debian amd64 image, which avoids Snap from Ubuntu and OOM problems with dnf.\nChange disk type to standard persistent disk.\nSelect e2-micro instance type and one of the Free Tier-eligible regions.\n\n\nCreate instance from template.\n\nSelect “no service account”, unless you need to assign IAM permissions.\nUnselect custom device name of boot disk.\n\n\nEnable “block project-wide SSH keys” and “deletion protection” if you want to.\n\nInstance template\n\nSelect e2-micro machine type.\nChange disk type to standard and size to 30 GB.\nSelect the OS image you want.\nSelect VPC and subnet.\nSelect “IPv4 and IPv6” IP stack.\nIf you prefer not to log in via the console, add SSH keys in Security with one word “comment” as the username.\n\nKEY_VALUE USERNAME\n\nNetwork egress\nThe default is “1 GB of outbound data transfer from North America to all region destinations (excluding China and Australia) per month.” Avoid China and Australia destinations, for example, derp5-all.tailscale.com in Australia.\nTo get 200 GB of free internet data transfer, switch your instance to use the Standard Network Service Tier. Note that Standard tier is not available for IPv6-only or dual-stack instances.\nIf you still want to switch to Standard tier, the guide is available at cloud.google.com/network-tiers/docs/set-network-tier. See cloud.google.com/network-tiers/pricing and cloud.google.com/vpc/network-pricing#tg0-t4 for latest information. This free tier was added in October 2023.\nSwap\n\n\n                  \n                  Caution\n                  \n                \n\nIt isn’t recommended to use RHEL-compatible Linux distributions on an e2-micro instance.\n\n\n1 GB memory isn’t enough for dnf upgrade with many repos (per Bug 1907030). Set up swap space as follows.\nsudo -i\n \numask 077\ndd if=/dev/urandom of=/.swapfile count=4096 bs=1MiB\nmkswap /.swapfile\necho &quot;/.swapfile\tnone\tswap\tsw\t0\t0&quot; &gt;&gt; /etc/fstab\nswapon -a\n \necho &quot;vm.swappiness = 10&quot; &gt; /etc/sysctl.d/90-vm.conf\nsysctl -p /etc/sysctl.d/90-vm.conf\nBefore dnf upgrade, remove unused packages to save time.\ndnf config-manager --disable google-cloud-sdk\ndnf install -y tmux\ntmux\n \nrpm -e google-cloud-sdk"},"notes/Cloud/Google-Cloud/Google-Kubernetes-Engine":{"slug":"notes/Cloud/Google-Cloud/Google-Kubernetes-Engine","filePath":"notes/Cloud/Google Cloud/Google Kubernetes Engine.md","title":"Google Kubernetes Engine","links":[],"tags":[],"content":"Network egress\nBesides container registries, a minimal GKE cluster have the following services that connects to the Internet.\n\nnode-problem-detector.service\ngoogle-guest-agent.service\n\nBootstrap images\nMinimal set of bootstrap images with Dataplane V2.\nImage:         gke.gcr.io/addon-resizer:1.8.18-gke.0\nImage:         gke.gcr.io/cilium/cilium:v1.12.10-gke.25\nImage:         gke.gcr.io/cluster-proportional-autoscaler:1.8.5-gke.0\nImage:         gke.gcr.io/csi-node-driver-registrar:v2.8.0-gke.4\nImage:         gke.gcr.io/gcp-compute-persistent-disk-csi-driver:v1.10.7-gke.0\nImage:         gke.gcr.io/k8s-dns-dnsmasq-nanny:1.22.22-gke.0\nImage:         gke.gcr.io/k8s-dns-kube-dns:1.22.22-gke.0\nImage:         gke.gcr.io/k8s-dns-sidecar:1.22.22-gke.0\nImage:         gke.gcr.io/metrics-server:v0.5.2-gke.3\nImage:         gke.gcr.io/netd-init:v0.6.19-gke-v0.2.5-gke.0\nImage:         gke.gcr.io/netd:v0.6.19-gke-v0.2.5-gke.0\nImage:         gke.gcr.io/proxy-agent:v0.1.3-gke.0\n\nRestrictions\nOn-premises nodes can not join a GKE cluster. Consider GKE on-prem instead."},"notes/Cloud/Google-Cloud/Maglev":{"slug":"notes/Cloud/Google-Cloud/Maglev","filePath":"notes/Cloud/Google Cloud/Maglev.md","title":"Maglev","links":["notes/Network/Direct-Server-Return"],"tags":[],"content":"Architecture overview\nECMP distributes packets for a VIP evenly to Maglev forwarders. Maglev then implements the return path with Direct Server Return, directly sending packets from service endpoint to the edge routers.\nA Maglev cluster can be sharded by serving different sets of VIPs on each shard, which improves scalability and performance isolation between tenants.\n\nMaglev configuration\nMaglev services retrieve configuration objects from local files or remote RPC.\nIn the diagram below, BP stands for backend pool, and represents a set of service endpoints (generally TCP or UDP servers). BPs can include other BPs to simplify configuration of a common set of backends.\nMaglev services\nMaglev runs on commodity Linux servers. It achieves 10Gbps line-rate throughput via kernel bypass, share-nothing architecture and other optimization techniques.\n\nEach Maglev machine contains a controller and a forwarder.\nMaglev controller\nA Maglev controller announces VIPs defined in its config objects, and withdraws all VIP announcements when the forwarder becomes unhealthy. This ensures that routers only forward packets to healthy machines.\nMaglev forwarder\nHealth checking\nEach BP is associated with one or more health checking methods, and health checks are deduplicated by IP to reduce overhead. Only healthy backends are considered for consistent hashing.\nPacket flow\n\nPackets are read by the steering module from the shared packet pool, and distributed to packet (rewriter) threads with 5-tuple hashing.\nPackets are rewritten to be GRE-encapsulated, with the outer IP header destined to the selected backend. Selection is done via connection tracking and consistent hashing.\nRewritten packets are send to TX queues, which are polled by the muxing module and passed to the NIC via the shared packet pool.\n\n\nThe shared packet pool between the NIC and the forwarder means that packets do not need to be copied for transmit or receive. A ring queue of pointers also makes it possible to process packets in batches, further improving efficiency.\n\nConsistent hashing\nMaglev favors even load balancing over minimal disruption during backend changes in its consistent hashing algorithm. Maglev achieves an over-provision factor of less than 1.2 over 60% of time in a production cluster.\nConfig updates are committed atomically, so that consistent hashing input (set of backends) only changes once. Configuration of different machines may be temporarily out of sync, due to the nature of distributed systems.\nConnection tracking\nConnection tracking state is stored locally on each thread of a Maglev machine. It helps when the set of backends change, but is insufficient for the following cases.\n\nWhen the set of Maglev machines changes, the router in front might not provide connection affinity. This behavior is vendor-specific and out of Maglev’s control.\nDuring heavy load or SYN flood attacks, the connection tracking table may be filled and could not track new connections.\n\nIn such cases, consistent hashing is used as a fallback, which is sufficient if backends do not change in the meantime.\nThread optimizations\n\nEach thread is pinned to a dedicated CPU core to achieve maximum performance.\nHash is recomputed on each packet thread to avoid cross-thread synchronization.\n\nReferences\n\nstatic.googleusercontent.com/media/research.google.com/en//pubs/archive/44824.pdf\n"},"notes/Cloud/Google-Cloud/Unexpected-costs-on-GCP":{"slug":"notes/Cloud/Google-Cloud/Unexpected-costs-on-GCP","filePath":"notes/Cloud/Google Cloud/Unexpected costs on GCP.md","title":"Unexpected costs on GCP","links":["notes/Cloud/Google-Cloud/Google-Cloud-Free-Tier","notes/Cloud/Google-Cloud/Google-Kubernetes-Engine"],"tags":[],"content":"Cost analysis\nReports\nGroup by SKU, exclude “Promotions”-type credits, and sort by Subtotal.\nBigQuery\nEnable standard usage cost export to BigQuery, and run the following queries.\n/* List billing data from yesterday excluding those using discounts */\nSELECT *\n  FROM\n    `&lt;project&gt;.&lt;dataset_name&gt;.gcp_billing_export_v1_***` CROSS JOIN UNNEST(credits) AS credit\n  WHERE\n    DATE(_PARTITIONTIME) = DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY) AND\n    cost &gt; 0 AND\n    credit.type &lt;&gt; &quot;DISCOUNT&quot;\n  LIMIT 1000;\n \n/* List *discounted* SKUs and type of discount on a specific day */\nSELECT DISTINCT sku.id, sku.description, credit.type, credit.id, credit.name\n  FROM\n    `&lt;project&gt;.&lt;dataset_name&gt;.gcp_billing_export_v1_***` CROSS JOIN UNNEST(credits) AS credit\n  WHERE\n    TIMESTAMP_TRUNC(_PARTITIONTIME, DAY) = TIMESTAMP(&quot;2023-11-**&quot;) AND\n    cost &gt; 0 AND\n    credit.type = &quot;DISCOUNT&quot;\n  LIMIT 1000;\n \n/* Filter for a specific SKU, return original records */\nSELECT service, sku, usage_start_time, usage_end_time, cost, credits\n  FROM\n    `&lt;project&gt;.&lt;dataset_name&gt;.gcp_billing_export_v1_***`\n  WHERE\n    TIMESTAMP_TRUNC(_PARTITIONTIME, DAY) = TIMESTAMP(&quot;2023-11-**&quot;) AND\n    cost &gt; 0 AND\n    sku.id = &quot;CF4E-A0C7-E3BF&quot;\n  LIMIT 1000;\n \n/* Filter for a specific SKU in a month, return cost per day */\nSELECT TIMESTAMP_TRUNC(_PARTITIONTIME, DAY) AS ts, service.description, sku.description, sum(cost) AS cost\n  FROM\n    `billing-management-400904.all_billing_data.gcp_billing_export_v1_01D2EE_85D75C_0DBFA9`\n  WHERE\n    TIMESTAMP_TRUNC(_PARTITIONTIME, MONTH) = TIMESTAMP(&quot;2023-11-01&quot;) AND\n    sku.id = &quot;D34A-7997-2D03&quot;\n  GROUP BY ts, service.description, sku.description\n  HAVING cost &gt; 0\n  ORDER BY ts ASC\n  LIMIT 1000;\nThe second query shows discounted costs, including the Free Tier discount.\nSee cloud.google.com/bigquery/docs/reference/standard-sql/operators for more SQL operators supported by BigQuery.\nUnexpected costs\nFree Tier\n\nGoogle Kubernetes Engine\n\nZonal Kubernetes Clusters\n\n\nCompute Engine\n\nE2 Instance Core running in XXX\nE2 Instance Ram running in XXX\n\n\n\nCompute Engine’s free tier is applied via transactions with negative cost that cancel out the real transactions.\nNetworking\nPrivate Service Connect (GKE Cluster Endpoint)\n\nNetworking Private Service Connect Partner Select End Point (6882-BFB0-B7E5)\n\n\n100% discount for Networking Private Service Connect Partner Select End Point.\n\n\nNetworking Service Directory Registered Resource (D34A-7997-2D03), 0.10 USD per month\n\n\nAccess services in another VPC network by using Private Service Connect endpoints. You can connect to your own services, or those provided by other service producers, including by Google.\n\nRun gcloud services enable servicedirectory.googleapis.com to enable the required API to inspect the resource.\nService directory registration by GKE is handled regardless of the status of the API. Service name is gk3-*-pe, type is Private Service Connect, namespace is the default goog-psc-default, and endpoint IP is the internal endpoint, which means it is immutable.\nNetwork Intelligence Center\n\nNetwork Intelligence Center Network Analyzer Resource Hours\nNetwork Intelligence Center Internet to Google Cloud Performance Resource Hours\nNetwork Intelligence Center Topology and Google Cloud Performance Resource Hours\n\n\nThe Network Topology and Performance Dashboard modules are available to all users for 100% discount. The cost of these modules will be shown in your billing details, but you will not be charged for them. Any changes to the discount structure will be effective with a 90 days prior notice. The updates to the discount rates will appear in your billing information only after you choose to re-enable the modules.\n\nReferences\n\ncloud.google.com/network-intelligence-center/pricing#network-topology-pricing-details\nwww.googlecloudcommunity.com/gc/Cloud-Hub/How-to-stop-Network-Intelligence-Center-related-SKUs/m-p/515742/highlight/true#M1782\ncloud.google.com/vpc/docs/configure-private-service-connect-services\ncloud.google.com/skus/sku-groups/global-skus\ncloud.google.com/free/docs/free-cloud-features#compute\n"},"notes/Cloud/Oracle-Cloud/OCI-IPv6-address-fix":{"slug":"notes/Cloud/Oracle-Cloud/OCI-IPv6-address-fix","filePath":"notes/Cloud/Oracle Cloud/OCI IPv6 address fix.md","title":"OCI IPv6 address fix","links":[],"tags":[],"content":"Issue\nOn boot, Linux instances can get its IPv6 address, but after lease expires, it is possible to lose the address.\nSolution\nThe Stupid but workable way\nUse a oneshot systemd service to add a static address to the interface.\n[Unit]\nDescription=ensure static IPv6 address\nAfter=network.target\n\n[Service]\nType=oneshot\nExecStart=-/usr/sbin/ip -6 addr add 2603:c024:4506:d46f:c7ad:ddf2:a87b:89dc dev enp0s3\nProtectHome=yes\n\n[Install]\nWantedBy=multi-user.target\n\n[Unit]\nDescription=Run ensure-ipv6-addr daily and on boot\n\n[Timer]\nOnBootSec=15min\nOnUnitActiveSec=1d\n\n[Install]\nWantedBy=timers.target\n\nThe hard way and iSCSI Networking\n\niSCSI boot volumes use the 169.254.0.2/32 address and block volumes use the 169.254.2.0/24 network.\n\nThe default kernel cmdline on Oracle Linux 9 contains netroot=iscsi:169.254.0.2:::1:iqn.2015-02.oracle.boot:uefi, which enables DHCP during early boot.\nFrom journald logs, we can see that the connection is refused on our instance.\ndracut-initqueue[950]: iscsiadm: cannot make connection to 169.254.0.2: Connection refused\ndracut-initqueue[950]: iscsiadm: cannot make connection to 169.254.0.2: Connection refused\ndracut-initqueue[950]: iscsiadm: connection login retries (reopen_max) 5 exceeded\ndracut-initqueue[950]: iscsiadm: Could not perform SendTargets discovery: iSCSI PDU timed out\ndracut-initqueue[887]: Warning: Target discovery to 169.254.0.2:3260 failed with status 0\nThe reason is that the attachement type (Boot volume type) is Paravirtualized, but in this case, IOPS performance is worse than iSCSI attachments. The benefit is that netroot from the cmdline can be removed, and that the VM supports live migration for best availability.\nFor a configuration in /etc/NetworkManager/system-connections to be effective, it must not overlap with configurations in /etc/sysconfig/network-scripts according to default config precedence on Oracle Linux 9, and NetworkManager should not be activated when running from the initial ramdisk.\nA workaround for the latter is to configure allowed-connections for the device, see gitlab.freedesktop.org/NetworkManager/NetworkManager/-/commit/bace14fe1f374db26e49e4e7d61d2fbfce4241cc.\nBy removing netroot from the cmdline, we can regain control of NetworkManager configuration, and set a static IP with nmtui.\nThe formal way\nA workaround was implemented in systemd for this issue.\n\ngithub.com/systemd/systemd/issues/28183\ngithub.com/systemd/systemd/pull/28138\n\nAlso note that we need to have dhcpv6-client in the list of services for the public zone if we are using firewalld. This can be checked with firewall-cmd --list-all, and added with the following commands.\nsudo firewall-cmd --add-service=dhcpv6-client --permanent\nsudo firewall-cmd --reload"},"notes/Cloud/Oracle-Cloud/OCI-link-local-addresses":{"slug":"notes/Cloud/Oracle-Cloud/OCI-link-local-addresses","filePath":"notes/Cloud/Oracle Cloud/OCI link-local addresses.md","title":"OCI link-local addresses","links":[],"tags":[],"content":"\nInstances use link local addresses to access the instance metadata service (169.254.169.254:80), DNS (169.254.169.254:53), NTP (169.254.169.254:123), kernel updates (169.254.0.3), and iSCSI connections to boot volumes (169.254.0.2:3260, 169.254.2.0/24:3260). You can use host-based firewalls, such as iptables, to ensure that only the root user is authorized to access these IPs. Ensure that these operating system firewall rules are not altered.\n\niSCSI\nOracle Linux configures iscsi.service with /var/lib/iscsi/nodes/iqn.2015-02.oracle.boot:uefi/169.254.0.2,3260,1/default.\niscsi then triggers start of iscsid via iscsid.socket.\nReferences\n\ndocs.oracle.com/en-us/iaas/Content/Security/Reference/compute_security.htm\n"},"notes/Cloud/Oracle-Cloud/OCI-network-security-rules":{"slug":"notes/Cloud/Oracle-Cloud/OCI-network-security-rules","filePath":"notes/Cloud/Oracle Cloud/OCI network security rules.md","title":"OCI network security rules","links":[],"tags":[],"content":"Security lists\nSecurity lists let you define a set of security rules that applies to all the VNICs in an entire subnet.\nNetwork Security Groups\nNetwork security groups (NSGs) let you define a set of security rules that applies to a group of VNICs of your choice."},"notes/Cloud/Oracle-Cloud/OCI-public-IP-ranges":{"slug":"notes/Cloud/Oracle-Cloud/OCI-public-IP-ranges","filePath":"notes/Cloud/Oracle Cloud/OCI public IP ranges.md","title":"OCI public IP ranges","links":[],"tags":[],"content":"curl -s docs.oracle.com/en-us/iaas/tools/public_ip_ranges.json | jq -r &#039;.regions[] | select( .region == &quot;xxx&quot;) | .cidrs[].cidr&#039;\n \n# Replace xxx with Region Identifier\n\ndocs.oracle.com/en-us/iaas/Content/General/Concepts/regions.htm\ndocs.oracle.com/en-us/iaas/Content/General/Concepts/addressranges.htm\n"},"notes/Cloud/Oracle-Cloud/OCI-upgrade-VM-to-Oracle-Linux-10":{"slug":"notes/Cloud/Oracle-Cloud/OCI-upgrade-VM-to-Oracle-Linux-10","filePath":"notes/Cloud/Oracle Cloud/OCI upgrade VM to Oracle Linux 10.md","title":"OCI upgrade VM to Oracle Linux 10","links":[],"tags":[],"content":"Preparing\ndocs.oracle.com/en/operating-systems/oracle-linux/10/leapp/leapp-PreparingfortheUpgrade.html\nPrepare a console connection, but do not log in. It’s only used to monitor the progress of the upgrade process.\nOS Management Hub\nIf you have enabled OSMH, make sure to unregister the instance and review your /etc/yum.repos.d files before continuing to ensure future unregistration still works.\n\nWait until the .repo.osmh-backup files are gone before proceeding.\nReview changes made via OSMH and apply them to the restored files as needed.\nDelete /etc/yum.repos.d/osmh.repo to avoid inteference.\n\nAt the moment, OSMH doesn’t support Oracle Linux 10 yet.\nNix\nIf you have nix installed, selinux-autorelabel would run for quite a while on the second reboot during the upgrade process because of the large number of files. It is recommended to remove or at least prune your Nix store before conducting the upgrade.\nUpgrade\ndocs.oracle.com/en/operating-systems/oracle-linux/10/leapp/leapp-UpgradingtheSystem.html\nsudo dnf install -y leapp-upgrade\nsudo leapp preupgrade --oci\n \n# deal with the report and documented issues\n \nsudo leapp upgrade --oci\nsudo reboot\nPostupgrade\n# Edit `/etc/dnf/dnf.conf` by removing or commenting out `exclude=` lines that refer to `leapp` packages.\n# Check packages left from 9 and remove as needed\nrpm -qa | grep el9\nrpm -qa --queryformat &quot;%{NAME}\\n&quot; | grep leapp\n \n# Check for errors\nsudo dnf upgrade\n \n# Restore SELinux\nsudo setenforce enforcing\nsudo sed -i &#039;/^SELINUX=permissive/ s/permissive/enforcing/&#039; /etc/selinux/config\nsudo reboot\n \n# Apply configuration updates\nsudo rpmconf -a # resolve the conflicts\nsudo reboot\n \n# Reconfigure network\nsudo cloud-init clean --configs network\nsudo cloud-init init --local\nls /etc/NetworkManager/system-connections/ # Diff with new config and delete the migrated &#039;System xxx&#039; config\nsudo rm &quot;/etc/NetworkManager/system-connections/System enp0s6.nmconnection&quot;\nsudo reboot # will rotate host SSH key"},"notes/Cloud/Oracle-Cloud/Oracle-Linux-upgrade-to-UEK-8":{"slug":"notes/Cloud/Oracle-Cloud/Oracle-Linux-upgrade-to-UEK-8","filePath":"notes/Cloud/Oracle Cloud/Oracle Linux upgrade to UEK 8.md","title":"Oracle Linux upgrade to UEK 8","links":[],"tags":[],"content":"After release of UEK 8, you may upgrade to the newer kernel on Oracle Linux 9.6 with the following steps:\nSelf-managed\n\nUpdate oraclelinux-release-el9 and check the file /etc/yum.repos.d/uek-ol9.repo.\n\n[ol9_UEKR7]\nname=Oracle Linux 9 UEK Release 7 ($basearch)\nbaseurl=https://yum$ociregion.$ocidomain/repo/OracleLinux/OL9/UEKR7/$basearch/\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\ngpgcheck=1\nenabled=1\n \n[ol9_UEKR8]\nname=Oracle Linux 9 UEK Release 8 ($basearch)\nbaseurl=https://yum$ociregion.$ocidomain/repo/OracleLinux/OL9/UEKR8/$basearch/\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\ngpgcheck=1\nenabled=0\n\nIf ol9_UEKR8 is not enabled, enable it.\n\nsudo dnf config-manager --set-enabled ol9_UEKR8\n\n\nInstall or upgrade kernel-uek to the latest version.\n\nOS Management Hub\n\nIn software sources, add the ol9_uekr8 source for your architecture.\nIn groups, attach the new UEK source and detach the old one.\nIn software sources, delete the old UEK source.\n"},"notes/Cloud/PSaaS/Free-domain-name-providers":{"slug":"notes/Cloud/PSaaS/Free-domain-name-providers","filePath":"notes/Cloud/PSaaS/Free domain name providers.md","title":"Free domain name providers","links":[],"tags":[],"content":"\nnic.us.kg/ (.us.kg)\nwww.netlib.re/ (netlib.re)\n"},"notes/Cloud/PSaaS/Free-email-alias-services":{"slug":"notes/Cloud/PSaaS/Free-email-alias-services","filePath":"notes/Cloud/PSaaS/Free email alias services.md","title":"Free email alias services","links":[],"tags":[],"content":"\nFirefox Relay\nDuckDuckGo email protection\naddy.io\n"},"notes/Cloud/PSaaS/Free-email-sending-service":{"slug":"notes/Cloud/PSaaS/Free-email-sending-service","filePath":"notes/Cloud/PSaaS/Free email sending service.md","title":"Free email sending service","links":["notes/Cloud/PSaaS/SMTP2GO"],"tags":[],"content":"\nSMTP2GO\n"},"notes/Cloud/PSaaS/SMTP2GO":{"slug":"notes/Cloud/PSaaS/SMTP2GO","filePath":"notes/Cloud/PSaaS/SMTP2GO.md","title":"SMTP2GO","links":[],"tags":[],"content":"Slack webhook\nThe Slack integration service at slackbot.smtp2go.com does not accept Email processed events. For this type of events, it returns status code 299 and does not send a notification to your Slack channels."},"notes/Cloud/Self-hosted-IaaS-cloud-platforms":{"slug":"notes/Cloud/Self-hosted-IaaS-cloud-platforms","filePath":"notes/Cloud/Self-hosted IaaS cloud platforms.md","title":"Self-hosted IaaS cloud platforms","links":["notes/Cloud/AWS/AWS-backbone-network"],"tags":[],"content":"OpenStack\nOpenStack is a cloud computing platform that consists of many interrelated components. It’s great at scaling for large-scale deployment, but the platform is too complicated for small-scale deployments.\nIt’s possible to simplify deployment with MicroStack, but the use of snap, LXD and Juju is concerning. Other concerns include requiring un-partitioned disks for cloud storage (Ceph) in multi-node production deployment, and lack of IP address flexibility in single-node deployment.\nApache CloudStack\nApache CloudStack is an Infrastructure-as-a-Service platform that manages and orchestrates pools of storage, network and computing resources to build a public or private compute cloud. It’s a more integrated solution compared to OpenStack.\nThe terms regions and zones are similar to concepts in AWS backbone network. For source NAT support, you have to choose advanced networking for your zones.\nOpenNebula\nOpenNebula is an open source cloud and edge computing platform.\nUbicloud\nUbicloud is a an open source cloud licensed under AGPL-3.0, but some components are licensed under Elastic License 2.0.\nThe VM host must run Ubuntu 22.04 or 24.04, limiting the choice of distributions.\nAs of Jan 2025, Ubicloud still lacks basic features like powering off a VM, resizing a VM, granular firewall rules per VM, backup features like cloning and snapshotting and utilizing secondary network interfaces on the VM host for internal networking IPv4 source NAT is also not supported, so you need extra public IPv4 addresses for static 1:1 NAT.\nAs of Feb 2024, it is clarified that the self-hosted version of Ubicloud is not an immediate area of focus yet. The managed service side needs to be improved first.\nProxmox Virtual Environment\nProxmox VE is a server management platform based on Debian and provides bare-metal ISO installer. It does not support other Linux distributions.\nOxide rack\nRacks assembled by Oxide Computer can run their custom stack of open source software and firmware: github.com/oxidecomputer.\nPaid Solutions\n\nVirtFusion, starting at $1.5 per month for 1 hypervisor.\nVirtkick, starting at $49 per month.\n\nHall of fame\n\nEucalyptus, died in 2021.\n"},"notes/Computer-Science/AWS-CLB-surge-queue-and-Little's-law":{"slug":"notes/Computer-Science/AWS-CLB-surge-queue-and-Little's-law","filePath":"notes/Computer Science/AWS CLB surge queue and Little's law.md","title":"AWS CLB surge queue and Little's law","links":["GPT-4-chat-demo"],"tags":[],"content":"Metrics from a TCP Listener\nSampleCount\n\nSampleCount of RequestCount and Latency metrics are exactly the same as number of requests.\nSampleCount of SurgeQueueLength is roughly number of requests doubled.\nSampleCount of EstimatedProcessedBytes and EstimatedALB* metrics is number of load balancer nodes at 1 minute periods.\nSampleCount of HealthyHostCount and UnHealthyHostCount is a multiple of number of load balancer nodes at 1 minute periods. The multiplier could be one of 18, 60, 66, or some other integer.\n\nConnection Rate\nWhen TCP request rate is stable and no requests fail, sum of EstimatedALBNewConnectionCount should be twice as big as sum of RequestCount, because connections established with both clients and targets are counted towards EstimatedALBNewConnectionCount.\nAverage Waiting Time in Surge Queue\n\n\n                  \n                  Warning\n                  \n                \n\nThis is a thought experiment with GPT-4 chat demo. The resulting formula is based on a false assumption.\n\n\nThe 2 times relationship between SurgeQueueLength samples and number of requests implies that each request triggers 2 samples.\nGiven that the maximum SurgeQueueLength we have observed is the per node limit of 1024, we can assume that each sample only takes the surge queue length of that specific node.\nTherefore, the total SurgeQueueLength of the load balancer should be Avg(SurgeQueueLength) multiplied by the number of nodes, assuming that each node handles the same amount of requests in each period.\nApplying Little’s law to the surge queue, we get\n\\begin{aligned}\nAvg(Latency)\\,s\n&amp;= \\frac{Avg(SurgeQueueLength) * Number\\ of\\ Nodes}{Sum(RequestCount) / Period\\,s}\\\\\n&amp;= \\frac{Avg(SurgeQueueLength) * SampleCount(EstimatedProcessedBytes)}{ Sum(RequestCount) / Period\\,s * Period\\,min}\\\\\n&amp;= \\frac{Avg(SurgeQueueLength) * SampleCount(EstimatedProcessedBytes)}{60 * Sum(RequestCount)}\n\\end{aligned}\nFrom the CloudWatch data we have analyzed, we can assume that ratio of nodes across Availability Zones (AZs) is the same as ratio of HealthyHostCount in each AZ.\nTherefore, to calculate the average latency per AZ, we could use per-AZ metrics and SampleCount of EstimatedProcessedBytes (which is not split by AZ) multiplied by \\frac{SampleCount(HealthyHostCount_{a})}{SampleCount(HealthyHostCount)}.\nThe resulting formula is\n\\begin{aligned}\nAvg(Latency_{a})\\,s\n&amp;= \\frac{Avg(SurgeQueueLength_{a}) * SampleCount(EstimatedProcessedBytes)}{60 * Sum(RequestCount_{a})}\\\\\n&amp;= \\frac{Avg(SurgeQueueLength_{a}) * SampleCount(EstimatedProcessedBytes) * SampleCount(HealthyHostCount_{a})}{60 * Sum(RequestCount_{a}) * SampleCount(HealthyHostCount)}\n\\end{aligned}\n, with the assumption that requests are evenly distributed across nodes.\nThe Real Situation\nRegarding the assumption in the above section, we can see from percentile statistics of EstimatedALBNewConnectionCount that the distribution of connections across nodes is not even nor stable. To get the total SurgeQueueLength, each node’s samples must be normalized to the same weight, which is not possible from summary metrics.\nTo get accurate numbers, you need to enable access logs for your CLB and crunch the *_processing_time numbers."},"notes/Data-lakehouse/Spark-accelerators":{"slug":"notes/Data-lakehouse/Spark-accelerators","filePath":"notes/Data lakehouse/Spark accelerators.md","title":"Spark accelerators","links":[],"tags":[],"content":"Auron\ngithub.com/apache/auron\nSupported Spark versions: 3.0 to 3.5\nDataFusion Comet\ngithub.com/apache/datafusion-comet\nSupported Spark versions: 3.4.3 to 3.5.x"},"notes/Database/Free-PostgreSQL-compatible-PaaS":{"slug":"notes/Database/Free-PostgreSQL-compatible-PaaS","filePath":"notes/Database/Free PostgreSQL-compatible PaaS.md","title":"Free PostgreSQL-compatible PaaS","links":[],"tags":[],"content":"YugabyteDB Aeon\ndocs.yugabyte.com/preview/yugabyte-cloud/cloud-basics/create-clusters/create-clusters-free/#inactive-sandbox-clusters\nLimit of one single node YugabyteDB cluster per account. Free Forever. No credit card information required.\nCluster size:\n\nUp to 2 vCPU, 4 GB memory, 10 GB storage, 3000 disk IOPS\nUp to 500 tables or 12.5 million rows\nUp to 15 simultaneous DB connections\ndata out transfers: free allowance is 10GB per month for every 1 vCPU per month used in a cluster.\n\nInactive database policy:\nSandbox clusters are paused after 10 days of inactivity. When a cluster is paused, you receive an email notification. You need to resume the paused cluster before you can perform any operations on it. If you don’t resume your cluster, a second notification is sent after 13 days of inactivity, notifying you that the cluster will be deleted in 48 hours.\nBackup: no backups.\nPostgreSQL version: 11-compatible.\nv2.25 preview release is 15-compatible. docs.yugabyte.com/preview/develop/pg15-features/\n\nYugabyteDB now supports in-place zero downtime upgrade from a PostgreSQL 11-compatible (v2024.2.2) release to a PostgreSQL 15-compatible (v2.25.1) release.\n\nTiger Data (Tiger Cloud)\nFree plan in Beta:\n\nUp to 2 services\nUp to 750 MB per service\nShared compute\nFeatures: Forks, Logs, Insights\n\nAiven\naiven.io/docs/platform/concepts/free-plan#free-plan-features-and-limitations\naiven.io/docs/platform/concepts/service-power-cycle\n\n1 dedicated VM\n1 CPU per VM\n1 GB RAM per VM\n5 GB total storage\n\nInactive database policy:\n\nFree plans will be automatically powered off if they aren’t actively used.\nServices powered off for more than 180 consecutive days are automatically deleted. A notification is sent before the deletion.\n\nBackup: included, but subject to inactive database policy.\nPostgreSQL version: up to 17\nSupabase\n\n500 MB database size\n\nShared CPU • 500 MB RAM\n\n\n5 GB bandwidth\n1 GB file storage\n200 simultaneous DB connections to pooler in transaction mode without prepared statement support, or 15 in session mode\n\nInactive database policy:\n\nTo save on cloud resources we’re currently pausing free-tier projects that are inactive for more than 7 days.\nPaused Free projects are restorable for 90 days following their pause date.\nOnce a project is no longer restorable, the “restore” option is replaced with an option to download the latest logical backup, taken right before the project is paused, and all Storage objects.\n\nPostgreSQL version: 15\nNote: Supabase documentation states that transaction mode pooler endpoints don’t support prepared statements yet, but supavisor 1.0 has implemented support for it albeit in an inefficient way. What is going on?\nCockroachDB Cloud\nFree for use up to 10 GiB of storage and 50M RUs per organization per month.\nNeon\nneon.tech/docs/introduction/plans#free-plan-allowances\n\nStorage: 0.5 GB-month per project, up to 5 GB total\nCompute: each project gets 100 CU-hours/month, which is NOT enough to run a primary 0.25 CU compute 24/7.\n\n0.25 CU is 0.25 vCPU, 1 GB RAM.\n\n\nData transfer (egress): 5 GB per month\n\nInactive database policy:\nNeon automatically archives branches that are:\n\nOlder than 14 days.\nHave not been accessed for the past 24 hours.\n\nData is never deleted automatically.\nPostgreSQL version: up to 17"},"notes/Database/MariaDB-grant-privileges-via-Unix-socket":{"slug":"notes/Database/MariaDB-grant-privileges-via-Unix-socket","filePath":"notes/Database/MariaDB grant privileges via Unix socket.md","title":"MariaDB grant privileges via Unix socket","links":[],"tags":[],"content":"CREATE USER &#039;phabricator&#039;@&#039;localhost&#039; IDENTIFIED VIA unix_socket;\nGRANT ALL PRIVILEGES ON `phabricator\\_%`.* TO &#039;phabricator&#039;@&#039;localhost&#039;;"},"notes/Database/MongoDB-shell":{"slug":"notes/Database/MongoDB-shell","filePath":"notes/Database/MongoDB shell.md","title":"MongoDB shell","links":[],"tags":[],"content":"show dbs\nuse &lt;database&gt;\nshow collections\nconfig.set(&quot;displayBatchSize&quot;, 3) // limit the number of items returned by a cursor\ndb.&lt;collection&gt;.find()\nReferences\n\nwww.mongodb.com/docs/mongodb-shell/reference/configure-shell-settings-api/#update-number-of-items-returned-by-a-cursor\n"},"notes/Database/MySQL-replication-and-failover-with-Percona-XtraBackup-and-Orchestrator":{"slug":"notes/Database/MySQL-replication-and-failover-with-Percona-XtraBackup-and-Orchestrator","filePath":"notes/Database/MySQL replication and failover with Percona XtraBackup and Orchestrator.md","title":"MySQL replication and failover with Percona XtraBackup and Orchestrator","links":[],"tags":[],"content":"Project links\n\ndocs.percona.com/percona-xtrabackup/8.0/\ngithub.com/percona/orchestrator\n\nSupported database versions\nIf you are using MariaDB 10.3 and later, Percona XtraBackup is not supported and you should follow Mariabackup’s documentation instead. See mariadb.com/kb/en/percona-xtrabackup-overview/#compatibility-with-mariadb.\nAlso note that MariaDB and MySQL have different GTID implementations, and the following guide is only for MySQL 8.0.\nPreparations\n\nEnable log_bin, log_slave_updates (only needed on slave), gtid_mode and enforce_gtid_consistency.\n\n- and - can be used interchangeably in MySQL configuration.\nIf not already enabled, SET @@GLOBAL.ENFORCE_GTID_CONSISTENCY = WARN; first to check if there are any incompatible queries.\nYou can enable gtid_mode online by following this documentation on MySQL 5.7.6 or later: dev.mysql.com/doc/mysql-replication-excerpt/5.7/en/replication-mode-change-online-enable-gtids.html\n\n\nserver_id must be different on master and slave database.\nIf hostname:port read from database configuration is not directly reachable from your orchestrator instance, you may need to configure report_host and report_port to let orchestrator find your instance via &quot;MySQLHostnameResolveMethod&quot;: &quot;@@report_host&quot;.\nBinary log is stored in select @@global.log_bin_basename; which normally reside in the data directory.\nRevoke unused SUPER and CONNECTION_ADMIN privileges and and make sure no one is actively writing data with these privileges.\n\nList all grants with these privileges with SELECT GRANTEE, PRIVILEGE_TYPE FROM INFORMATION_SCHEMA.USER_PRIVILEGES WHERE PRIVILEGE_TYPE IN (&#039;SUPER&#039;, &#039;CONNECTION_ADMIN&#039;); dev.mysql.com/doc/refman/8.0/en/privileges-provided.html#dynamic-privileges-migration-from-super\nSELECT user FROM INFORMATION_SCHEMA.PROCESSLIST; to list active users and their privileges.\nNote that static global privileges like SUPER are unaffected for a connected client. These changes take effect only in sessions for subsequent connections.\nSince MySQL 5.7.8, you could also set UseSuperReadOnly in orchestrator’s config to ensure no one can write data.\n\n\n\n[mysqld]\nserver_id=2\nreport_host=192.168.1.x\nreport_port=3306\n \nlog_bin\nlog_slave_updates\n \ngtid_mode=ON\nenforce-gtid-consistency=ON\nBackup and restore\nPercona XtraBackup and MySQL version must match. For example, use Percona XtraBackup 8.0 for MySQL 8.0 database backup.\nPreparations\n\ndocker pull percona/percona-xtrabackup:8.0.35-32 on both the source and destination servers.\nPrepare the target database, started once with your my.cnf config to make sure it works, then shut it down and empty its data directory.\nCheck database connectivity from source to destination and vice versa for reverse replication.\nMake sure there is sufficient disk space on the source server to keep the binary log files needed for replication.\n\nBackup\n\n\n                  \n                  NOTE\n                  \n                \n\nIf you have custom InnoDB options, you may need to mount the my.cnf config file to /etc/my.cnf in the backup container to let XtraBackup respect them. The following example skips this for brevity.\n\n\n\n\n                  \n                  WARNING\n                  \n                \n\nNote your server’s bandwidth limit, especially if this is a server serving production traffic.\n\n\n# docker will store a copy of container stdout logs, so we are using `docker exec` as a workaround.\ndocker run --name pxb --volumes-from mysqldb --link mysqldb:mysql --rm --user root -d percona/percona-xtrabackup:8.0.35-32 sleep infinity\ndocker exec -it pxb /bin/bash\n \nmicrodnf install nmap-ncat\n \nxtrabackup --backup --stream=xbstream --throttle=4 --datadir=/var/lib/mysql --host=mysql --port=3306 --user=root --password=mysecretpassword | tee &gt;(sha1sum &gt; source_xt_checksum) | nc desthost 9999 &amp;&amp; echo SUCCESS\n \ncat source_xt_checksum\n\n--throttle=4 limits the bandwidth used to 40 MB/s. There are some overhead, so be conservative.\ndocker run -t mixes stdout and stderr, but in our case we are streaming stdout elsewhere, so it’s fine.\nDon’t use stdout of docker run as a pipeline for data. The Docker daemon stores a copy of it, wasting disk I/O and space.\nIf you are using bind mount for the data directory, use that instead of --volumes-from mysqldb.\nWith nmap-ncat, you don’t need to specify -q 5 to let nc terminate the connection automatically upon EOF.\n\nRestore\n# Start a new container and stop it for data recovery\ndocker run -d -p 3306:3306 --name mysqldb -v /path/to/datadir:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=mysecretpassword mysql:8.0\ndocker stop mysqldb\n \n# Receive and prepare the backup\nnc -l 9999 | tee &gt;(sha1sum &gt; destination_checksum) &gt; /path/to/backupdir/backup.xbstream\n \n# Start an interactive shell with xtrabackup CLI\n# NOTE: Destructive commands like `rm -rf` should be ran interactively in the container to discard shell history.\ndocker run -v /path/to/backupdir:/backup -v /path/to/datadir:/var/lib/mysql -it --rm --user root percona/percona-xtrabackup:8.0.35-32 /bin/bash\n \n# Extract\nxbstream -xv -C /backup/20250415 &lt; /backup/backup.xbstream\n# Prepare\nxtrabackup --prepare --target-dir=/backup/20250415\n \n# Restore\nrm -rf /var/lib/mysql/*\n# Use --copy-back --parallel=2 if you have sufficient space and time for doing another copy\nxtrabackup --move-back --datadir=/var/lib/mysql --target-dir=/backup/20250415\nchown -R mysql:mysql /var/lib/mysql/\n \nexit\n \n# Start the database and check its logs\ndocker start mysqldb\ndocker logs -f mysqldb\nReplication\nOn master\nReplace $replicapass with a strong password and 192.168.1.% with your trusted network prefix.\nCREATE USER &#039;repl&#039;@&#039;192.168.1.%&#039; IDENTIFIED BY &#039;$replicapass&#039;;\nGRANT REPLICATION SLAVE ON *.* TO &#039;repl&#039;@&#039;192.168.1.%&#039;;\nOnce replication is properly set up, which you could verify with show slave hosts\\G, you may execute PURGE BINARY LOGS to free some disk space, but don’t use RESET MASTER as it could break replication.\n\nRESET MASTER is not intended to be used while any replicas are running. The behavior of RESET MASTER when used while replicas are running is undefined (and thus unsupported), whereas PURGE BINARY LOGS may be safely used while replicas are running.\n\nOn slave\n-- Set read_only\nset @@global.read_only=on; -- Updates form clients who have the SUPER privilege are exempted, but you should avoid doing that during replication.\n \n-- Check Executed_Gtid_Set\nshow master status\\G\n-- Only execute these if gtid does not match and you have confidence that data is not corrupt.\nRESET MASTER;\nSET @@global.gtid_purged=&#039;&lt;gtid_string_found_in_xtrabackup_binlog_info&gt;&#039;;\n \n-- Needed if source was a replica\nRESET SLAVE ALL;\n \n-- Set up replication\nCHANGE MASTER TO\nMASTER_HOST = &#039;...&#039;,\nMASTER_PORT = ...,\nMASTER_USER = &#039;...&#039;,\nMASTER_PASSWORD = &#039;...&#039;,\nMASTER_AUTO_POSITION=1,\nGET_MASTER_PUBLIC_KEY=1;\nstart slave;\n \nshow slave status\\G\nshow warnings\\G\n \nshow processlist\\G -- run on both master and slave DB\nshow slave hosts\\G -- run on master only\nNote that if the caching_sha2_password authentication plugin is used on master, you need to add GET_MASTER_PUBLIC_KEY=1 to the CHANGE MASTER TO statement.\nOrchestrator\nFirst, follow github.com/percona/orchestrator/blob/master/docs/install.md to set up a backend MySQL server for orchestrator.\nAlternatively, you could use SQLite as the backend database for orchestrator. Make a copy of conf/orchestrator-sample-sqlite.conf.json and configure relevant fields as follows.\n{\n  // Backend DB\n  &quot;BackendDB&quot;: &quot;sqlite&quot;,\n  &quot;SQLite3DataFile&quot;: &quot;/path/to/orchestrator.sqlite3&quot;,\n \n  // Security\n  &quot;AuthenticationMethod&quot;: &quot;basic&quot;,\n  &quot;HTTPAuthUser&quot;: &quot;dba_team&quot;,\n  &quot;HTTPAuthPassword&quot;: &quot;xxxxx&quot;, // replace it with a strong password\n \n  // Discovery\n  &quot;MySQLHostnameResolveMethod&quot;: &quot;@@report_host&quot;,\n \n  // Replication\n  &quot;UseSuperReadOnly&quot;: true,\n}\nFor databases in the topology, grant privileges on the master and let it propagate through replication. Change orch_topology_password to a strong password and orch_host to the host running orchestrator.\nCREATE USER &#039;orchestrator&#039;@&#039;orch_host&#039; IDENTIFIED BY &#039;orch_topology_password&#039;;\nGRANT SUPER, PROCESS, REPLICATION SLAVE, RELOAD ON *.* TO &#039;orchestrator&#039;@&#039;orch_host&#039;;\nGRANT SELECT ON mysql.slave_master_info TO &#039;orchestrator&#039;@&#039;orch_host&#039;;\nGRANT SELECT ON ndbinfo.processes TO &#039;orchestrator&#039;@&#039;orch_host&#039;; -- Only for NDB Cluster\nFLUSH PRIVILEGES;\nGraceful master promotion\ngithub.com/percona/orchestrator/blob/master/docs/topology-recovery.md#graceful-master-promotion\n\nIn a graceful takeover:\n\neither the user or orchestrator choose an existing replica as the designated new master.\norchestrator ensures the designated replica takes over its siblings as intermediate master\norchestrator turns the master to be read-only (possibly also super-read-only)\norchestrator makes sure your designated server is caught up with replication.\norchestrator promotes your designated server as the new master.\norchestrator turns promoted server to be writable.\norchestrator demotes the old master and places it as a direct replica of the new master\nif possible, orchestrator sets replication user/password for the demoted master\nin the graceful-master-takeover-auto variant (see following), orchestrator starts replication on demoted master.\n\nThe operation can take a few seconds, during which time your app is expected to complain, seeing that the master is read-only.\nInvoke graceful takeover via:\n\nWeb interface: drag a direct master’s replica onto the left half of the master’s box. The web interface uses the graceful-master-takeover variation; the replication on demoted master will not kick in.\n\n\nSafety notes:\n\nsuper-read-only is used if UseSuperReadOnly is set in orchestrator config.\nOnce the server has advertised itself as --read-only, MySQL blocks ongoing transactions’ COMMIT from completing.\n\nOperation procedure:\n\nMake sure replication lag is within an acceptable range.\nDrag the replica to the starting point, and drop when it says “PROMOTE AS MASTER”.\nConfirm the dialog.\n\nAfter it stabilizes, the now-replica database should be in read-only mode and have an empty Slave_SQL_Running_State in show slave status\\G.\nYou could start replication in the reverse direction with start slave; on the now-replica database, and downtime status of the database shown on orchestrator will end automatically.\nAutomated recovery of master failure\nRecoverMasterClusterFilters and RecoverIntermediateMasterClusterFilters controls auto-recovery. In the example configuration files, auto-recovery is disabled with a pattern that you would not normally use in production.\nManual master promotion\nWith the slave caught up to near-instant, set master to read-only.\nset @@global.read_only=on;\nCompare Executed_Gtid_Set from show master status\\G on the master and show slave status\\G on the slave. If they match, stop replication and disable read_only mode on slave.\n-- on slave DB\nstop slave;\nset @@global.read_only=off;\nClients can now connect to the then-slave DB, which is acting as the master now.\nReferences\n\ndocs.percona.com/percona-xtrabackup/8.0/create-gtid-replica.html\ndocs.percona.com/percona-xtrabackup/8.0/set-up-replication.html\nwww.percona.com/blog/super_read_only-gtid-replication/\ngithub.com/percona/orchestrator/blob/master/docs/topology-recovery.md#requirements\ngithub.com/percona/orchestrator/blob/master/docs/security.md\ndev.mysql.com/doc/refman/8.0/en/reset-master.html\ndev.mysql.com/doc/refman/8.4/en/replication-howto-repuser.html\n"},"notes/Database/PgBouncer":{"slug":"notes/Database/PgBouncer","filePath":"notes/Database/PgBouncer.md","title":"PgBouncer","links":[],"tags":[],"content":"Authentication\n\nThe passwords or secrets stored in the authentication file serve two purposes. First, they are used to verify the passwords of incoming client connections, if a password-based authentication method is configured. Second, they are used as the passwords for outgoing connections to the backend server, if the backend server requires password-based authentication (unless the password is specified directly in the database’s connection string). The latter works if the password is stored in plain text or MD5-hashed. SCRAM secrets can only be used for logging into a server if the client authentication also uses SCRAM, the PgBouncer database definition does not specify a user name, and the SCRAM secrets are identical in PgBouncer and the PostgreSQL server (same salt and iterations, not merely the same password). This is due to an inherent security property of SCRAM: The stored SCRAM secret cannot by itself be used for deriving login credentials.\n\nPrepared statements in transaction pooling mode\nPgBouncer 1.21.0 added support for protocol-level named prepared statements.\nSee github.com/pgbouncer/pgbouncer/pull/845 and github.com/postgresml/pgcat/pull/474 (PgCat).\nMonitoring\ngithub.com/prometheus-community/pgbouncer_exporter\nConnect to the reserved pgbouncer database, that is, the admin console, as the stat_collector user with configured password or TLS authentication credentials.\nRequired configuration\nstats_users = stat_collector\nignore_startup_parameters = extra_float_digits\nDefault connection string\npostgres://postgres:@localhost:6543/pgbouncer?sslmode=disable\n\nBuilding from source\nBesides the dependencies listed in README, you also need to install autoconf, automake and libtool to run autogen.sh if building from a Git repo clone."},"notes/Database/Pigsty-notes":{"slug":"notes/Database/Pigsty-notes","filePath":"notes/Database/Pigsty notes.md","title":"Pigsty notes","links":[],"tags":[],"content":"Unattended upgrades\nOn Ubuntu, it’s recommended to disable unattended-upgrades to avoid unexpected database restarts.\nPostgreSQL instance parameter tuning\nYou may increase pg_max_conn as needed, but no more than 5000 unless you are prepared to bump HAProxy limits as well and face issues that Azure decided not to deal with in their Azure Database for PostgreSQL product. If possible, add more read replicas and optimize your queries instead of that.\nYou may also want to adjust WAL size settings in github.com/pgsty/pigsty/blob/v3.7.0/roles/pgsql/templates/olap.yml#L317-L319. The defaults could be wasteful.\nSingle-instance PgBouncer bottleneck\nSee github.com/pgsty/pigsty/issues/500.\nNode DNS and /etc/hosts modifications\nTo prevent such modifications, set\nnode_write_etc_hosts: false\nnode_dns_method: none\nin global vars section of pigsty.yml.\nBash history\nroles/node/files/node.sh sets\nexport HISTSIZE=65535\nexport HISTFILESIZE=$HISTSIZE\nexport HISTCONTROL=ignoredups\nexport HISTIGNORE=&quot;l:ls:cd:cd -:pwd:exit:date:* --help&quot;\nwhich means ls, cd and xxx --help commands will not be recorded in bash history.\nDefault user for psql\n\nPigsty creates ~/.pigsty on the admin node with this content:\n\nexport PGUSER=dbuser_dba\nexport PGDATABASE=postgres\n(from roles/infra/templates/env/pigsty.j2)\n\nThis file is sourced in ~/.bashrc:\n\n[ -f ~/.pigsty ] &amp;&amp; . ~/.pigsty\n(configured in roles/infra/tasks/env.yml)\n\nPassword is stored in ~/.pgpass with entries for dbuser_dba, so no password prompt is needed.\n\nTherefore, if you are running psql as the ansible_user during Pigsty setup, you will log in as dbuser_dba automatically.\nIf you use sudo -u postgres psql instead, you would log in as postgres via local peer authentication. Both are superuser, but the default parameters could be different.\nCustomize psqlrc\n.psqlrc under the postgres user’s home directory defines\n\\set PROMPT1 &#039;%[%033[0;31;31m%]%n@%`hostname`:%&gt;/%/=%#%[%033[0m%] &#039;\n\\set PROMPT2 &#039;%[%033[0;31;31m%]%/%R%#%[%033[0m%] &#039;\nand a set of utility meta-commands that could be invoked via SQL Interpolation:\n-- Check database sizes\n:dbsize\n\n-- View active connections\n:conninfo\n\n-- Find slow queries\n:slowquery\n\n-- Check for lock conflicts\n:locks\n\n-- Find bloated tables\n:tablebloat\n\nBackup multi-processing (fixed in v4.0)\n\nHow can I configure options independently for each command? pgbackrest.org/faq.html#optimize-config\npgBackRest has the ability to set options independently in the configuration file for each command. Configure Cluster Stanza details this feature as well as option precedence.\nFor example, the process-max option can be optimized for each command: …\n\nYou could configure [global:backup] for parallel backups. For example, min(node_cpu / 2, 4):\ndiff --git a/roles/pgsql/templates/pgbackrest.conf b/roles/pgsql/templates/pgbackrest.conf\nindex d714d2c..0b17551 100644\n--- a/roles/pgsql/templates/pgbackrest.conf\n+++ b/roles/pgsql/templates/pgbackrest.conf\n@@ -94,6 +94,9 @@ archive-mode=off\n #--------------------------------------------------------------#\n # 10. adhoc (parallel)                                         #\n #--------------------------------------------------------------#\n+[global:backup]\n+process-max={{ ([(node_cpu|int / 2)|round(0,&#039;ceil&#039;), 4])|min|int }}\n+\n [global:restore]\n process-max={{ node_cpu|int }}\n \nOptimistically, this should reduce full backup time significantly, but be careful scaling up further and monitor CPU, disk and network limits and exhaustion.\nOffline single-node install\ncurl -fLo /tmp/pkg.tgz &#039;github.com/pgsty/pigsty/releases/download/v3.7.0/pigsty-pkg-v3.7.0.u24.aarch64.tgz&#039;\n./bootstrap -k\n./configure\nThen modify pigsty.yml to use local repo because the default is to use the infra node at http://${admin_ip}/pigsty:\nnode_repo_modules: local # use pre-made local repo rather than install from upstream\nrepo_upstream:\n  - { name: pigsty-local ,description: &#039;Pigsty Local&#039; ,module: local ,releases: [24] ,arch: [aarch64] ,baseurl: { default: &#039;file:/www/pigsty/ ./&#039; }}\nNote that only the latest PostgreSQL packages are included in the offline package downloaded from GitHub releases, so you are on your own if you need an older version.\nUseful dashboards\n\nPGCAT Instance (session breakdown)\nPGCAT Database\nPGSQL Tables (tuples changed)\nPGRDS Cluster\nPGRDS Instance\nPGSQL Persist\nPGSQL PITR (backups)\n\nOther notes:\n\nPGCAT data are not bound by the time range selected on a dashboard. Reset the statistics with:\n\nSELECT monitor.pg_stat_statements_reset();\n\nThe PGCAT Schema dashboard may default to a random schema with no data, and treemap panels like those in the Bloat row will say “Configure your query” as if it’s not configured. This is by design and cannot be fixed.\nThe Column Stat table in PGCAT Table will not display for tables dbuser_monitor doesn’t have SELECT privilege on. Because the dbuser_monitor user doesn’t have the BYPASSRLS attribute, this also includes any table with RLS enabled.\n\nSync Grafana dashboards from source\n# dashboard_sync copies dashboards to /infra/dashboards/ for dashboard_init to read\n./infra.yml -t dashboard_sync,dashboard_init\nInstalling extensions\n\n\n                  \n                  NOTE\n                  \n                \n\npgsql-feat, etc. already includes a lot of extensions. Check for duplicates before adding more to the pg_extensions list.\n\n\nFor example, install hypopg on the monitor schema:\nCREATE EXTENSION &quot;hypopg&quot; WITH SCHEMA &quot;monitor&quot;;\nBytebase demo\n--- pigsty.yml.old\t2026-02-02 00:10:24.639422176 +0000\n+++ pigsty.yml\t2026-02-02 00:12:48.349472796 +0000\n@@ -23,6 +23,25 @@\n     etcd:  { hosts: { 127.0.0.1: { etcd_seq: 1  }} ,vars: { etcd_cluster: etcd  }}\n     pgsql: { hosts: { 127.0.0.1: { pg_seq: 1, pg_role: primary  }} ,vars: { pg_cluster: pgsql }}\n     #minio: { hosts: { 127.0.0.1: { minio_seq: 1 }} ,vars: { minio_cluster: minio }}\n+    app:\n+      hosts: { 127.0.0.1: {} }\n+      vars:\n+        docker_enabled: true                # enabled docker with ./docker.yml\n+        #docker_registry_mirrors: [&quot;docker.1panel.live&quot;,&quot;docker.1ms.run&quot;,&quot;docker.xuanyuan.me&quot;,&quot;registry-1.docker.io&quot;]\n+        app: bytebase                       # specify the default app name to be installed (in the apps)\n+        apps:                               # define all applications, appname: definition\n+\n+          # Admin GUI for PostgreSQL, launch with: ./app.yml\n+          pgadmin:                          # pgadmin app definition (app/pgadmin -&gt; /opt/pgadmin)\n+            conf:                           # override /opt/pgadmin/.env\n+              PGADMIN_DEFAULT_EMAIL: admin@pigsty.cc   # default user name\n+              PGADMIN_DEFAULT_PASSWORD: pigsty         # default password\n+\n+          # Schema Migration GUI for PostgreSQL, launch with: ./app.yml -e app=bytebase\n+          bytebase:\n+            conf:\n+              BB_DOMAIN: ddl.pigsty  # replace it with your public domain name and postgres database url\n+              BB_PGURL: &quot;postgresql://dbuser_bytebase:&lt;CHANGE ME&gt;@127.0.0.1:5432/bytebase?sslmode=prefer&quot;\n \n   vars:\n \n@@ -35,6 +54,7 @@\n     dns_enabled: false                # disable dnsmasq service on single node\n     infra_portal:\n       home : { domain: i.pigsty }\n+      bytebase  : { domain: ddl.pigsty ,endpoint: &quot;${admin_ip}:8887&quot; }\n     proxy_env:                        # global proxy env when downloading packages\n       no_proxy: &quot;localhost,127.0.0.1,10.0.0.0/8,192.168.0.0/16,*.pigsty,*.aliyun.com,mirrors.*,*.myqcloud.com,*.tsinghua.edu.cn&quot;\n       # http_proxy:  # set your proxy here: e.g http://user:pass@proxy.xxx.com\n@@ -68,8 +88,10 @@\n     pg_users:\n       - { name: dbuser_meta ,password: &lt;25-character random characters&gt;   ,pgbouncer: true ,roles: [dbrole_admin   ] ,comment: pigsty admin user }\n       - { name: dbuser_view ,password: &lt;25-character random characters&gt; ,pgbouncer: true ,roles: [dbrole_readonly] ,comment: read-only viewer  }\n+      - { name: dbuser_bytebase ,password: &lt;CHANGE ME&gt; ,pgbouncer: true ,roles: [dbrole_admin] ,comment: admin user for bytebase database   }\n     pg_databases:\n       - { name: meta, baseline: cmdb.sql ,comment: pigsty meta database ,schemas: [pigsty] ,extensions: [ postgis, timescaledb, vector ]}\n+      - { name: bytebase ,owner: dbuser_bytebase ,revokeconn: true ,comment: bytebase primary database }\n     pg_libs: &#039;timescaledb, pg_stat_statements, auto_explain, pg_wait_sampling&#039;\n     pg_hba_rules:\n       - { user: all ,db: all ,addr: intra ,auth: pwd ,title: &#039;everyone intranet access with password&#039; ,order: 800 }\n \nGeneral PostgreSQL notes\nVacuuming\n\n\nYou may increase autovacuum_freeze_max_age to avoid the emergency vacuum kicking in too often. Often 500 million or 1 billion is fine.\n\n\nYou can use the vacuumdb command instead of SQL commands. There is no effective difference between vacuuming and analyzing databases via this utility and via other methods for accessing the server, but --jobs comes in handy.\n\n\nvacuumdb --all --freeze --jobs=2 --echo --analyze\n\nYou can log into template1 to fix it if you want, but you won’t be able to log into template0. template0 can safely be ignored and let run to autovacuum_freeze_max_age since it’s extremely small and will finish nearly instantaneously. – Keith Fiske\n\nRead-only role for AI analysis\nCREATE ROLE xxx LOGIN BYPASSRLS ROLE dbrole_readonly PASSWORD &#039;your secret password&#039;;\n \nALTER ROLE xxx SET search_path TO &quot;\\$user&quot;, public, extensions;\nALTER ROLE xxx SET default_transaction_read_only = on;\nALTER ROLE xxx SET statement_timeout = &#039;1min&#039;;\nEXPLAIN in pgAdmin 4 query tool\n\nMake sure you have selected “Costs” in the dropdown menu. It applies to explain too.\nFor explain analyze, also select “Timing”.\n\nReferences\n\ngithub.com/pgsty/pigsty/blob/v3.7.0/roles/node_id/vars/u24.aarch64.yml#L40\n"},"notes/Database/PostgREST":{"slug":"notes/Database/PostgREST","filePath":"notes/Database/PostgREST.md","title":"PostgREST","links":[],"tags":[],"content":"Caching with nginx\nYou can use headers to specify the range of rows in PostgREST, but it doesn’t work with proxy_cache enabled in nginx:\n\nIf caching is enabled, the header fields “If-Modified-Since”, “If-Unmodified-Since”, “If-None-Match”, “If-Match”, “Range”, and “If-Range” from the original request are not passed to the proxied server.\n\nA potentially valid configuration for anonymous requests only:\nproxy_cache your_cache;\nproxy_cache_valid 200 1h;\nproxy_cache_method GET;\nproxy_cache_convert_head off;\nproxy_cache_key &quot;...&quot;; # lots of headers that may affect results\nproxy_cache_bypass $http_authorization $http_range;"},"notes/Database/PostgreSQL-and-psql-trivia-commands":{"slug":"notes/Database/PostgreSQL-and-psql-trivia-commands","filePath":"notes/Database/PostgreSQL and psql trivia commands.md","title":"PostgreSQL and psql trivia commands","links":[],"tags":[],"content":"Expanded mode\nSELECT * FROM storage.objects LIMIT 4\\gx\n\nCreate user and table\nCREATE ROLE salesapp WITH LOGIN PASSWORD &#039;your_password&#039;;\nCREATE DATABASE sales OWNER salesapp;\n \n-- if the user doesn&#039;t have SET ROLE permission\nCREATE ROLE salesapp WITH LOGIN PASSWORD &#039;your_password&#039; CREATEDB;\n-- and then CREATE DATABASE as the new role\nAdministrator guide\nFull export\nPGPASSWORD=&quot;...&quot; pg_dumpall -f xxx_full.sql -d &#039;postgresql://user@...&#039;\nWrite output to file\n\\o xxx.txt\n...\n \n-- restore to stdout\n\\o\nExport DB schema\npg_dump --schema-only --dbname \nSELECT * FROM supabase_functions.migrations;\n"},"notes/Database/PostgreSQL-in-disaggregated-architecture":{"slug":"notes/Database/PostgreSQL-in-disaggregated-architecture","filePath":"notes/Database/PostgreSQL in disaggregated architecture.md","title":"PostgreSQL in disaggregated architecture","links":[],"tags":[],"content":"\nAurora Serverless v2 docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.how-it-works.html\nAlloyDB for PostgreSQL cloud.google.com/alloydb/docs/overview\nNeon github.com/neondatabase/neon\nOrioleDB (WIP) www.orioledb.com/docs/usage/decoupled-storage\n"},"notes/Database/PostgreSQL-logical-replication":{"slug":"notes/Database/PostgreSQL-logical-replication","filePath":"notes/Database/PostgreSQL logical replication.md","title":"PostgreSQL logical replication","links":[],"tags":[],"content":"www.postgresql.org/docs/15/logical-replication-architecture.html\n\nLogical replication starts by copying a snapshot of the data on the publisher database. Once that is done, changes on the publisher are sent to the subscriber as they occur in real time. The subscriber applies data in the order in which commits were made on the publisher so that transactional consistency is guaranteed for the publications within any single subscription.\n"},"notes/Database/PostgreSQL-software-stack":{"slug":"notes/Database/PostgreSQL-software-stack","filePath":"notes/Database/PostgreSQL software stack.md","title":"PostgreSQL software stack","links":[],"tags":[],"content":"Postgres HA\n\nrepmgr\npg_auto_failover\nPatroni\nStolon\nEDB Failover Manager (EFM)\nEDB Postgres Distributed (PGD)\nBucardo\n\nConnection pooler\n\nPGBouncer\nPgPool-II\nPgDog\nOdyssey\nProxySQL\nSupavisor\n\nBackup solutions\n\nBarman\npgBackRest\nWAL-G\npg_probackup\n"},"notes/Database/Supabase-on-Pigsty-modifications":{"slug":"notes/Database/Supabase-on-Pigsty-modifications","filePath":"notes/Database/Supabase on Pigsty modifications.md","title":"Supabase on Pigsty modifications","links":[],"tags":[],"content":"Caveats\n\nPostgREST performance worsen with more than 16 CPU cores. To be safe, you should use 8-16 threads or less by setting GHCRTS=&quot;-N&lt;x&gt;&quot; in environment variables and run multiple instances to sustain high throughput. (This may have improved lately.)\n\n\nThe numbers still don’t improve on 32, 48, 64 cores but now they maintain. Also not sure if there’s something else wrong with my benchmark setup in those. github.com/PostgREST/postgrest/issues/2294\n\n\n-N ⟨x⟩. Use ⟨x⟩ simultaneous threads when running the program. ghc.gitlab.haskell.org/ghc/doc/users_guide/using-concurrent.html#rts-flag-N-x\n\n\ngithub.com/Kong/kong/issues/3058\n\ndiff --git a/app/supabase/docker-compose.yml b/app/supabase/docker-compose.yml\nindex e46ba4a8..f393d22b 100644\n--- a/app/supabase/docker-compose.yml\n+++ b/app/supabase/docker-compose.yml\n@@ -77,6 +77,8 @@ services:\n     environment:\n       KONG_DATABASE: &quot;off&quot;\n       KONG_DECLARATIVE_CONFIG: /home/kong/kong.yml\n+      KONG_DNS_VALID_TTL: 10\n+      KONG_DNS_STALE_TTL: 3600\n       # github.com/supabase/cli/issues/14\n       KONG_DNS_ORDER: LAST,A,CNAME\n       KONG_PLUGINS: request-transformer,cors,key-auth,acl,basic-auth,request-termination,ip-restriction\n@@ -161,13 +163,15 @@ services:\n   #--------------------------------------------------------------#\n   # supabase.com/docs/guides/getting-started/architecture#postgrest-api\n   rest:\n-    container_name: supabase-rest\n     image: postgrest/postgrest:v13.0.7\n     restart: unless-stopped\n+    deploy:\n+      replicas: 3\n     depends_on:\n       analytics:\n         condition: service_healthy\n     environment:\n+      GHCRTS: &quot;-N8&quot;\n       PGRST_DB_URI: postgres://authenticator:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}\n       PGRST_DB_SCHEMAS: ${PGRST_DB_SCHEMAS}\n       PGRST_DB_ANON_ROLE: anon\ndiff --git a/app/supabase/volumes/api/kong.yml b/app/supabase/volumes/api/kong.yml\nindex 673aa6db..2bd28ddc 100644\n--- a/app/supabase/volumes/api/kong.yml\n+++ b/app/supabase/volumes/api/kong.yml\n@@ -30,6 +30,16 @@ basicauth_credentials:\n     username: $DASHBOARD_USERNAME\n     password: $DASHBOARD_PASSWORD\n \n+###\n+### Upstreams for load balancing\n+###\n+upstreams:\n+  - name: rest-upstream\n+    algorithm: least-connections\n+    targets:\n+      - target: rest:3000\n+        weight: 100\n+\n ###\n ### API Routes\n ###\n@@ -87,7 +97,7 @@ services:\n   ## Secure REST routes\n   - name: rest-v1\n     _comment: &#039;PostgREST: /rest/v1/* -&gt; http://rest:3000/*&#039;\n-    url: http://rest:3000/\n+    url: http://rest-upstream/\n     routes:\n       - name: rest-v1-all\n         strip_path: true\n@@ -108,7 +118,7 @@ services:\n   ## Secure GraphQL routes\n   - name: graphql-v1\n     _comment: &#039;PostgREST: /graphql/v1/* -&gt; http://rest:3000/rpc/graphql&#039;\n-    url: http://rest:3000/rpc/graphql\n+    url: http://rest-upstream/rpc/graphql\n     routes:\n       - name: graphql-v1-all\n         strip_path: true\n@@ -280,4 +290,4 @@ services:\n       - name: cors\n       - name: basic-auth\n         config:\n-          hide_credentials: true\n\\ No newline at end of file\n+          hide_credentials: true\n \n\nPostgREST’s db-pool (PGRST_DB_POOL) size defaults to 10, which should be increased as necessary per docs.postgrest.org/en/v12/references/connection_pool.html#acquisition-timeout.\nsupabase/storage is written in Node.js and can only saturate 1 CPU core. You need multiple if it becomes a bottleneck.\nIn high throughput scenarios with 10,000 or more RPS, you may need to increase connection reuse in Kong as documented in developer.konghq.com/gateway/performance/optimize/.\nPublishable and secret keys are only available on the Supabase hosted platform. supabase.com/docs/guides/api/api-keys\n\nSetup process\nBased on v3.6.1:\n[Download] ===========================================\n[ OK ] version = v3.6.1 (from default)\ncurl -fSL repo.pigsty.io/src/pigsty-v3.6.1.tgz -o /tmp/pigsty-v3.6.1.tgz\n################################################################################ 100.0%\n[ OK ] md5sums = 083d8680fa48e9fec3c3fcf481d25d2f  /tmp/pigsty-v3.6.1.tgz\n[Install] ===========================================\n[ OK ] install = /home/ubuntu/pigsty, from /tmp/pigsty-v3.6.1.tgz\n\nbash get\ncd ~/pigsty\n./configure -c supabase\npatch -p1 &lt; ...\n\nRemove vector container in Supabase self-hosted docker compose stack. You should collect logs elsewhere.\n\nPreferably also remove the analytics container to save yourself from the supa-kick cron job.\n\n\nRemove unused timescaledb extension.\nDisable promtail and loki. (Now VictoriaLogs and Vector in v4.0)\nLeave DNS alone with node_dns_method: none. Supabase has its hosts entries set in Docker specs.\n\nAnd /etc/hosts with node_write_etc_hosts: false if you don’t need to self-host MinIO.\n\n\nComment out PKI files in .gitignore to manage them via Git.\n"},"notes/Database/Verify-TLS-Certificate-in-psql-session":{"slug":"notes/Database/Verify-TLS-Certificate-in-psql-session","filePath":"notes/Database/Verify TLS Certificate in psql session.md","title":"Verify TLS Certificate in psql session","links":[],"tags":[],"content":"Append ssl* arguments to the connection string like so.\npsql &#039;postgres://...?sslmode=verify-full&amp;sslrootcert=system&#039;\n"},"notes/Database/Workaround-\"permission-denied-for-schema-auth\"-on-Supabase":{"slug":"notes/Database/Workaround-\"permission-denied-for-schema-auth\"-on-Supabase","filePath":"notes/Database/Workaround \"permission denied for schema auth\" on Supabase.md","title":"Workaround \"permission denied for schema auth\" on Supabase","links":[],"tags":[],"content":"The auth schema is protected and only accessible via the postgres role, so we can’t directly grant the permissions:\npostgres=&gt; GRANT USAGE ON SCHEMA auth TO your_role;\nWARNING:  no privileges were granted for &quot;auth&quot;\nGRANT\nAnd even if the schema grant succeeded, some tables are also protected from GRANT SELECT:\npostgres=&gt; GRANT SELECT ON ALL TABLES IN SCHEMA auth TO your_role;\nWARNING:  no privileges were granted for &quot;oauth_consents&quot;\nWARNING:  no privileges were granted for &quot;oauth_clients&quot;\nWARNING:  no privileges were granted for &quot;oauth_authorizations&quot;\nWARNING:  no privileges were granted for &quot;oauth_client_states&quot;\nGRANT\nSolution\nInstead, you could use PostgreSQL’s role inheritance to workaround the limitations at the cost of granting a broader permission:\nGRANT postgres TO your_role;"},"notes/Economics/Economics-in-China":{"slug":"notes/Economics/Economics-in-China","filePath":"notes/Economics/Economics in China.md","title":"Economics in China","links":[],"tags":[],"content":"2010\nExcerpt translated from github.com/shengcaishizhan/kkndme_tianya.\nEconomics\n\nHigh inflation and continuous depreciation of currency are determined by the state-owned economic system, which cannot be changed in a short time frame.\nThe state-owned economic system determines that\n\nGovernment administrative costs are high.\nEconomics is overly reliant on government investment.\nCost of corruption is astonishingly high.\nExport of low value-added products generates foreign exchange earnings, generating large amounts of cash flowing into market, causing inflation.\n\n\nHolding idle cash is risky, more than holding any preservable goods or assets.\nDemand for assets like bicycles, cars and houses absorbs excessive cash, which ensures commoners has to keep working hard to fight inflation, ensuring stability and prosperity of the society.\nCurrency is designed to exploit commoners via inflation.\nThe government expects property price to rise slowly and steadily, absorbing inflation pressure.\n\nInflation\n\nEmployee wages within the system grows with inflation. Those out of the system are dependent on profitability of their industry and company.\n\nMaintaining Stability\n\nThe bottom line is to ensure food security, i.e. ensuring availability of affordable food.\nTo control food pricing, cash must flow into other assets, especially property.\nPoor people buying properties with mortgage imposes risks to the financial system.\n\nProperty Rights\n\nProperty rights include the right to use (live in) the property and ownership.\nCost of living is reflected in rental prices, not in ownership.\nIt’s the ownership price that absorbs excessive cash, not rental price. Therefore rent-to-sale ratio scales with amount of excessive cash. With large amount of cash issued, rent-to-sale ratio becomes lower.\nResidential land has a lease of 70 years. Houses with 40 or 50 year lease has many disadvantages, including more expensive infrastructure cost (water, electricity, etc.)\n\n”Land Finance”\n\nValue of real estate in China is composed of the house itself and the right to use the land it is built on.\nIndividuals or organizations only have the right to own properties and use the land through ownership and usage rights.\n\nProperty Price\n\nHousing prices are not determined by the average income (e.g. as reported by the National Bureau of Statistics), but rather by the average income of the elite, because:\n\nThe pyramid structure of China society implies that even if only 10% of the population resides at the top, it still constitutes an enormous number of over 100 million people, much higher than the sum of most Western countries.\nOnly the relationship between supply and demand determines the price of a commodity.\nCommodity housing in the center of a first-or-second-tier city is sufficiently scarce for the elite population. For example, some elites in Beijing could easily invest millions in cash to buy houses.\n\n\nValue of property is determined by population, cash (demand) and its position (limited supply).\nEven if property price “falls”, it will be falling relative to other commodity price, not on its absolute value.\nDon’t worry about price fluctuation of properties bought for living. Buy it if you can.\nLong-term investment of property is relatively secure. Short-term trading still has high risk.\nWhen inflation outruns mortgage interest, long-term mortgage is profitable.\nHong Kong has the highest property pricing in China, because land there is very scarce.\n\nProperty Tax\n\nCost of property will eventually be passed on to tenants, including any tax imposed.\n\nDemolition\n\nEventually, most old houses will be demolished to build new ones.\nDemolition brings city growth.\nLow-density, short buildings are more likely to be demolished.\nTwo ways to compensate demolition: Cash compensation and Resettlement.\n\nPolitics\n\nDriven by vested interests, the development of society is inevitably shaped by those who hold power. Even if policies go against the interests of the ruling class, they will likely be difficult to enforce, with few consequences for those who fail to comply. In the end, such policies often end up as empty promises that are never fully realized.\nPRC is ruled by people, not laws. Therefore, it’s not a capitalism country.\n\nCorruption\nFrom a made-up magazine story:\n\n宇文泰以治国之道问苏绰，二人闭门密谈。\n宇文泰问曰：国何以立？\n苏绰曰：具官。\n问：何为具官？\n曰：用贪官，反贪官。\n问：既是贪官，如何能用？\n曰：为臣者，以忠为大。臣忠则君安。然，臣无利则臣不忠。但官多财寡，奈何？\n问：奈何？\n曰：君授权与之官，使官以权谋利，官必喜。\n问：善。虽官得其利，然寡人所得何在？\n曰：官之利，乃君权所授，权之所在，利之所在也，是以官必忠。官忠则江山万世可期。\n叹曰：善！然则，既用贪官，又罢贪官，何故？\n曰：贪官必用，又必弃之，此乃权术之密奥也。\n宇文泰移席，谦恭求教曰：先生教我！\n苏绰大笑：天下无不贪之官。贪，何所惧？所惧者不忠也。凡不忠者，必为异己，以罢贪官之名，排除异己，则内可安枕，外得民心，何乐而不为？此其一。其二，官若贪，君必知之，君既知，则官必恐，官愈恐则愈忠，是以罢弃贪官，乃驭官之术也。若不用贪官，何以弃贪官？是以必用又必弃之也。倘若国中皆清廉之官，民必喜，则君必危矣。\n问：何故？\n曰：清官以清廉为恃，直言强项，犯上非忠，君以何名罢弃之？罢弃清官，则民不喜，不喜则生怨，生怨则国危，是以清官不可用也。\n宇文泰大喜。\n苏绰厉声曰：君尚有问乎？\n宇文泰大惊，曰：尚……尚有乎？\n苏绰复厉色问曰：所用者皆为贪官，民怨沸腾，何如？\n宇文泰汗下，再移席，匍匐问计。\n苏绰笑曰：下旨斥之可也。一而再，再而三，斥其贪婪，恨其无状，使朝野皆知君之恨，使草民皆知君之明，坏法度者，贪官也，国之不国，非君之过，乃贪官之过也，如此则民怨可消。\n又问：果有大贪，且民怨愤极者，何如？\n曰：杀之可也。抄其家，没其财，如是则民怨息，颂声起，收贿财，又何乐而不为？要而言之：用贪官，以结其忠；罢贪官，以排异己；杀大贪，以平民愤；没其财，以充宫用。此乃千古帝王之术也。\n"},"notes/Emacs/CIDER":{"slug":"notes/Emacs/CIDER","filePath":"notes/Emacs/CIDER.md","title":"CIDER","links":[],"tags":["clojure","emacs"],"content":"Starting the REPL\nStart the REPL with cider-jack-in, before evaluating any Clojure expressions.\nBasic evaluation\nLoad the buffer with cider-load-buffer (C-c C-k), and execute the top level form under point with cider-eval-defun-at-point (C-c C-c). To eval top level forms inside comment forms with C-c C-c, set clojure-ts-toplevel-inside-comment-form or clojure-toplevel-inside-comment-form to t respectively.\nC-x C-e evaluates the form preceding point. You can also use C-c C-e which binds to the same command cider-eval-last-sexp.\nC-u C-c C-c prefixes the form with #dbg, recursively inserting breakpoints to everything inside it. #break instead just places one breakpoint in front of the form.\nOnce you drop into the CIDER debugger, check out docs.cider.mx/cider/debugging/debugger.html#keys for the commands and keys available. Notably, there are:\n\nn, i and o. Step next, in, or out.\nh. Skip all sexps up to “here” (current position).\nc. Continue till next breakpoint.\nC. Continue without stopping.\nq. Quit the debugger.\ne. Eval code in current context.\np, P and l. Inspect the current value, an arbitrary expression, or local variables.\n\nInspector\nTo inspect the eval result, run cider-inspect-last-result (SPC m i r in Doom).\nIn the inspector view, use cider-inspector-pop (L in evil mode) to return to last view, and cider-inspector-next-inspectable-object (type ] ] or g j in evil mode) to jump to next inspectable object. Use cider-inspector-next-page (C-j) to jump between pages if there are too many items.\nCheatsheet\n\nM-x cider-cheatsheet-select opens minibuffer to search the cheatsheet.\n\nRefactoring (Hydra shortcut)\nhydra-cljr-help-menu (SPC m R in Doom) is a Hydra menu for quick consecutive refactoring.\n\nn am adds missing libspec. It searches cljr-magic-require-namespaces for aliases.\np ap adds project dependency. Requires existing :deps key in deps.edn.\n\n{:deps {}}\nReferences\n\ngithub.com/clojure-emacs/clj-refactor.el/blob/dc1bbc8cdaa723bdbb6669ea7d280625c370755d/clj-refactor.el#L93-L101\ndocs.cider.mx/cider/usage/misc_features.html\n"},"notes/Emacs/Emacs-Features":{"slug":"notes/Emacs/Emacs-Features","filePath":"notes/Emacs/Emacs Features.md","title":"Emacs Features","links":[],"tags":[],"content":"\n\nPut a call to provide at the end of each separate Lisp file.\n\n\n\nprovide and require are an alternative to autoload for loading files automatically. They work in terms of named features. Autoloading is triggered by calling a specific function, but a feature is loaded the first time another program asks for it by name.\n\nUse of require ensures that the file is only be loaded once.\nEmacs Lisp files are searched from the load path.\nReferences\n\nwww.gnu.org/software/emacs/manual/html_node/elisp/Named-Features.html\nwww.gnu.org/software/emacs/manual/html_node/elisp/Coding-Conventions.html\nwww.gnu.org/software/emacs/manual/html_node/emacs/Lisp-Libraries.html\n"},"notes/Emacs/Emacs-Frame-Setup":{"slug":"notes/Emacs/Emacs-Frame-Setup","filePath":"notes/Emacs/Emacs Frame Setup.md","title":"Emacs Frame Setup","links":[],"tags":["emacs"],"content":"Fullscreen by default\n(add-to-list &#039;default-frame-alist &#039;(fullscreen . maximized))"},"notes/Emacs/Telegra":{"slug":"notes/Emacs/Telegra","filePath":"notes/Emacs/Telegra.md","title":"Telegra","links":[],"tags":[],"content":"Cheatsheet\nEvil mode keybindings\nRoot buffer:\n\ns, telega-filter-map. u for unread, m for mention, / for reset, f for folder, t for type, s for search,\n\na for Interactively select a Chat filter to add to active filter,\ne for Edit and reapply filters list.\ni for “important”. Defaults to mentions and unmuted chats with unread messages or reactions.\n\n\nC, telega-chat-create. Interactively create new chat.\n\nChat buffer, also known as chatbuf:\n\nZa, telega-chatbuf-attach. Attach anything, including stickers.\nZf, telega-chatbuf-attach-media. Attach FILENAME as media.\nZv, telega-chatbuf-attach-clipboard. Attach clipboard to the chatbuf as photo. Requires an image in clipboard.\nzz, telega-chatbuf-recenter-1. Recenter message at point.\nM-x telega-msg-remove-text-spoiler. Remove text spoiler. Sometimes you can use &lt;RET&gt;.\n\nImage view in chatbuf:\n\n{, telega-image-prev. Show previous image in chat.\n}, telega-image-next. Show next image in chat.\n\ng A for chatbuf navigation:\n\nu, telega-chatbuf-next-unread. Goto next unread message in the chatbuf.\n&gt; or r, telega-chatbuf-read-all. Jump to the last message and mark all messages as read.\n@ or m, telega-chatbuf-next-unread-mention. Goto next unread mention or search for most recent mention before message at point.\n!, telega-chatbuf-next-unread-reaction. Goto next unread reaction in chatbuf.\no, telega-chatbuf-next-outgoing. Goto next outgoing (sent by you) message or search for last outgoing message.\n^ or P, telega-chatbuf-goto-pinned-message. Go backwards to last pinned message for the chatbuffer. If not found, go to the latest pinned message. Note: it remembers the last pinned message viewed and searches from there, outliving the chatbuf’s lifetime.\ns, telega-chatbuf-inplace-search. Search backward in the chatbuf. If C-u is given, then search forward instead.\n\ng a for Telegra prefix map:\n\nt, telega. Switch to root buffer.\nb, telega-switch-buffer. Interactively switch to an opened CHAT’s buffer.\nc, telega-chat-with. Start messaging with CHAT-OR-USER.\ns, telega-saved-messages. Switch to “Saved Messages” chatbuf.\nu, telega-switch-unread-chat. Switch to next unread message in next unread CHAT. Press again to highlight the unread message.\n\nOn message at point:\n\n!, telega-msg-add-reaction. Add reaction to MSG.\ni, telega-msg-edit. Start editing the MSG.\n&lt;tab&gt;, telega-button-forward. Move forward or backward (&lt;backtab&gt;) to next visible/active button.\nT, telega-msg-open-thread-or-topic.\n\nMSG could be a channel post, in this case open thread in the discussion group.\nOr MSG could be in supergroup, then filter messages to the corresponding thread or topic.\n\n\n\nCommon keys:\n\ng?, telega-describe-*. Show info about various items, e.g. USER, CHAT and MSG.\nq. Quit window.\n\nIn chatbuf, you may need to use C-u q to force close window.\nThis is because after a\n\npop-to-buffer (telega-chat--pop-to-buffer and telega-msg-open-thread-or-topic) or\npop-to-buffer-same-window (telega-webpage--instant-view and telega-image-view-file) call\n\n\nand returning from the pop up,\nthe quit-restore window parameter is reset to nil from (same (#&lt;buffer *Telega Root*&gt; 1 #&lt;marker at 582 in *Telega Root*&gt; 198) #&lt;window 3 on ◀ [redacted]&gt; #&lt;buffer ◀ [redacted]&gt;), where #&lt;buffer *Telega Root*&gt; is the prev-buffer that quit-window was supposed to display.\nTo workaround this, bind q to a workaround function in both maps of telega-chat-mode.\nHow to modify key bindings in chatbuf:\n\nevil-collection-set-readonly-bindings binds q in telega-msg-button-map to #&#039;quit-window.\ntelega-chat-mode’s keybindings are a combination of telega-msg-button-map and telega-chat-mode-map. The former takes precedence when a chat message is focused.\nTherefore, both maps needs to be modified.\n\n\n\n\n\nMessage bindings (cursor on message):\n\\\\{telega-msg-button-map}\nGlobal chat bindings:\n\\\\{telega-chat-mode-map}&quot;\n\nCompletion\n\ntelega-company-username, backend to complete username. Start with @.\ntelega-company-hashtag, backend to complete hashtag. Start with #.\ntelega-company-emoji, backend to complete emojis. For stickers, use Za.\ntelega-company-botcmd, backend to complete bot commands. Only completes in a bot chatbuf.\n\nDirectories\n\ntelega-cache-dir, Directory for telegram downloads.\n\nGetting Started\nInstalling Telega on macOS\n\nInstall the Symbola font and configure unicode-fonts with Apple Color Emoji.\n\n(after! unicode-fonts (push &quot;Apple Color Emoji&quot; (cadr (assoc &quot;Supplemental Symbols and Pictographs&quot; unicode-fonts-block-font-mapping))))\n\nInstall dependencies with MacPorts. Optional dependencies are\n\nqrencode for log in.\npngpaste for pasting image from clipboard.\n\n\n\nsudo port install tdlib qrencode pngpaste\n\nConfigure telega-server library prefix for tdlib.\n\n(setq telega-server-libs-prefix &quot;/opt/local&quot;)"},"notes/Emacs/autoload":{"slug":"notes/Emacs/autoload","filePath":"notes/Emacs/autoload.md","title":"autoload","links":[],"tags":[],"content":"Magic autoload comment\n\nA magic autoload comment (often called an autoload cookie) consists of ;;;###autoload, on a line by itself, just before the real definition of the function in its autoload-able source file. The function loaddefs-generate writes a corresponding autoload call into loaddefs.el. Building Emacs loads loaddefs.el and thus calls autoload.\n\nExample:\n;;;###autoload\n(define-derived-mode ini-mode prog-mode &quot;ini&quot;\n  &quot;Major mode for editing Windows-style ini files.&quot;\n  (setq font-lock-defaults &#039;(ini-font-lock-keywords nil)))\nSame line magic\n\nYou can also use a magic comment to execute a form at build time without executing it when the file itself is loaded. To do this, write the form on the same line as the magic comment. Since it is in a comment, it does nothing when you load the source file; but loaddefs-generate copies it to loaddefs.el, where it is executed while building Emacs.\n\nExample:\n;;;###autoload(add-to-list &#039;auto-mode-alist &#039;(&quot;\\\\.ini\\\\&#039;&quot; . ini-mode))\nautoload function\nOutside of Emacs itself, Doom modules and package.el-managed packages, the magic comment ;;;###autoload doesn’t work by default.\nIn your local Emacs Lisp files, you should use the autoload function directly, or import it with use-package by configuring :load-path to load a local package and use :commands (including :hook, :bind, :mode, etc.) to let use-package handle autoload for you.\nReferences\n\nwww.gnu.org/software/emacs/manual/html_node/elisp/Autoload.html\ngithub.com/doomemacs/doomemacs/issues/1213#issuecomment-468970403\ngithub.com/emacs-mirror/emacs/blob/e81e625ab895f1bd3c5263f5b66251db0fd38bd6/lisp/emacs-lisp/package.el#L813\ngithub.com/doomemacs/doomemacs/blob/986398504d09e585c7d1a8d73a6394024fe6f164/lisp/lib/autoloads.el#L160\n"},"notes/Emacs/doom/Consult":{"slug":"notes/Emacs/doom/Consult","filePath":"notes/Emacs/doom/Consult.md","title":"Consult","links":[],"tags":[],"content":"Asynchronous search\ngithub.com/minad/consult#asynchronous-search\nDoom Emacs uses the perl splitting style, which splits the input string at a punctuation character and treats each as an Emacs regular expression, so special characters like $ has to be escaped.\nTo avoid such splitting, add a backslash (\\) before spaces.\nSecond filter\n\nConsult splits the input string into two parts, if the first character is a punctuation character, like #. For example #regexps#filter-string, is split at the second #.\nThe filter-string is passed to the fast Emacs filtering to further narrow down the list of matches.\n\nNegation operator\n40 !404 searches for 40, but excludes candidates containing 403.\nSearch in file type\nArguments after -- is passed to rg. For example,\n#regexps -- -g *.go -g !*_test.go\n\nWorkaround searching for whitespace character\n#use[\\ ] -- -g *.php\n"},"notes/Emacs/doom/Dhall":{"slug":"notes/Emacs/doom/Dhall","filePath":"notes/Emacs/doom/Dhall.md","title":"Dhall","links":[],"tags":[],"content":"Run dhall-freeze as early as possible, because dhall-mode re-evaluates the buffer on each change."},"notes/Emacs/doom/Doom-CLI":{"slug":"notes/Emacs/doom/Doom-CLI","filePath":"notes/Emacs/doom/Doom CLI.md","title":"Doom CLI","links":[],"tags":[],"content":"Commands\nWhen you need to force a full byte-compile, for example after upgrading Emacs:\ndoom sync --rebuild\nWhen your need to reclaim some disk space occupied by .emacs.d:\ndoom gc"},"notes/Emacs/doom/Eglot":{"slug":"notes/Emacs/doom/Eglot","filePath":"notes/Emacs/doom/Eglot.md","title":"Eglot","links":[],"tags":[],"content":"Debugging\nDoom does not support Debug Adapter Protocol (DAP) debuggers with +eglot yet.\nYou can use github.com/svaante/dape instead."},"notes/Emacs/doom/Embark":{"slug":"notes/Emacs/doom/Embark","filePath":"notes/Emacs/doom/Embark.md","title":"Embark","links":[],"tags":[],"content":"Start with SPC a or C-;.\nSource\ngithub.com/oantolin/embark"},"notes/Emacs/doom/Evil-collection":{"slug":"notes/Emacs/doom/Evil-collection","filePath":"notes/Emacs/doom/Evil-collection.md","title":"Evil-collection","links":["notes/Emacs/doom/Magit"],"tags":[],"content":"Info key bindings\n\nu, Info-up: go to the superior node of this node.\ng1 - g9, gm, gt, gT: same as regular Info key bindings without evil.\ngj, gk: Info-next and Info-prev, same as n and p in regular Info key bindings.\n\nCalc key bindings\nNote: the key bindings from evil-collection are very broken, so keybindings shown here are the original with evil-collection disabled.\n(after !evil\n  (remove-hook &#039;evil-collection-init #&#039;calc-mode))\n \n;; Alternatively, use `set-evil-initial-state!&#039;, which includes (after! evil ...).\n(set-evil-initial-state! #&#039;calc-mode &#039;emacs)\n\nq, calc-quit: exit Calc mode and close its windows.\nC-x * 0, calc-reset: reset Calc to its initial state. It does not erase the values of any variables.\nC-x * b, calc-big-or-small: Toggle full screen Calc. Use before C-x * c, that is M-x calc.\nU, D: calc-undo and calc-redo.\nt y: yank a number from trail to the stack.\nt ], calc-trail-last: reset the trail pointer to the last entry.\nt p, t n: move the trail pointer to previous or next entry.\ny, calc-copy-to-buffer: Copy the top of stack into an editing buffer.\nd 6: Display numbers in hex.\n\nMagit key bindings\nevil-collection-magit-use-y-for-yank\n\nreplace “y” for magit-show-refs with “yy” for evil-collection-magit-yank-whole-line, “ys” for magit-copy-section-value, “yb” for magit-copy-buffer-revision and “yr” for magit-show-refs. This keeps “y” for magit-show-refs, in the help popup (magit-dispatch).\n\nevil-collection-magit-use-z-for-folds\nWhen non nil (default in Doom), use “z” as a prefix for common vim fold commands, such as\n\nz1 Reset visibility to level 1 for all sections\nz2 Reset visibility to level 2 for all sections\nz3 Reset visibility to level 3 for all sections\nz4 Reset visibility to level 4 for all sections\nza Toggle a section\nzo Show section\nzO Show sections recursively\nzc Hide section\nzC Hide sections recursively\nzr Same as z4.\n\nActivate additional evil-collection-MODULE\n(after! mpdel\n  (add-transient-hook! &#039;mpdel-mode\n    (+evil-collection-init &#039;mpdel)))"},"notes/Emacs/doom/Evil":{"slug":"notes/Emacs/doom/Evil","filePath":"notes/Emacs/doom/Evil.md","title":"Evil","links":["notes/CLI/Vim"],"tags":[],"content":"yank forward\ny f SPC doesn’t yank the space character with evil-snipe-override-mode. See github.com/hlissner/evil-snipe/issues/86.\n(remove-hook &#039;doom-first-input-hook #&#039;evil-snipe-override-mode)\nCommands\nRepeat last change: .\nRepeat last substitute: &amp;\nComment lines: g c N j (comment or uncomment N lines below, defined by motion N j)\nAdd comment at end of line with space: M-; (press a afterwards to start writing)\nText objects\nSee Text Objects.\nEx-commands\nClose buffer: :bd (or use C-w d)\nKey bindings\nQuick jump in current line:\n\nIn motion state, type s and the two characters to search for (S searches backwards, and type s repeatedly to jump to next match in visible buffer)\nIn operator state, that is, waiting state after typing y, d, etc.: z and Z\n\nEasyMotion:\n\ng s s and two characters: highlight all occurrences of the two letters as jump locations.\ng s / or g s SPC and any characters combo quickly: when the idle timer expires a list of jump locations matching the combo are shown.\ng s a / g s A: jump forward or backward in the same lexical scope, such as a block.\ng s * or g s #: search for the word under cursor, forward or backward.\n\nEmbrace:\n\nS in visual state. For example, S {: make selection a new {} block.\ny s i s {: quote sentence with {, i w is a Text Objects. Use } to not insert spaces surrounding the text object.\nd s &quot;: remove &quot; quotes.\nc s &quot; &#039;: change &quot; quoted string to &#039;. As a special case, tag &lt;q&gt; can be typed as a replacement.\n"},"notes/Emacs/doom/Font-face-attribute-override":{"slug":"notes/Emacs/doom/Font-face-attribute-override","filePath":"notes/Emacs/doom/Font face attribute override.md","title":"Font face attribute override","links":[],"tags":[],"content":"Override the default set by tree-sitter.\n(after! tree-sitter\n  (set-face-attribute &#039;tree-sitter-hl-face:property nil :slant &#039;normal))\nReferences\n\ngithub.com/emacs-tree-sitter/elisp-tree-sitter/discussions/130\n"},"notes/Emacs/doom/Font":{"slug":"notes/Emacs/doom/Font","filePath":"notes/Emacs/doom/Font.md","title":"Font","links":[],"tags":[],"content":"(setq doom-font (font-spec :family &quot;Cascadia Mono PL&quot; :size 12 :weight &#039;semi-light))"},"notes/Emacs/doom/How-to-bump-a-package":{"slug":"notes/Emacs/doom/How-to-bump-a-package","filePath":"notes/Emacs/doom/How to bump a package.md","title":"How to bump a package","links":[],"tags":[],"content":"Automatic bump functions\ndoom/bump-package: bump by package name.\ndoom/bump-module: bump whole module, can select entire category or individual modules.\ndoom/commit-bumps: pre-fill magit commit for staged changes. You need to stage your changes first.\nHow to contribute (manual)\n\nMake the commit hash changes.\nEnter the magit buffer with SPC g g.\nStage the changes.\nSPC : and run doom/bumpify-diff. Alternatively, run doom/commit-bumps instead of step 4 and 5.\nc c and paste the commit message with p.\nTest updates with ~/.emacs.d/bin/doom upgrade -p.\n"},"notes/Emacs/doom/Init":{"slug":"notes/Emacs/doom/Init","filePath":"notes/Emacs/doom/Init.md","title":"Init","links":[],"tags":[],"content":"Enabled Modules\n:ui\nindent-guides\n\n:emacs\nibuffer\n\n:term\nvterm\n\n:checkers\n(spell +flyspell)\n\n:tools\n(lookup +docsets +dictionary)\nlsp\nmagit\n"},"notes/Emacs/doom/Jumper":{"slug":"notes/Emacs/doom/Jumper","filePath":"notes/Emacs/doom/Jumper.md","title":"Jumper","links":[],"tags":[],"content":"Natural jumper\n;; Add to config.el\n(after! better-jumper\n  (setq better-jumper-add-jump-behavior &#039;replace))"},"notes/Emacs/doom/Leader-Key":{"slug":"notes/Emacs/doom/Leader-Key","filePath":"notes/Emacs/doom/Leader Key.md","title":"Leader Key","links":[],"tags":[],"content":"Define new key bindings with leader key prefix\n(map! :leader\n      (:prefix (&quot;o&quot; . &quot;open&quot;)\n       :desc &quot;elfeed&quot; &quot;e&quot; #&#039;=rss))\nRemap leader keys\nChange alt key bindings:\n;; Add to config.el\n(setq doom-leader-alt-key &quot;C-SPC&quot;\n      doom-localleader-alt-key &quot;C-SPC m&quot;)\nTop-level key bindings\nPop up scratch buffer: SPC x"},"notes/Emacs/doom/Lookup":{"slug":"notes/Emacs/doom/Lookup","filePath":"notes/Emacs/doom/Lookup.md","title":"Lookup","links":[],"tags":[],"content":"Open URLs\ng f (+lookup/file) works for URLs too.\nDocsets\nDash docsets need to be associated with major modes. Most :lang modules have this already.\n(set-docsets! &#039;tcl-mode &quot;Tcl&quot;)"},"notes/Emacs/doom/Magit":{"slug":"notes/Emacs/doom/Magit","filePath":"notes/Emacs/doom/Magit.md","title":"Magit","links":[],"tags":[],"content":"Navigation\nmagit-section-backward-sibling ([) and magit-section-forward-sibling (]).\nLine-wrap\n$ is mapped to magit-process-buffer, so it’s hard to jump to end of line.\nUse SPC t w to enable line wrapping.\nCommit message\nFinish or cancel editing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nActionKeyFinishC-c C-c, ZZCancelC-c C-k, ZQ\nCommit message ring\nBoth finished and cancelled messages are saved to a ring that persists until Emacs is closed. Use M-p and M-n to navigate older messages in any edit session."},"notes/Emacs/doom/Mpdel":{"slug":"notes/Emacs/doom/Mpdel","filePath":"notes/Emacs/doom/Mpdel.md","title":"Mpdel","links":[],"tags":[],"content":"(use-package! mpdel\n  :config\n  (+evil-collection-init &#039;mpdel)\n  (map! :leader\n        :desc &quot;MPDel&quot; &quot;Z&quot; mpdel-core-map))"},"notes/Emacs/doom/Org-roam-v2":{"slug":"notes/Emacs/doom/Org-roam-v2","filePath":"notes/Emacs/doom/Org-roam v2.md","title":"Org-roam v2","links":[],"tags":[],"content":"Config\n;; in config.el\n(setq org-roam-directory &quot;~/org-roam/&quot;)\n \n(after! org-roam\n  (setq +org-roam-auto-backlinks-buffer t))\norg-roam-protocol\nFollow the Org-roam user manual to create an AppleScript application. Then save the following as a bookmarklet in Firefox:\njavascript:location.href =\n    &#039;org-protocol://roam-ref?template=r&amp;ref=&#039;\n    + encodeURIComponent(location.href)\n    + &#039;&amp;title=&#039;\n    + encodeURIComponent(document.title)"},"notes/Emacs/doom/ParEdit":{"slug":"notes/Emacs/doom/ParEdit","filePath":"notes/Emacs/doom/ParEdit.md","title":"ParEdit","links":[],"tags":[],"content":"Why doesn’t Doom package ParEdit?\nFrom Doom’s FAQs\n\nWhy are there no default keybinds for Smartparens (for evil users)?\nDoom only uses smartparens to manage pair “completion” (it does the job better than electric-{pair,quote}-mode or the multitude of other pair-management solutions in the Emacs ecosystem at the time of writing).\nNone of smartparen’s commands have default keybinds for evil users because they are redundant with motions and text-objects provided by evil/vim. If you disagree, I recommend trying the :editor lispy or :editor parinfer modules.\n\nBut if you insist on using ParEdit in Doom, read on.\nInstall\nAdd following code to packages.el or enable clojure in :lang of init.el.\n(package! paredit :pin &quot;...&quot;)\nConfiguration\nAdd following code to config.el and restart Emacs.\n(autoload &#039;enable-paredit-mode &quot;paredit&quot; &quot;Turn on pseudo-structural editing of Lisp code.&quot; t)\n(add-hook! &#039;(emacs-lisp-mode-hook clojure-mode-hook) #&#039;enable-paredit-mode)\nKey bindings\nparedit-{backward,forward}-slurp-sexp (C-( and C-)) pulls new elements in from either side and paredit-{backward,forward}-barf-sexp (C-{ and C-}) pushes elements away."},"notes/Emacs/doom/Projectile":{"slug":"notes/Emacs/doom/Projectile","filePath":"notes/Emacs/doom/Projectile.md","title":"Projectile","links":["notes/Emacs/doom/wgrep"],"tags":[],"content":"Projects\nBroadly speaking, Projectile identifies projects like this:\n\nDirectories that contain the special .projectile file\nDirectories under version control (e.g. a Git repo)\nDirectories that contain some project description file (e.g. a Gemfile for Ruby projects or pom.xml for Java maven-based projects)\n\nProject-wide actions\n\nFind file: SPC p f\n\nInvalidate cache: SPC p i\n\n\nSave all: SPC p s\nProject-wide search and replace\n"},"notes/Emacs/doom/Rime":{"slug":"notes/Emacs/doom/Rime","filePath":"notes/Emacs/doom/Rime.md","title":"Rime","links":[],"tags":[],"content":"Setup\n;; Add to packages.el\n(package! pyim :disable t)\n(package! rime)\n;; Add to config.el\n(use-package! rime\n  :after-call after-find-file pre-command-hook\n  :init\n  (setq rime-emacs-module-header-root &quot;/Applications/MacPorts/Emacs.app/Contents/Resources/include&quot;\n        rime-librime-root &quot;/opt/local&quot;)\n  :config\n  (setq rime-show-candidate &#039;popup\n        rime-disable-predicates\n        &#039;(rime-predicate-evil-mode-p\n          rime-predicate-prog-in-code-p)\n        default-input-method &quot;rime&quot;))"},"notes/Emacs/doom/Straight":{"slug":"notes/Emacs/doom/Straight","filePath":"notes/Emacs/doom/Straight.md","title":"Straight","links":[],"tags":[],"content":"\nOut of the box, you can install any package listed on MELPA, GNU ELPA, or Emacsmirror, which is to say any package in existence. (Although MELPA is used as a package listing, packages are installed by cloning their Git repositories rather than by downloading tarballs like package.el does.)\n\nMost of the time you don’t need to specify a :recipe."},"notes/Emacs/doom/Undo":{"slug":"notes/Emacs/doom/Undo","filePath":"notes/Emacs/doom/Undo.md","title":"Undo","links":[],"tags":[],"content":"Disable undo history persistence\n;; Add in config.el\n(remove-hook &#039;undo-fu-mode-hook #&#039;global-undo-fu-session-mode)"},"notes/Emacs/doom/Vertico":{"slug":"notes/Emacs/doom/Vertico","filePath":"notes/Emacs/doom/Vertico.md","title":"Vertico","links":["notes/Emacs/doom/Consult","notes/Emacs/doom/Embark"],"tags":[],"content":"Key bindings in minibuffer\nPreview: C-SPC for +vertico/embark-preview\nNext &amp; previous history: M-p and M-n\nPage up &amp; down: C-S-j and C-S-k (C-S- does not work in tty)\nNext &amp; previous group: C-M-j (also TAB) and C-M-k\nNext &amp; previous row: C-j and C-k\nExit with input: M-RET (vertico-exit-input) or RET (exit-minibuffer)\nKey bindings in minibuffer input\nInsert selection to minibuffer (eval expression, M-x, or ex-command, i.e. colon-commands): TAB\nSearch pattern\nConsult\nSearch in all key bindings\nUsually SPC h b b, but use C-h b b or &lt;doom-leader-alt-key&gt; instead of SPC when leader key (SPC) is not available, for example in a vertico minibuffer:\nscroll-up-command             &lt;kp-next&gt;, C-S-j\nvertico-scroll-up             &lt;remap&gt; &lt;scroll-up-command&gt;\n\nCopy candidate list\nC-; E or C-c C-; in minibuffer to export candidates to a new buffer with Embark.\ncompleting-read-multiple (crm)\nPowers multi-select feature in magit.\n\n+vertico/crm-select: TAB\n+vertico/crm-exit: RET\n+vertico/crm-select-keep-input: S-TAB\n"},"notes/Emacs/doom/Window":{"slug":"notes/Emacs/doom/Window","filePath":"notes/Emacs/doom/Window.md","title":"Window","links":[],"tags":[],"content":"SPC w o (doom/window-enlargen)\nSPC w C-o (delete-other-windows)\nSPC w d (+workspace/close-window-or-workspace), also s-w and SPC w c\nSPC w q (evil-quit = Z Q)\nNote: SPC w and C-w are interchangeable."},"notes/Emacs/doom/Workspace":{"slug":"notes/Emacs/doom/Workspace","filePath":"notes/Emacs/doom/Workspace.md","title":"Workspace","links":[],"tags":[],"content":"Key bingings\nQuick switch: s-{0..9}"},"notes/Emacs/doom/cc":{"slug":"notes/Emacs/doom/cc","filePath":"notes/Emacs/doom/cc.md","title":"cc","links":[],"tags":[],"content":"LSP (preferred)\n;; in init.el\n:lang\n(cc +lsp)\n\nIrony-Mode\nIt does not work out of the box on macOS, but it is possible to put additional header flags to ~/.clang_complete, as long as no intermediate parent directory contains .clang_complete or compile_flags.txt.\n(defun irony-cdb-clang-complete--locate-db ()\n  (when buffer-file-name\n    (catch &#039;fname\n      (locate-dominating-file\necho | clang -x c++ -v -E - 2&gt;&amp;1 | sed -n &#039;/^#include &lt;/,/^End/s|^[^/]*\\([^ ]*/include[^ ]*\\).*$|-I\\1|p&#039; &gt; ~/.clang_complete\nrtags\nrtags also does not work out of the box on macOS, requiring users to configure ~/.rdmrc.\n--isystem=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1\n--isystem=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/12.0.0/include\n&lt;...&gt;\n"},"notes/Emacs/doom/chinese":{"slug":"notes/Emacs/doom/chinese","filePath":"notes/Emacs/doom/chinese.md","title":"chinese","links":["notes/Emacs/doom/Rime"],"tags":[],"content":"How to enable\n;; Uncomment in init.el\n(doom! :input\n       chinese\n \n       :ui\n       unicode\n       ...)\nInput methods\npyim\nEnabled by default in chinese module.\nemacs-rime\nRime"},"notes/Emacs/doom/defcustom":{"slug":"notes/Emacs/doom/defcustom","filePath":"notes/Emacs/doom/defcustom.md","title":"defcustom","links":[],"tags":[],"content":"Use setq in (after! ...) to set variables for a packge.\nIf a variable is defined with defcustom and has an associated custom-set form, use setq! instead of setq in doom to execute it."},"notes/Emacs/doom/lispy":{"slug":"notes/Emacs/doom/lispy","filePath":"notes/Emacs/doom/lispy.md","title":"lispy","links":[],"tags":[],"content":"Recommendation\nLispy overrides some keys in insert mode if the cursor is immediately before ( or after ).\nIf you are proficient in Vim, maybe you don’t need this module.\nKey bindings\nMovement: h j k l as usual, f to step into and b to move back in history\nSlurp: &gt;\nBarf: &lt;\nClone: c\nForward: ]\nBackward: [\nJump to matching pair: d\nSplit: M-j\nJoin: +\nTyping &quot; inside of a string inserts \\&quot;\\&quot;, so the split command is very useful for string templating.\nInsert\nParens: (\nBraces: {\nBrackets: }\nQuotes: &quot;\nLispyVille\nThe default key theme:\n  :init\n  (setq lispyville-key-theme\n        &#039;((operators normal)\n          c-w\n          (prettify insert)\n          (atom-movement t)\n          slurp/barf-lispy\n          additional\n          additional-insert))\n\nEach  (key-theme modes) is a pair of a LispyVille key theme and modes in which to bind them. For example, (escape insert) binds the “escape” theme in just the insert state. Without (), the default is to bind normal and visual states.\nAs described in github.com/abo-abo/lispy/issues/534, for arrow keys to work in xterm, M-O must be free from bindings in Emacs.\nHowever, package lispyville binds both M-o and M-O keys to its functions with evil-define-key*. Unbind them with the following config.\n(map! :after lispyville\n      :map lispyville-mode-map\n      :n &quot;M-O&quot; nil\n      :n &quot;M-o&quot; nil)\nGiven the order Doom Emacs’ config gets loaded,\n\nprivate/&lt;user-login-name&gt;/config.el is loaded automatically, after all other modules. Keeping :private &lt;user-login-name&gt; in init.el is harmless, but does nothing.\nprivate/&lt;user-login-name&gt;/init.el is loaded before all modules.\nIf your needs are simple, use after! to reconfigure packages.\n\nwe could also configure lispyville-key-theme in config.el, but remember to put it in at top-level, not within after!.\n(setq lispyville-key-theme\n      &#039;((operators normal)\n        c-w\n        (prettify insert)\n        (atom-movement t)\n        slurp/barf-lispy\n        additional\n        ;; additional-insert ; disabled for tty\n        ))\nReferences\n\ngithub.com/doomemacs/doomemacs/issues/88#issuecomment-306222820\n"},"notes/Emacs/doom/lsp-mode":{"slug":"notes/Emacs/doom/lsp-mode","filePath":"notes/Emacs/doom/lsp-mode.md","title":"lsp-mode","links":["notes/Emacs/doom/Projectile"],"tags":[],"content":"Multi root servers\nMulti-root means that one server can handle multiple projects, but the default behavior of lsp-mode is to load all projects for this language server at once.\nTo make it load folders on demand, add the following in (after! lsp-mode ...).\n(advice-add &#039;lsp :before (lambda (&amp;rest _args) (eval &#039;(setf (lsp-session-server-id-&gt;folders (lsp-session)) (ht)))))\nEven if all projects are loaded, cross-project references does not work. Move related projects into a workspace folder and create the special .projectile file to let Projectile treat it as a whole.\nState files\nSession information is stored in the file pointed to by lsp-session-file.\nTo remove a project from history, run lsp-workspace-folders-remove.\nTo list all current projects, run lsp-describe-session.\nDebugging\ndap-mode is another package hosted under the emacs-lsp organization. It is integrated with and depends on lsp-mode."},"notes/Emacs/doom/rust":{"slug":"notes/Emacs/doom/rust","filePath":"notes/Emacs/doom/rust.md","title":"rust","links":[],"tags":[],"content":"Apheleia\n:editor format wraps Apheleia, which does not support cargo fmt yet. Directly calling rustfmt means the edition specified in Cargo.toml is ignored, and rustfmt may throw an error if unsupported syntax is used.\nA workaround is to add a rustfmt.toml file, as described in github.com/radian-software/apheleia/issues/278.\n# rustfmt.toml\nedition = &quot;2021&quot;\nEglot\nWith rust-analyzer, hyperlinks from markdown hover text (get-text-property (point) &#039;help-echo) are not clickable.\nThis is supposedly fixed in Emacs (Eglot) commit cb562118cb14, but does not work with rustic specifically.\nIssue description is similar to github.com/joaotavora/eglot/issues/865, but it’s rustic’s problem here."},"notes/Emacs/doom/tree-sitter":{"slug":"notes/Emacs/doom/tree-sitter","filePath":"notes/Emacs/doom/tree-sitter.md","title":"tree-sitter","links":["notes/Emacs/doom/Straight"],"tags":[],"content":"Use existing *-ts-mode package\nFirst, install packages in package.el.\n(package! tree-sitter-langs\n  :pin &quot;3a3ad0527d5f8c7768678878eb5cfe399bedf703&quot;)\n \n(package! typst-ts-mode\n  :recipe (:host sourcehut :repo &quot;l2dy/typst-ts-mode&quot;)\n  :pin &quot;39a9e63c019bd5498c8f0e5a7ee8cb9d6bb53fd0&quot;)\nIf package depends on treesit instead of tree-sitter, it’s required to copy and rename parser library files.\n;; config.el\n \n(defun treesit-copy-langs-lib-if-newer (lang)\n  &quot;Copy treesit libraries from tree-sitter-langs&quot;\n  (require &#039;tree-sitter-langs)\n  (let* ((ts-lib-path (car (file-expand-wildcards (concat (tree-sitter-langs--bin-dir) lang &quot;.*&quot;))))\n         (ts-lib-name (file-name-nondirectory ts-lib-path))\n         (ts-lib-user-dir (concat user-emacs-directory (file-name-as-directory &quot;tree-sitter&quot;)))\n         (ts-lib-user-path (concat ts-lib-user-dir &quot;libtree-sitter-&quot; ts-lib-name)))\n    (when (or (not (file-exists-p ts-lib-user-path))\n              (time-less-p (file-attribute-modification-time (file-attributes ts-lib-user-path))\n                           (file-attribute-modification-time (file-attributes ts-lib-path))))\n      (make-directory ts-lib-user-dir t)\n      (delete-file ts-lib-user-path)\n      (copy-file ts-lib-path ts-lib-user-path nil t))))\n \n(use-package! typst-ts-mode\n  :mode &quot;\\\\.typ\\\\&#039;&quot;\n  :config\n  (treesit-copy-langs-lib-if-newer &quot;typst&quot;))\nUsing pre-compiled language grammars\n\nYou can find them on his Github releases page. You can also download the tree-sitter-langs package from MELPA, but I recommend you just download the shared libs directly instead, as you’ll in any event have to rename them and place the grammar libraries somewhere else.\nThe names of the files are &lt;LANGUAGE&gt;.so (or with your platform’s equivalent extension) which is not in keeping with the expected naming style in Emacs. You must first rename them so they’re named libtree-sitter-&lt;LANGUAGE&gt;.so. This is as good a time as any to learn how to bulk rename them with Emacs’s M-x dired and the editable dired buffers feature.\n\nDefine your own new major mode for highlighting\nSupported languages: github.com/emacs-tree-sitter/tree-sitter-langs/tree/master/queries\n\nEnsure (package! tree-sitter-langs ...) pins to the right commit (or a later commit) in packages.el and tree-sitter module is enabled in init.el.\nRun doom sync if pin is updated, and verify that updates are applied to local Straight directories.\nDefine the major mode in config.el, or a custom Doom module with define-derived-mode split into autoload.el.\n\n;;;###autoload\n(define-derived-mode typst-mode text-mode &quot;Typst&quot;\n  &quot;Major mode for editing Typst documents.&quot;\n  (set-tree-sitter-lang! &#039;typst-mode &#039;typst) ;; only required if not in tree-sitter-langs--init-major-mode-alist\n  (add-hook &#039;typst-mode-local-vars-hook #&#039;tree-sitter! &#039;append))\n \n(add-to-list &#039;auto-mode-alist &#039;(&quot;\\\\.typ\\\\&#039;&quot; . typst-mode))\nTo enable LSP instead, replace #&#039;tree-sitter! with #&#039;lsp!.\n\nFor Elisp gurus: Doom provides MAJOR-MODE-local-vars-hook, and we use it instead of MAJOR-MODE-hook because it runs later in the mode’s startup process (giving other functionality or packages — like direnv — time to configure the LSP client).\n\nLazy loading\nCheck if tsc-dyn-get-ensure is defined on start to verify lazy loading.\nLinux AArch64 support\nSee also github.com/emacs-tree-sitter/elisp-tree-sitter/issues/166#issuecomment-1522766887.\nAdd the following to config.el, which is equivalent to use-package’s :init.\n;; No binaries are provided for tree-sitter on AArch64 Linux\n(setq tsc-dyn-get-from &#039;(:compilation))\n\nThis does not fix missing binaries of tree-sitter-langs, so you need to build them yourself.\nReferences\n\ngithub.com/doomemacs/doomemacs/issues/1213#issuecomment-468970403\nwww.masteringemacs.org/article/how-to-get-started-tree-sitter\ngithub.com/doomemacs/doomemacs/blob/master/docs/faq.org#turn-doom-emacs-into-a-insert-language-here-ide-with-lsp\n"},"notes/Emacs/doom/tty":{"slug":"notes/Emacs/doom/tty","filePath":"notes/Emacs/doom/tty.md","title":"tty","links":[],"tags":[],"content":"+osc\nIn Mosh, SSH_TTY is left as is and points to a dead TTY. unset SSH_TTY in .zprofile or read tty from tmux display-message -p &#039;#{pane_tty}&#039; in a nested tmux session."},"notes/Emacs/doom/wgrep":{"slug":"notes/Emacs/doom/wgrep","filePath":"notes/Emacs/doom/wgrep.md","title":"wgrep","links":[],"tags":[],"content":"SPC s p foo C-; E i :%s/././ RET Z Z\n\nSPC-s-p foo invokes project-wide search\nC-; E exports the results into a wgrep buffer\ni &lt;...buffer edits&gt; RET Z Z makes the buffer editable and saves the changes.\n\nhungyi.net/posts/doom-emacs-search-replace-project/"},"notes/Emacs/emacsclient-on-macOS":{"slug":"notes/Emacs/emacsclient-on-macOS","filePath":"notes/Emacs/emacsclient on macOS.md","title":"emacsclient on macOS","links":[],"tags":["emacs","macos"],"content":"Starting Emacs server automatically\nConfigure a macOS launch agent with the plist file and load it with launchctl.\nlaunchctl load -w ~/Library/LaunchAgents/gnu.emacs.daemon.plist\n\n&lt;!-- Put following in ~/Library/LaunchAgents/gnu.emacs.daemon.plist --&gt;\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;!DOCTYPE plist PUBLIC &quot;-//Apple//DTD PLIST 1.0//EN&quot; &quot;www.apple.com/DTDs/PropertyList-1.0.dtd&quot;&gt;\n&lt;plist version=&quot;1.0&quot;&gt;\n&lt;dict&gt;\n    &lt;key&gt;Label&lt;/key&gt;\n    &lt;string&gt;gnu.emacs.daemon&lt;/string&gt;\n \n    &lt;key&gt;ProgramArguments&lt;/key&gt;\n    &lt;array&gt;\n        &lt;string&gt;/Applications/MacPorts/Emacs.app/Contents/MacOS/Emacs&lt;/string&gt;\n        &lt;string&gt;--fg-daemon&lt;/string&gt;\n    &lt;/array&gt;\n \n    &lt;key&gt;RunAtLoad&lt;/key&gt;\n    &lt;true/&gt;\n \n    &lt;key&gt;ProcessType&lt;/key&gt;\n    &lt;string&gt;Interactive&lt;/string&gt;\n&lt;/dict&gt;\n&lt;/plist&gt;\nEmacs client with AppleScript\nSave the following in Script Editor.app as an Application.\ndo shell script &quot;/Applications/MacPorts/Emacs.app/Contents/MacOS/bin/emacsclient -c -n -q&quot;\n\n⚠ Warning: Without -n the applet won’t quit and prevents system sleep.\n"},"notes/Emacs/mu4e/Prefer-Plain-Text-in-mu4e":{"slug":"notes/Emacs/mu4e/Prefer-Plain-Text-in-mu4e","filePath":"notes/Emacs/mu4e/Prefer Plain Text in mu4e.md","title":"Prefer Plain Text in mu4e","links":[],"tags":["emacs","mu4e"],"content":"\nBy default, mu4e tries to display the ’richest’ option, which is the last MIME-part of the alternatives. You can customize this to prefer the text version, if available, with something like the following in your configuration (and see the docstring for mm-discouraged-alternatives for details)\n\n(with-eval-after-load &quot;mm-decode&quot;\n  (add-to-list &#039;mm-discouraged-alternatives &quot;text/html&quot;)\n  (add-to-list &#039;mm-discouraged-alternatives &quot;text/richtext&quot;))\nwww.djcbsoftware.nl/code/mu/mu4e/MSGV-Rich_002dtext-and-images.html#MSGV-Rich_002dtext-and-images"},"notes/Emacs/mu4e/mu4e-Hotkeys":{"slug":"notes/Emacs/mu4e/mu4e-Hotkeys","filePath":"notes/Emacs/mu4e/mu4e Hotkeys.md","title":"mu4e Hotkeys","links":[],"tags":["emacs","mu4e"],"content":"M-&lt;up&gt;: move to previous message\nM-&lt;down&gt;: move to next message"},"notes/English-Terms/Conference-talks":{"slug":"notes/English-Terms/Conference-talks","filePath":"notes/English Terms/Conference talks.md","title":"Conference talks","links":[],"tags":[],"content":"During Q&amp;A, if you didn’t hear a question clearly, say “excuse me” to politely ask the questioner to repeat."},"notes/English-Terms/Data-center-terms":{"slug":"notes/English-Terms/Data-center-terms","filePath":"notes/English Terms/Data center terms.md","title":"Data center terms","links":[],"tags":[],"content":"Architecture\n\nredundant and independent network connections\nactive-active redundant\ndisaster recovery facility\n\nMaintenance\n\nincident\nevents\n\nPower\n\nunplanned maintenance event affecting one of xxx\nindependent power feeds\nutility power feeds\nutility company\npower up generators\nsupplement the feed that was down\nfail over to generator power\nsource of power\nground fault\ntransformer\n"},"notes/HTTP/CORS-Origin":{"slug":"notes/HTTP/CORS-Origin","filePath":"notes/HTTP/CORS Origin.md","title":"CORS Origin","links":[],"tags":[],"content":"Access-Control-Allow-Origin: &lt;origin&gt;\nYou can only allow one specific origin. If the server needs to support clients from multiple origins, it must return the origin for the specific client making the request."},"notes/HTTP/CORS-credentials":{"slug":"notes/HTTP/CORS-credentials","filePath":"notes/HTTP/CORS credentials.md","title":"CORS credentials","links":[],"tags":[],"content":"\nThe CORS request was attempted with the credentials flag set, but the server is configured using the wildcard (”*”) as the value of Access-Control-Allow-Origin, which doesn’t allow the use of credentials.\n\ndeveloper.mozilla.org/en-US/docs/Web/HTTP/CORS/Errors/CORSNotSupportingCredentials"},"notes/HTTP/Cross-Site-Request-Forgery-(CSRF)":{"slug":"notes/HTTP/Cross-Site-Request-Forgery-(CSRF)","filePath":"notes/HTTP/Cross-Site Request Forgery (CSRF).md","title":"Cross-Site Request Forgery (CSRF)","links":[],"tags":[],"content":"words.filippo.io/csrf/"},"notes/HTTP/HTTP-request-RTTs":{"slug":"notes/HTTP/HTTP-request-RTTs","filePath":"notes/HTTP/HTTP request RTTs.md","title":"HTTP request RTTs","links":[],"tags":[],"content":"\nPhase 1: DNS Lookup\nPhase 2: TCP Handshake (1 RTT)\nPhase 3: TLS Handshake (1 RTT if TLS 1.3)\n\n2 round trips if TLS version &lt; 1.3\n\n\nPhase 4: HTTP (1 RTT + server-side latency)\n"},"notes/HTTP/Preflight-request":{"slug":"notes/HTTP/Preflight-request","filePath":"notes/HTTP/Preflight request.md","title":"Preflight request","links":[],"tags":[],"content":"It’s an OPTIONS request, using three HTTP request headers: Access-Control-Request-Method, Access-Control-Request-Headers, and the Origin header.\nFor example:\nOPTIONS /resource/foo\nAccess-Control-Request-Method: DELETE\nAccess-Control-Request-Headers: origin, x-requested-with\nOrigin: foo.bar.org"},"notes/HTTP/Simple-file-server":{"slug":"notes/HTTP/Simple-file-server","filePath":"notes/HTTP/Simple file server.md","title":"Simple file server","links":[],"tags":[],"content":"\ngithub.com/sigoden/dufs\n\nnix run nixpkgs/&lt;rev&gt;#dufs -- -p 6000\n\nExample &lt;rev&gt;: c6a788f552b7b7af703b1a29802a7233c0067908\n\ngithub.com/static-web-server/static-web-server\n"},"notes/Health/20-20-20-rule":{"slug":"notes/Health/20-20-20-rule","filePath":"notes/Health/20-20-20 rule.md","title":"20-20-20 rule","links":[],"tags":[],"content":"Every 20 minutes spent using a screen, you should try to look away at something that is 20 feet away from you for a total of 20 seconds."},"notes/Kubernetes/CRI-logging-format":{"slug":"notes/Kubernetes/CRI-logging-format","filePath":"notes/Kubernetes/CRI logging format.md","title":"CRI logging format","links":[],"tags":[],"content":"\nThe runtime should decorate each log entry with a RFC 3339Nano timestamp prefix, the stream type (i.e., “stdout” or “stderr”), the tags of the log entry, the log content that ends with a newline.\nThe tags fields can support multiple tags, delimited by :. Currently, only one tag is defined in CRI to support multi-line log entries: partial or full. Partial (P) is used when a log entry is split into multiple lines by the runtime, and the entry has not ended yet. Full (F) indicates that the log entry is completed — it is either a single-line entry, or this is the last line of the multiple-line entry.\nFor example,\n2016-10-06T00:17:09.669794202Z stdout F The content of the log entry 1\n2016-10-06T00:17:09.669794202Z stdout P First line of log entry 2\n2016-10-06T00:17:09.669794202Z stdout P Second line of the log entry 2\n2016-10-06T00:17:10.113242941Z stderr F Last line of the log entry 2\n\nWith the knowledge, kubelet can parse the logs and serve them for kubectl logs requests. This meets requirement (3). Note that the format is defined deliberately simple to provide only information necessary to serve the requests. We do not intend for kubelet to host various logging plugins. It is also worth mentioning again that the scope of this proposal is restricted to stdout/stderr streams of the container, and we impose no restriction to the logging format of arbitrary container logs.\n\nReferences\n\ngithub.com/kubernetes/design-proposals-archive/blob/acc25e14ca83dfda4f66d8cb1f1b491f26e78ffe/node/kubelet-cri-logging.md#proposed-solution\n"},"notes/Kubernetes/Flux-Helm-Release-troubleshooting":{"slug":"notes/Kubernetes/Flux-Helm-Release-troubleshooting","filePath":"notes/Kubernetes/Flux Helm Release troubleshooting.md","title":"Flux Helm Release troubleshooting","links":[],"tags":[],"content":"Release stuck in pending-upgrade\nYour best option is to wait till timeout passes, reconciliation will sort it out.\nIf the current release revision is invalid and you can’t wait, rollback to a known good one, and let it reconcile again.\nhelm rollback -n flux-system &lt;RELEASE&gt; &lt;known good REVISION&gt;\n\nDeleting a HelmRelease\nKustomization in kustomize.toolkit.fluxcd.io/v1 defines the timeout and retryInterval of reconciliation.\nA deleted HelmRelease during reconciliation is considered a timeout failure and gets re-applied by the controlling Kustomization.\nerror Kustomization/infra-controllers.flux-system - Reconciliation failed after 5m1.877215018s, next try in 1m0s Health check failed after 5m0.030168483s: timeout waiting for: [HelmRelease/flux-system/victoria-metrics-alert status: &#039;NotFound&#039;]\ninfo Kustomization/infra-controllers.flux-system - server-side apply for cluster definitions completed\ninfo HelmRelease/victoria-metrics-alert.flux-system - HelmChart &#039;flux-system/flux-system-victoria-metrics-alert&#039; is not ready\n\nHelmChart not ready\nRun flux reconcile source helm &lt;repo&gt; to fetch latest charts from repo.\nHelmChart &#039;xxx&#039; is not ready\n\nForce reconcile\nIf reconciliation is stuck, you could try suspend and resume.\nflux suspend helmrelease &lt;name&gt;\nkubectl get -n flux-system helmrelease/&lt;name&gt; -o yaml # verify config\nflux resume helmrelease &lt;name&gt; # start reconcile"},"notes/Kubernetes/Flux":{"slug":"notes/Kubernetes/Flux","filePath":"notes/Kubernetes/Flux.md","title":"Flux","links":["notes/Kubernetes/Flux-Helm-Release-troubleshooting"],"tags":[],"content":"HelmRelease\nPost renderer\nfluxcd.io/flux/components/helm/helmreleases/#post-renderers\nHelmRelease resources has a built-in Kustomize compatible Post Renderer, which provides some Kustomize directives.\nNote that the patchesStrategicMerge and patchesJson6902 directive is deprecated, just use patches instead.\nTroubleshooting\nExperiment with helm template locally first. See also Flux Helm Release troubleshooting.\nSecrets\nK8s Secrets\nManage with sealed-secrets.\nWith kubeseal, secrets can be safely committed in Git. After reconciliation, use kubectl get -A sealedsecret to check decryption status.\nReference Secrets from HelmRelease\nSecrets used in valuesFrom should be put into the same namespace as the HelmRelease. kubeseal encryption is associated with cluster namespace, so if you got it wrong, it has to be re-encrypted.\nNote that targetPath in arrays like array[0].name is not supported. See github.com/helm/helm/issues/8320.\nDeploy credentials rotation\nFine-grained PAT from GitHub only lasts for a year.\nTo rotate the SSH key generated at bootstrap, first delete the secret from the cluster with:\nkubectl -n flux-system delete secret flux-system\nThen run flux bootstrap again.\nCommon Debug Commands\nflux logs --tail 10 -f\nHelm controller Logs\nkubectl describe -n flux-system helmrelease [name]\nRetry Helm install\nflux reconcile hr [name] --with-source # Attempt deploy\n \n# If retries are exhausted\nflux suspend hr [name]\nflux resume hr [name]\nRestore from fault\nthis namespace may not be deleted\nflux delete kustomization node-feature-discovery\n# wait for resources being deleted\n \n# force kill\nflux suspend kustomization node-feature-discovery\nRun flux suspend kustomization &lt;name&gt; to force delete a Kustomization in deletion that mistook a resource it did not own as its own.\n2024-10-01T00:00:00Z error Kustomization/node-feature-discovery.flux-system - Reconciler error delete failed, errors: Namespace/kube-system delete failed: namespaces &quot;kube-system&quot; is forbidden: this namespace may not be deleted;\n"},"notes/Kubernetes/GitHub-registry-image-mirroring":{"slug":"notes/Kubernetes/GitHub-registry-image-mirroring","filePath":"notes/Kubernetes/GitHub registry image mirroring.md","title":"GitHub registry image mirroring","links":[],"tags":[],"content":"crane copy ghcr.io/sergelogvinov/haproxy:2.8.6-alpine3.19 ghcr.io/l2dy-registry/sergelogvinov-haproxy:2.8.6-alpine3.19\n \nfor i in proxmox-cloud-controller-manager:v0.8.0 proxmox-csi-node:v0.11.0 proxmox-csi-controller:v0.11.0; do\ncrane copy &quot;ghcr.io/sergelogvinov/$i&quot; &quot;ghcr.io/l2dy-registry/$i&quot;\ndone"},"notes/Kubernetes/Grafana-Kubernetes-monitoring-Helm-charts":{"slug":"notes/Kubernetes/Grafana-Kubernetes-monitoring-Helm-charts","filePath":"notes/Kubernetes/Grafana Kubernetes monitoring Helm charts.md","title":"Grafana Kubernetes monitoring Helm charts","links":[],"tags":[],"content":"Metric collection optimization\n\nDisable OpenCost if not needed.\nDisable collection of tmpfs filesystem, ipvs, and veth device metrics.\nRetain most metrics from node_exporter.\n\nmetrics:\n  cost:\n    enabled: false\n  node-exporter:\n    allowList: []\n    extraMetricRelabelingRules: |\n      rule {\n        source_labels = [&quot;__name__&quot;]\n        regex = &quot;node_scrape_collector_.+&quot;\n        action = &quot;drop&quot;\n      }\nprometheus-node-exporter:\n  extraArgs:\n    - --no-collector.ipvs\n    - --collector.netclass.ignored-devices=^(veth.*|cali.*|[a-f0-9]{15})$\n    - --collector.netdev.device-exclude=^(veth.*|cali.*|[a-f0-9]{15})$\n    # Add tmpfs to defaults\n    - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|tmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$\nopencost:\n  enabled: false"},"notes/Kubernetes/Helm-chart-releaser":{"slug":"notes/Kubernetes/Helm-chart-releaser","filePath":"notes/Kubernetes/Helm chart releaser.md","title":"Helm chart releaser","links":[],"tags":[],"content":"\nCreate gh-pages branch first.\nCommit Actions workflow before charts directory.\nRemote repos referenced in Chart.lock needs to be added before executing the chart-releaser step.\nCommit your charts directories under /charts.\n\nReferences\n\ngithub.com/marketplace/actions/helm-chart-releaser\n"},"notes/Kubernetes/K3s-HA-cluster":{"slug":"notes/Kubernetes/K3s-HA-cluster","filePath":"notes/Kubernetes/K3s HA cluster.md","title":"K3s HA cluster","links":["notes/Kubernetes/K3s-etcd-HA","notes/Kubernetes/K3s-external-database-HA","notes/Network/VXLAN"],"tags":[],"content":"Datastores\nK3s etcd HA: best reliability, but has strict performance and latency constraints.\nK3s external database HA: depends reliable access to the database.\nNetwork\nThe default backend for Flannel is VXLAN, which is a UDP-based encapsulation technique without encryption.\nWireGuard backend for Flannel\nWith this configuration, K3s supervisor traffic uses a websocket tunnel and cluster (CNI) traffic uses a wireguard tunnel.\nOn servers:\n--node-external-ip=&lt;SERVER_EXTERNAL_IP&gt; \\\n--flannel-backend=wireguard-native \\\n--flannel-external-ip\n\nOn agents:\n--node-external-ip=&lt;AGENT_EXTERNAL_IP&gt;\n\nDual-Stack Network\n--cluster-cidr=10.42.0.0/16,fd00:42::/56\n--service-cidr=10.43.0.0/16,fd00:43::/112\n\nCA validation\nUse the complete token from /var/lib/rancher/k3s/server/node-token for Cluster CA validation.\nlevel=warning msg=&quot;Cluster CA certificate is not trusted by the host CA bundle, but the token does not include a CA hash. Use the full token from the server&#039;s node-token file to enable Cluster CA validation.&quot;\n\nAgent registration\nK3s only adds host IP addresses by default. For a fixed registration address like a load-balanced VIP, you should specify --tls-san. This address is used for agent nodes (not part of control plane) to join the cluster.\n\nTo avoid certificate errors with the fixed registration address, you should launch the server with the tls-san parameter set. This option adds an additional hostname or IP as a Subject Alternative Name in the server’s TLS cert, and it can be specified as a list if you would like to access via both the IP and the hostname.\n\n\n\nOptional: A fixed registration address for agent nodes to register with the cluster\n\n\nExample result:\nSubject Alternative Name (not critical):\n\tDNSname: kubernetes\n\tDNSname: kubernetes.default\n\tDNSname: kubernetes.default.svc\n\tDNSname: kubernetes.default.svc.cluster.local\n\tDNSname: localhost\n\tDNSname: &lt;hostname&gt;\n\tIPAddress: 10.43.0.1\n\tIPAddress: 127.0.0.1\n\tIPAddress: &lt;tls-san IP&gt;\n\tIPAddress: &lt;IPv4 IP&gt;\n\tIPAddress: &lt;IPv6 IP&gt;\n\tIPAddress: ::1\n\nIPv6\nAPI server\nThe Go standard library defaults to listen on both IPv4 and IPv6 when listen address is 0.0.0.0 and network is tcp, so the API server port is OK.\nLiteral IPv6 address can be used in --tls-san. See cnRegexp and populateCN() in go/pkg/mod/github.com/rancher/dynamiclistener@v0.3.6-rc2/factory/gen.go.\nSELinux\nUsing a custom --data-dir under SELinux isn’t supported. To customize it, you would most likely need to write your own custom policy.\nFor most users, it’s not worth the effort and --selinux shouldn’t be used.\nReferences\n\ngithub.com/k3s-io/k3s/issues/2850 (etcd latency expectations)\ndocs.k3s.io/installation/network-options#distributed-hybrid-or-multicloud-cluster\n"},"notes/Kubernetes/K3s-Traefik":{"slug":"notes/Kubernetes/K3s-Traefik","filePath":"notes/Kubernetes/K3s Traefik.md","title":"K3s Traefik","links":["notes/Kubernetes/K3s-system-HelmChart","notes/Kubernetes/Traefik"],"tags":[],"content":"Helm config\nYou can override default values with HelmChartConfig. To troubleshoot install issues, check Deploy Logs.\napiVersion: helm.cattle.io/v1\nkind: HelmChartConfig\nmetadata:\n  name: traefik\n  namespace: kube-system\nspec:\n  valuesContent: |-\n    affinity:\n      podAntiAffinity:\n        requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: &#039;{{ template &quot;traefik.name&quot; . }}&#039;\n                app.kubernetes.io/instance: &#039;{{ .Release.Name }}-{{ .Release.Namespace }}&#039;\n            topologyKey: kubernetes.io/hostname\n    deployment:\n      replicas: 8 # must be less than number of nodes, given the anti-affinity rule.\n      revisionHistoryLimit: 0 # discard old ReplicaSets. Does NOT work.\n    service:\n      spec:\n        externalTrafficPolicy: Local\n    ports:\n      websecure:\n        proxyProtocol:\n          enabled: true\n          trustedIPs:\n            - 10.0.0.0/8 # replace with actual IPs in Local externalTrafficPolicy mode\n    logs:\n      access:\n        enabled: true\n\nrevisionHistoryLimit: 0 does not work because 0 is treated as false like absent value. See github.com/helm/helm/issues/3164.\nIf number of replicas is equal to number of nodes, you may have to manually delete old ReplicaSets for new ones to be scheduled.\nkubectl delete -n kube-system ReplicaSet/traefik-xxx\nSee also Traefik."},"notes/Kubernetes/K3s-etcd-HA":{"slug":"notes/Kubernetes/K3s-etcd-HA","filePath":"notes/Kubernetes/K3s etcd HA.md","title":"K3s etcd HA","links":[],"tags":[],"content":"IPv6\netcd cluster\nK3s embedded etcd only listens on the IPv4 node IP. Use --node-ip to override the default.\nWhen --node-ip is an IPv6 address, clusterCIDR is also made IPv6.\nGiven this side effect, it may be better to manage etcd separately if nodes are not reachable via IPv4.\nReferences\n\nranchermanager.docs.rancher.com/how-to-guides/new-user-guides/kubernetes-cluster-setup/rke2-for-rancher\ngithub.com/k3s-io/k3s/blob/56abe7055fca997daf2bd88e67b1ddcb148c41b9/pkg/cli/server/server.go#L297-L305\n"},"notes/Kubernetes/K3s-exit-node-bypass-route":{"slug":"notes/Kubernetes/K3s-exit-node-bypass-route","filePath":"notes/Kubernetes/K3s exit node bypass route.md","title":"K3s exit node bypass route","links":[],"tags":[],"content":"K3s Flannel CNI\nConfigure dependency chain as follows. Only the dependent services (k3s-agent.service in this case) need to be customized.\ntailscale.service\n  -&gt; k3s-agent.service\n     [Unit] After=network-online.target tailscaled.service # Start sequence\n     [Unit] BindsTo=tailscaled.service # Propagate stop and restart\n     [Service] PostStart=-ip route add throw 10.42.0.0/16 table 52 # Ignore &quot;RTNETLINK answers: File exists&quot; failure\n\nWhen tailscaled restarts, Flannel routes are deleted if Tailscale exit node route is activated, so k3s-agent has to be restarted too.\nThis can be implemented with BindsTo=, but Tailscale can take some time to set up the interface, so the 100.x node-ip must be specified via arguments explicitly."},"notes/Kubernetes/K3s-external-database-HA":{"slug":"notes/Kubernetes/K3s-external-database-HA","filePath":"notes/Kubernetes/K3s external database HA.md","title":"K3s external database HA","links":[],"tags":[],"content":"Connection pooling\nPooling is implemented but config is not exposed to k3s.\nThe default is maxIdleConns=2, maxOpenConns=0, connMaxLifetime=0s.\nPostgreSQL\nConnection string\npostgres://username:password@hostname:port/database-name?sslmode=verify-full\n\nWith --datastore-cafile, sslmode is automatically set to verify-full. The certificate files will not be copied, so it’s best to specify an absolute location.\nMySQL\nTLS verify\nIf cert, key and CA files are not specified, append ?tls=true to the datastore endpoint to enforce TLS.\nOtherwise, Kine sets a custom TLS config that always verify server certificates.\n// func (c Config) ClientConfig() (*tls.Config, error)\nif c.CertFile == &quot;&quot; &amp;&amp; c.KeyFile == &quot;&quot; &amp;&amp; c.CAFile == &quot;&quot; {\n\treturn nil, nil\n}\n// func prepareDSN(dataSourceName string, tlsConfig *cryptotls.Config)\nconfig, err := mysql.ParseDSN(dataSourceName)\n \nif tlsConfig != nil {\n\t[...snip...]\n\tconfig.TLSConfig = &quot;kine&quot;\n}\n \nparsedDSN := config.FormatDSN()\n// func FormatDSN()\nif len(cfg.TLSConfig) &gt; 0 {\n\twriteDSNParam(&amp;buf, &amp;hasParam, &quot;tls&quot;, url.QueryEscape(cfg.TLSConfig))\n}\nManaged database\nOn managed MySQL databases, CREATE DATABASE might not be supported. For example, Vitess without database creator plugins will invoke the failDBDDL plugin, which always fails.\nReferences\n\ndocs.k3s.io/datastore#datastore-endpoint-format-and-functionality\ngithub.com/k3s-io/k3s/issues/1093\nwww.suse.com/support/kb/doc/\ngithub.com/k3s-io/kine/issues/63\n"},"notes/Kubernetes/K3s-system-HelmChart":{"slug":"notes/Kubernetes/K3s-system-HelmChart","filePath":"notes/Kubernetes/K3s system HelmChart.md","title":"K3s system HelmChart","links":[],"tags":[],"content":"Chart deploy logs\nkubectl describe -n kube-system HelmChart/traefik shows that HelmCharts are applied via Jobs.\n  Type    Reason    Age   From             Message\n  ----    ------    ----  ----             -------\n  Normal  ApplyJob  1m    helm-controller  Applying HelmChart using Job kube-system/helm-install-traefik\n\nYou can check the Helm logs with kubectl logs.\nkubectl logs -n kube-system Job/helm-install-traefik"},"notes/Kubernetes/K8s-Secrets":{"slug":"notes/Kubernetes/K8s-Secrets","filePath":"notes/Kubernetes/K8s Secrets.md","title":"K8s Secrets","links":[],"tags":[],"content":"\nNote: if you do not want to perform the base64 encoding, you can choose to use the stringData field instead.\n\ndata in a Secret must be base64-encoded."},"notes/Kubernetes/K8s-Volumes":{"slug":"notes/Kubernetes/K8s-Volumes","filePath":"notes/Kubernetes/K8s Volumes.md","title":"K8s Volumes","links":[],"tags":[],"content":"securityContext\n\nBy default, Kubernetes recursively changes ownership and permissions for the contents of each volume to match the fsGroup specified in a Pod’s securityContext when that volume is mounted. For large volumes, checking and changing ownership and permissions can take a lot of time, slowing Pod startup. You can use the fsGroupChangePolicy field inside a securityContext to control the way that Kubernetes checks and manages ownership and permissions for a volume.\n\nThis does not work with hostPath-type volumes.\nlocal volume setup on Linux calls SetVolumeOwnership(), which respects securityContext.\nK3s\nRancher’s local-path-provisioner is based on hostPath by default, so it’s recommended to add annotations to the StorageClass which specify defaultVolumeType.\nannotations:\n  defaultVolumeType: &lt;local or hostPath&gt;\nAlternatively, Longhorn can be installed as the CSI.\nReferences\n\nkubernetes.io/docs/tasks/configure-pod-container/security-context/#configure-volume-permission-and-ownership-change-policy-for-pods\nkubernetes.io/docs/concepts/storage/volumes/#local\ngithub.com/kubernetes/kubernetes/blob/741c8db18a52787d734cbe4795f0b4ad860906d6/pkg/volume/local/local.go#L618\ndocs.k3s.io/storage#setting-up-longhorn\n"},"notes/Kubernetes/K8s-metrics":{"slug":"notes/Kubernetes/K8s-metrics","filePath":"notes/Kubernetes/K8s metrics.md","title":"K8s metrics","links":[],"tags":[],"content":"Kubelet metrics\nkubectl get --raw can make raw HTTP requests to the API server. Alternatively, you could use curl via kubectl proxy.\nkubectl get --raw /api/v1/nodes/&lt;node&gt;/proxy/metrics\nkubectl get --raw /api/v1/nodes/&lt;node&gt;/proxy/metrics/cadvisor"},"notes/Kubernetes/Kubernetes-DNS":{"slug":"notes/Kubernetes/Kubernetes-DNS","filePath":"notes/Kubernetes/Kubernetes DNS.md","title":"Kubernetes DNS","links":[],"tags":[],"content":"DNS does not resolve Service names across namespaces.\nAppend .&lt;namespace&gt;.svc.cluster.local to the service name to reference a service across namespaces."},"notes/Kubernetes/Kubernetes-monitoring":{"slug":"notes/Kubernetes/Kubernetes-monitoring","filePath":"notes/Kubernetes/Kubernetes monitoring.md","title":"Kubernetes monitoring","links":["notes/Kubernetes/Grafana-Kubernetes-monitoring-Helm-charts","notes/Observability/Grafana-dashboards"],"tags":[],"content":"Setup\n\nGrafana Kubernetes monitoring Helm charts\ngithub.com/kubernetes-monitoring/kubernetes-mixin\ngithub.com/monitoring-mixins/website (simple mixin export tool)\n\nDashboards\nGrafana dashboards"},"notes/Kubernetes/Kustomize":{"slug":"notes/Kubernetes/Kustomize","filePath":"notes/Kubernetes/Kustomize.md","title":"Kustomize","links":[],"tags":[],"content":"Nested config\nOne kustomization.yaml file can only define one YAML object, so you have to organize Kustomization into different directories to implement a set of  Kustomization with different namespaces."},"notes/Kubernetes/Longhorn":{"slug":"notes/Kubernetes/Longhorn","filePath":"notes/Kubernetes/Longhorn.md","title":"Longhorn","links":[],"tags":[],"content":"Installation requirements\n\nThe host filesystem supports the file extents feature to store the data. Currently these are support:\n\next4\nXFS\n\n\n\nDisk config\nnode.longhorn.io/default-disks-config: \n&#039;[\n    { \n        &quot;path&quot;:&quot;/mnt/disk1&quot;,\n        &quot;allowScheduling&quot;:true\n    },\n    {   \n        &quot;name&quot;:&quot;fast-ssd-disk&quot;, \n        &quot;path&quot;:&quot;/mnt/disk2&quot;,\n        &quot;allowScheduling&quot;:false,\n        &quot;storageReserved&quot;:10485760,\n        &quot;tags&quot;:[\n            &quot;ssd&quot;,\n            &quot;fast&quot;\n        ]\n    }\n]&#039;\n\nSecurity\nThe backend does not support authentication. See github.com/longhorn/longhorn/issues/1983."},"notes/Kubernetes/Persistent-SQLite-on-K8s":{"slug":"notes/Kubernetes/Persistent-SQLite-on-K8s","filePath":"notes/Kubernetes/Persistent SQLite on K8s.md","title":"Persistent SQLite on K8s","links":[],"tags":[],"content":"Litestream\n\nCurrently, Litestream only allows a single node at a time in a StatefulSet but future versions will allow read replication to additional nodes.\n\nlitestream.io/guides/kubernetes/"},"notes/Kubernetes/Pinning-FROM-with-image-digest":{"slug":"notes/Kubernetes/Pinning-FROM-with-image-digest","filePath":"notes/Kubernetes/Pinning FROM with image digest.md","title":"Pinning FROM with image digest","links":[],"tags":[],"content":"Using multi-platform base images\nThe digest shown on Docker Hub is platform-specfic. When you click a tag, it brings you to the first architecture only.\nTo get digest of the entire multi-platform image, you could use nerdctl as shown below or docker buildx imagetools inspect &lt;image&gt;:&lt;tag&gt;.\n$ nerdctl image inspect --mode native bitnami/pgbouncer:1.20.1\n[..snip..]\n&quot;Image&quot;: {\n    &quot;Name&quot;: &quot;docker.io/bitnami/pgbouncer:1.20.1&quot;,\n    &quot;Labels&quot;: null,\n    &quot;Target&quot;: {\n        &quot;mediaType&quot;: &quot;application/vnd.docker.distribution.manifest.list.v2+json&quot;,\n        &quot;digest&quot;: &quot;sha256:710da11a466f98b90380fb8e02b487aacf8ef33b07acabb402067c122ac63e8d&quot;,\n        &quot;size&quot;: 529\n    },\n    &quot;CreatedAt&quot;: &quot;2023-10-02T14:54:49.666483Z&quot;,\n    &quot;UpdatedAt&quot;: &quot;2023-10-02T14:54:49.666483Z&quot;\n},\n"},"notes/Kubernetes/Scaling-K8s-to-a-large-cluster":{"slug":"notes/Kubernetes/Scaling-K8s-to-a-large-cluster","filePath":"notes/Kubernetes/Scaling K8s to a large cluster.md","title":"Scaling K8s to a large cluster","links":[],"tags":["k8s","scale"],"content":"For K3s:\n\nEnsure master nodes have enough memory for etcd, Kubernetes API server, etc.\nYou should consider increasing the subnet size for the cluster CIDR so that you don’t run out of IPs for the pods. You can do that by passing the --cluster-cidr option to K3s server upon starting.\nYou should consider the same for the service CIDR. In K3s, the largest supported service-cidr mask is /12 for IPv4, and /112 for IPv6.\nAdd the flag --etcd-arg=quota-backend-bytes=5368709120 to all master nodes to increase the max size of the embedded etcd datastore to 5 GiB. 8 GiB is a suggested maximum size for normal environments.\nProtocol buffers used by gRPC have a maximum size limit of &lt; 2 GiB for any data in serialized form. This would only affect requests to Kubernetes API server with very large response body.\nKubernetes API server configuration --request-timeout defaults to a minute, and to prevent resource exhaustion you should keep it at 1m0s.\n\nReferences\n\nranchermanager.docs.rancher.com/how-to-guides/advanced-user-guides/tune-etcd-for-large-installs\netcd.io/docs/v3.5/dev-guide/limit/\nkubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/\n"},"notes/Kubernetes/Traefik":{"slug":"notes/Kubernetes/Traefik","filePath":"notes/Kubernetes/Traefik.md","title":"Traefik","links":[],"tags":[],"content":"Kubernetes CRDs\nIn v2.10, the Kubernetes CRDs API Group traefik.containo.us is deprecated, and its support will end starting with Traefik v3. Please use the API Group traefik.io instead.\nentryPoints\nSpecify the entryPoints to use with annotations on Ingress:\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myingress\n  annotations:\n    traefik.ingress.kubernetes.io/router.entrypoints: web\nOtherwise, the default entryPoints is used.\nasDefault\nIf there is no entryPoint with the asDefault option set to true, then the list of default entryPoints includes all HTTP/TCP entryPoints.\nIf at least one entryPoint has the asDefault option set to true, then the list of default entryPoints includes only entryPoints that have the asDefault option set to true.\nSome built-in entryPoints are always excluded from the list, namely: traefik.\nThe asDefault option has no effect on UDP entryPoints. When a UDP router does not define the entryPoints option, it is attached to all available UDP entryPoints.\nDefault certificate\nSpecify default TLS certificate with a TLSStore named “default” in Traefik’s namespace.\napiVersion: traefik.io/v1alpha1\nkind: TLSStore\nmetadata:\n  name: default\n  namespace: {{ template &quot;traefik.namespace&quot; $ }}\n \nspec:\n  defaultCertificate:\n    secretName: mySecret\nFor Traefik versions &lt; 2.10, use the old API group.\napiVersion: traefik.containo.us/v1alpha1\nkind: TLSStore\nmetadata:\n  name: default\n  namespace: {{ template &quot;traefik.namespace&quot; $ }}\n \nspec:\n  defaultCertificate:\n    secretName: mySecret\nTraefik dashboard (in default setup)\nkubectl -n kube-system port-forward deploy/traefik 9000\n# open http://127.0.0.1:9000/\n\nReferences\n\ndoc.traefik.io/traefik/routing/providers/kubernetes-crd/#kind-tlsstore\n"},"notes/Kubernetes/cAdvisor-metrics":{"slug":"notes/Kubernetes/cAdvisor-metrics","filePath":"notes/Kubernetes/cAdvisor metrics.md","title":"cAdvisor metrics","links":[],"tags":[],"content":"Memory\n\nWe can see from this experiment that container_memory_usage_bytes does account for some filesystem pages that are being cached. We can also see that OOMKiller is tracking container_memory_working_set_bytes. This makes sense as shared filesystem cache pages can be evicted from memory at any time. There’s no point in killing the process just for using disk I/O.\n\nThe OOMKiller is mostly tracking container_memory_working_set_bytes, which is\n\nPrecisely, container_memory_working_set_bytes = container_memory_usage_bytes - inactive_file (from cadvisor code) = rss + cache + swap - inactive_file (from section 5.5 www.kernel.org/doc/Documentation/cgroup-v1/memory.txt) = rss + active_cache + swap = rss + active_cache (swap is disabled in k8s)\n\nNote that unreclaimable page cache is also accounted for.\nReferences\n\nfaun.pub/how-much-is-too-much-the-linux-oomkiller-and-used-memory-d32186f29c9d\n"},"notes/Kubernetes/cert-manager":{"slug":"notes/Kubernetes/cert-manager","filePath":"notes/Kubernetes/cert-manager.md","title":"cert-manager","links":[],"tags":[],"content":"Helm CRDs\n\ncert-manager does not use the official helm method of installing CRD resources. This is because it makes upgrading CRDs impossible with helm CLI alone. The helm team explain the limitations of their approach here.\n\n\nif you uninstall the release, the CRDs will also be uninstalled. If that happens then you will loose all instances of those CRDs, e.g. all Certificate resources in the cluster. You should consider if this is likely to happen to you and have a mitigation, such as backups or a means to reapply resources from an Infrastructure as Code (IaC) pattern.\n\nClusterIssuer Secrets\n\nThe ClusterIssuer resource is cluster scoped. This means that when referencing a secret via the secretName field, secrets will be looked for in the Cluster Resource Namespace. By default, this namespace is cert-manager however it can be changed via a flag on the cert-manager-controller component.\n\nWrite cluster-level Secret into the cert-manager namespace.\nDNS-01 Challenge\nSuitable for private domains, because HTTP-01 validators are not able to connect to them."},"notes/Life/Dealing-with-leaking-alkaline-batteries":{"slug":"notes/Life/Dealing-with-leaking-alkaline-batteries","filePath":"notes/Life/Dealing with leaking alkaline batteries.md","title":"Dealing with leaking alkaline batteries","links":[],"tags":[],"content":"If you need to keep the battery for compensation\n\nKeep the battery in the damaged device.\nIf you are in contact with the liquid leaked, rinse immediately with running water. If there are visible burns, contact your doctor.\nEnsure room is well ventilated and seal the device with the battery in a bag and put it in a safe place.\nAvoid handling the leak yourself to prevent chemical burns.\n\nDispose leaking batteries\n\nIf you are in contact with the liquid leaked, rinse immediately with running water. If there are visible burns, contact your doctor.\nPut on gloves, an apron and glasses (if you have them).\nEnsure room is well ventilated.\nRemove the leaked batteries (preferably wearing gloves).\nPut the leaking batteries in a clear plastic bag and seal it.\nPut the bag in a secure place away from children or pets immediately.\nWash your hands and dispose the bag.\n\nClean up the device\n\nPut on gloves, an apron and glasses (if you have them).\nEnsure room is well ventilated.\n(Preferred) Dip a cotton swab, a cloth or an old toothbrush in lemon juice or vinegar.\nWipe the white crystals off gently with it until your device is entirely clean.\nWash your hands!\nAfter the area has completely dried up, scrape the metal contacts to remove any residue and polish them with a pencil eraser.\n"},"notes/MacPorts/Fontconfig":{"slug":"notes/MacPorts/Fontconfig","filePath":"notes/MacPorts/Fontconfig.md","title":"Fontconfig","links":[],"tags":[],"content":"Font directory list\n\t&lt;dir&gt;/usr/share/fonts&lt;/dir&gt;\n\t&lt;dir&gt;/usr/X11/lib/X11/fonts&lt;/dir&gt; &lt;dir&gt;/opt/local/share/fonts&lt;/dir&gt; &lt;dir&gt;/Library/Fonts&lt;/dir&gt; &lt;dir&gt;/Network/Library/Fonts&lt;/dir&gt; &lt;dir&gt;/System/Library/Fonts&lt;/dir&gt;\n\t&lt;dir prefix=&quot;xdg&quot;&gt;fonts&lt;/dir&gt;\n\t&lt;!-- the following element will be removed in the future --&gt;\n\t&lt;dir&gt;~/.fonts&lt;/dir&gt;\n\nShould we add ~/Library/Fonts? github.com/macports/macports-ports/pull/13144"},"notes/MacPorts/Ideas":{"slug":"notes/MacPorts/Ideas","filePath":"notes/MacPorts/Ideas.md","title":"Ideas","links":[],"tags":[],"content":"Improvements\n\n Fix port bump in ports with multiple checksums (e.g. cargo.crates).\n port command blocks on DNS resolution timeout, and is impossible to interrupt safely.\n\nIt’s blocked on a curl call, which already has a reasonable timeout.\nWhy doesn’t Ctrl+C interrupt the call?\n\n\n port reclaim takes too much time checking distfiles.\n\nCache distfile information (done).\n\n\n[/] Dependency resolution is too slow.\n\nCould not make use of libsolv because we have variants and countless combinations out of them.\n\n\n"},"notes/MacPorts/OpenSSH-logs-on-macOS":{"slug":"notes/MacPorts/OpenSSH-logs-on-macOS","filePath":"notes/MacPorts/OpenSSH logs on macOS.md","title":"OpenSSH logs on macOS","links":[],"tags":[],"content":"Stream logs\nlog stream --process ssh\n"},"notes/MacPorts/Running-a-system-LaunchDaemon-with-MacPorts":{"slug":"notes/MacPorts/Running-a-system-LaunchDaemon-with-MacPorts","filePath":"notes/MacPorts/Running a system LaunchDaemon with MacPorts.md","title":"Running a system LaunchDaemon with MacPorts","links":[],"tags":[],"content":"Process\n\nAdd following file in MacPort source layout and portindex it.\nAdd the directory to MacPorts’ sources.conf.\nsudo port install xxx &amp;&amp; sudo port load xxx to install and activate the service.\n\nPortfile\n# -*- coding: utf-8; mode: tcl; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*- vim:fenc=utf-8:ft=tcl:et:sw=4:ts=4:sts=4\n\nPortSystem          1.0\n\nname                xxx\nepoch.              20240101\nversion             1\ncategories          net\nlicense             Restrictive\nplatforms           darwin\nmaintainers         nomaintainer\ndescription         None\nlong_description    None\nhomepage            none\n\ndistfiles\nuse_configure no\nbuild {}\ndestroot {}\n\nstartupitem.create     yes\nstartupitem.netchange  yes\nstartupitem.executable ${xxx_prefix}/bin/xxx -f ${prefix}/etc/xxx.conf\n\nadd_users           _xxx group=_xxx home=${prefix}/var/run/xxx \\\n                    shell=/usr/bin/false realname=xxx\\ Server\n\nlivecheck.type  none\n"},"notes/MacPorts/base/Alternative-compiler":{"slug":"notes/MacPorts/base/Alternative-compiler","filePath":"notes/MacPorts/base/Alternative compiler.md","title":"Alternative compiler","links":[],"tags":[],"content":"Beware of MP_PATH_SCAN.\ndnl This macro ensures MP installation prefix paths are NOT in PATH\ndnl for configure to prevent potential problems when base/ code is updated\ndnl and ports are installed that would match needed items.\nAC_DEFUN([MP_PATH_SCAN],[\n    ...\n])\nUse symboic links as a workaround:\nln -s /opt/local/libexec/llvm-13/libexec/intercept-cc ~/.local/bin/\nintercept-build-mp-13 bash -c &#039;./configure &amp;&amp; make -j6&#039;\n"},"notes/MacPorts/base/Anatomy":{"slug":"notes/MacPorts/base/Anatomy","filePath":"notes/MacPorts/base/Anatomy.md","title":"Anatomy","links":[],"tags":[],"content":"Database\n/* ports table */\n&quot;CREATE TABLE registry.ports (&quot;\n        &quot;id INTEGER PRIMARY KEY&quot; // row ID\n    &quot;, name TEXT COLLATE NOCASE&quot; // name of the port\n    &quot;, portfile TEXT&quot; // path of Portfile copy\n    &quot;, location TEXT&quot; // image (binary archive) location\n    &quot;, epoch INTEGER&quot; // part of version comparison\n    &quot;, version TEXT COLLATE VERSION&quot; // part of version comparison\n    &quot;, revision INTEGER&quot; // part of version comparison\n    &quot;, variants TEXT&quot; // actual variants used to build port\n    &quot;, requested_variants TEXT&quot; // variants explicitly requested by user\n    &quot;, state TEXT&quot; // installed (activated) or imaged (has image)\n    &quot;, date DATETIME&quot; // install date\n    &quot;, installtype TEXT&quot; // unused, always &quot;image&quot;\n    &quot;, archs TEXT&quot; // list of architectures of this port\n    &quot;, requested INTEGER&quot; // is port requested (boolean)\n    &quot;, os_platform TEXT&quot; // operating system (&quot;darwin&quot;)\n    &quot;, os_major INTEGER&quot; // OS version\n    &quot;, cxx_stdlib TEXT&quot; // stdlib used for C++ (&quot;libstdc++&quot; or &quot;libc++&quot;)\n    &quot;, cxx_stdlib_overridden INTEGER&quot; // flag to track broken C++ ports\n    &quot;, UNIQUE (name, epoch, version, revision, variants)&quot;\n    &quot;)&quot;,\n&quot;CREATE INDEX registry.port_name ON ports&quot;\n    &quot;(name, epoch, version, revision, variants)&quot;,\n&quot;CREATE INDEX registry.port_state ON ports(state)&quot;,\n \n/* file map */\n&quot;CREATE TABLE registry.files (&quot;\n        &quot;id INTEGER&quot; // row ID\n    &quot;, path TEXT&quot; // file path\n    &quot;, actual_path TEXT&quot; // actual path installed (FS case-sensitivity)\n    &quot;, active INTEGER&quot; // is file installed\n    &quot;, binary BOOL&quot; // is file a binary (rev-upgrade check)\n    &quot;, FOREIGN KEY(id) REFERENCES ports(id))&quot;,\n&quot;CREATE INDEX registry.file_port ON files(id)&quot;,\n&quot;CREATE INDEX registry.file_path ON files(path)&quot;,\n&quot;CREATE INDEX registry.file_actual ON files(actual_path)&quot;,\n&quot;CREATE INDEX registry.file_actual_nocase ON files(actual_path COLLATE NOCASE)&quot;,\n \n/* dependency map */\n&quot;CREATE TABLE registry.dependencies (&quot;\n        &quot;id INTEGER&quot; // row ID\n    &quot;, name TEXT&quot; // name of the port\n    &quot;, variants TEXT&quot; // variants of the port\n    &quot;, FOREIGN KEY(id) REFERENCES ports(id))&quot;, // the dependency\n&quot;CREATE INDEX registry.dep_id ON dependencies(id)&quot;,\n&quot;CREATE INDEX registry.dep_name ON dependencies(name)&quot;,\nVersioning\nepoch &gt; version &gt; revision\n\nPrefixes\nMacPorts defaults to /opt/local, but allows alternatives prefixes.\nPhases\n\nfetch\n\nFetch the ${distfiles} containing program source code or binaries.\n\nchecksum\n\nCompare ${checksums} specified in a Portfile to the checksums of the fetched ${distfiles}.\n\nextract\n\nExtract the ${distfiles} into working directory for build.\n\npatch\n\nApply optional patch files.\n\nconfigure\n\nExecute ${configure.cmd} in ${worksrcpath}.\n\nbuild\n\nExecute ${build.cmd} in ${worksrcpath}.\n\ndestroot\n\nExecute command to “stages” an installation into an intermediate location ${destroot}.\n\ninstall\n\nArchive (also known as Image) a port’s destrooted files into ${prefix}/var/macports/software.\n\nactivate\n\nExtract the port’s files from the archive in ${prefix}/var/macports/software to their final installed locations, usually in ${prefix}.\nPortGroup\nRolling release (synced with ports tree) of utility functions to help make Portfiles more concice and declarative.\nVariants\nMaximum flexibility, but brings a lot of headache. Prefer non-conflicting subports if possible.\nSubports\nA directive used in Portfile to generate multiple port definitions from a single Portfile.\nC++ stdlib\nThe default C++ runtime on OS X 10.9 and later is libc++ from LLVM which supports C++11.\nFor older OS X versions, MacPorts installs a functional libc++ toolchain by default to replace the ancient version of libstdc++ OS X shipped.\nOn Linux libstdc++ (The GNU C++ Library) is more ubiquitous."},"notes/MacPorts/base/Registry":{"slug":"notes/MacPorts/base/Registry","filePath":"notes/MacPorts/base/Registry.md","title":"Registry","links":[],"tags":[],"content":"registry2 package is entirely written in C.\nTcl_PkgProvide(interp, &quot;registry2&quot;, &quot;2.0&quot;)\nregistry2.0/registry.tcl provides registry 1.0, don’t mistaken it with the C part."},"notes/MacPorts/base/Tcl-API":{"slug":"notes/MacPorts/base/Tcl-API","filePath":"notes/MacPorts/base/Tcl API.md","title":"Tcl API","links":[],"tags":[],"content":"Tcl_GetIndexFromObjStruct\nSimple static dictionary lookup.\n// Array of `struct` type, whose first member is a null-terminated string.\n// End of array is marked by a NULL string pointer.\nstatic entry_cmd_type entry_cmds[] = {\n    /* Global commands */\n    { &quot;create&quot;, entry_create },\n    { &quot;delete&quot;, entry_delete },\n    { &quot;open&quot;, entry_open },\n    { &quot;close&quot;, entry_close },\n    { &quot;search&quot;, entry_search },\n    { &quot;exists&quot;, entry_exists },\n    { &quot;imaged&quot;, entry_imaged },\n    { &quot;installed&quot;, entry_installed },\n    { &quot;owner&quot;, entry_owner },\n    { NULL, NULL }\n};\n\n// Search for a string in array, save matching index to `cmd_index` and return TCL_OK.\nif (Tcl_GetIndexFromObjStruct(interp, objv[1], entry_cmds,\n            sizeof(entry_cmd_type), &quot;cmd&quot;, 0, &amp;cmd_index) == TCL_OK) {\n    entry_cmd_type* cmd = &amp;entry_cmds[cmd_index];\n    return cmd-&gt;function(interp, objc, objv);\n}\n"},"notes/Media/Music-streaming-setup":{"slug":"notes/Media/Music-streaming-setup","filePath":"notes/Media/Music streaming setup.md","title":"Music streaming setup","links":["notes/Self-Hosting/Litestream"],"tags":[],"content":"Why\nMobile devices have limited storage. With streaming, you can enjoy higher sound quality and more tracks.\nServer software\nNavidrome\nCommunity has written a K8s Deployment manifest with Ingress.\ngithub.com/navidrome/navidrome/blob/59f0c487e7e6943668c47321ef863291401f4a08/contrib/k8s/manifest.yml\nYou can back up the database with Litestream.\nAudio codec\nGeneration loss\nTranscoding from a lossy format might degrade the audio quality.\nTo avoid transcoding from lossy formats in the streaming process, store music files in either lossless formats or a codec that has the least generation loss in the last mile before digital-to-analog conversion (DAC). The best situation is that no transcoding is needed. For example, exclusive mode apps on Windows skips the mixer and therefore any transcoding.\nOpus\nlibopus has the best quality in popular lossy formats supported by FFmpeg. Encode/HighQualityAudio\nFor audible transparency, use 128 kbps for stereo. Opus Recommended Settings\nStereo 160 to 192 kbps is verified transparent according to wiki.hydrogenaud.io/index.php\nAAC\nApple Music’s default import function uses 256 kbps VBR AAC for stereo music.\nFor audible transparency, use 128 kbps for stereo.\nMinimal generation loss could be one of the design goals of AAC. Reference\nFFmpeg Transcode\nlibfdk_aac\nFor 192 kbps VBR, use -vbr 5 with -c:a libfdk_aac. VBR also disables the low-pass filter and preserves higher frequencies.\ngit log v2.0.2.. in github.com/mstorsjo/fdk-aac shows improvements in security hardening and VBR encoding, so it’s worth a try.\nyou can install FFmpeg with MacPorts.\nport install ffmpeg6 +nonfree\naac_at\nwiki.hydrogenaud.io/index.php\nFFmpeg’s q argument ranges from 0 to 14. In the source code, avctx-&gt;global_quality refers to q and AudioToolbox framework gets 127 - q * 9.\nFor 256 kbps VBR, use -q:a 2. Don’t use -global_quality:a, which is ineffective and gives a constant 128 kbps.\nA 3 minute long music file transcoded with  -vn -c:a aac_at -q:a &lt;q in filename&gt; gives the following file sizes.\n$ du -k q*.m4a # unit is kiB\n8196\tq0.m4a\n6404\tq2.m4a\n5380\tq4.m4a\n4100\tq5.m4a\n3844\tq6.m4a\n3588\tq7.m4a\n\ngithub.com/FFmpeg/FFmpeg/blob/393d1ee541b143633bfba2ff0e821d734fd511c2/libavcodec/audiotoolboxenc.c#L325-L335\nAAC generation loss\nwww.reddit.com/r/AppleMusic/comments/o67idh/losslesshires_lossless_on_airpods_pro/h2sshj5/\n\nThe thing here is that, yeah there’s an increase, because previously you had a lossy file (AAC) which lose again info thanks to the BT AAC codec, there’s two compressions to the file, now you only have one compression the BT AAC one, so there’s less info loss it during the process.\n\n\nIt’s decoded, mixed with system sounds (like alerts) and then recompressed. This is obvious because the output over bluetooth rolls off high-frequencies a bit sooner than the original AAC file. (I think the test I saw was on The Sound Guy’s website, but I can’t find it now)\nThe good news is that the generational loss from AAC to Uncompressed to AAC again is really minor. You can do it over and over and its still very difficult for people to tell the difference between the original AAC file and its descendant.\n"},"notes/NGINX/Angie-Prometheus-stats":{"slug":"notes/NGINX/Angie-Prometheus-stats","filePath":"notes/NGINX/Angie Prometheus stats.md","title":"Angie Prometheus stats","links":[],"tags":[],"content":"\n\n                  \n                  WARNING\n                  \n                \n\nTo collect statistics, enable a shared memory zone in the appropriate contexts using:\n\nthe zone directive in http_upstream or stream_upstream;\nthe status_zone directive;\nthe status_zone parameter in the resolver directive.\n\n\n\n\nstatus_zone directive set in server and location context have separate shared memory zone and each request is accounted for in both of them.\nNumber of processing requests is only available in server context, but you may use upstream zone metrics as an approximation.\n499 status code from logs corresponds to  angie_http_server_zones_requests_discarded in metrics.\nIgnore the “nested location blocks” thing from status_zone docs. It’s evil to nest location blocks because the inheritance rule for nested location blocks is surprisingly different from others.\n\n\nThe server zone statistics is working before the location is finally determined (and it allows it to have an additional metric like number of requests currently processing by the server). So it’s technically not possible to disable it for a particular location.\nNote also that the location can be changed multiple times during the request processing, while the server context stays the same for a particular request. That’s the reason why the location statistics are only counted at the end of request processing.\n\nNote that each request is counted twice at most, first before the location is determined, last at the end of request processing.\n\nngx_http_server_stats_s and ngx_http_get_server_stats() for server\nngx_http_location_stats_t and ngx_http_get_location_stats() for location\n\nngx_http_calculate_request_statistic() and ngx_http_calculate_post_request_statistic() combined collects statistics for server status_zone, and the later is also responsible for location status_zone collection.\nThis is the first function’s code:\nvoid\nngx_http_calculate_request_statistic(ngx_http_request_t *r,\n    ngx_http_status_zone_t *status_zone)\n{\n    ngx_http_server_stats_t  *stats;\n \n    stats = ngx_http_get_server_stats(r, status_zone);\n    if (stats == NULL) {\n        return;\n    }\n \n    (void) ngx_atomic_fetch_add(&amp;stats-&gt;processing, 1);\n    (void) ngx_atomic_fetch_add(&amp;stats-&gt;requests, 1);\n \n    r-&gt;server_stats = stats;\n}\nBonus script\nYou may use this awk command to count first level of URL prefixes in $10:\nawk -F\\\\t &#039;{\n  uri = $10\n  sub(/\\?.*$/, &quot;&quot;, uri)                     # strip query string\n  i = 1; lead = &quot;&quot;; n = length(uri)\n  while (i &lt;= n &amp;&amp; substr(uri, i, 1) == &quot;/&quot;) { lead = lead &quot;/&quot;; i++ }   # preserve leading slashes\n  rest = substr(uri, i)\n  if (rest == &quot;&quot;) { print lead; next }      # only slashes or empty\n  j = index(rest, &quot;/&quot;)\n  if (j == 0) print lead rest               # no further path -&gt; keep segment without trailing slash\n  else print lead substr(rest, 1, j-1) &quot;/&quot;  # had more path -&gt; append trailing slash\n}&#039;\nAlso note nginx.org/en/docs/http/ngx_http_core_module.html#merge_slashes, which applies to $uri."},"notes/NGINX/Byte-range-request":{"slug":"notes/NGINX/Byte-range-request","filePath":"notes/NGINX/Byte-range request.md","title":"Byte-range request","links":[],"tags":[],"content":"NGINX tries to slice the response body when one of the following conditions is met and the request specifies a Range header.\n\nNGINX is serving static files directly.\nNGINX cache is enabled.\nproxy_force_ranges is set to on.\n\nThis behavior is controlled by allow_ranges in struct ngx_http_request_s."},"notes/NGINX/NGINX-HTTP-variables-to-log":{"slug":"notes/NGINX/NGINX-HTTP-variables-to-log","filePath":"notes/NGINX/NGINX HTTP variables to log.md","title":"NGINX HTTP variables to log","links":[],"tags":[],"content":"Improved log format\nIf the ngx_http_realip_module module is not configured correctly, use $http_cf_connecting_ip\\t$remote_addr at the beginning instead.\nlog_format main_cf &#039;$remote_addr\\t$realip_remote_addr\\t$server_addr\\t$hostname\\t&#039;\n                   &#039;$time_iso8601\\t$host\\t$request_uri\\t$request_length\\t&#039;\n                   &#039;$request_time\\t$status\\t$body_bytes_sent\\t$http_user_agent\\t&#039;\n                   &#039;$upstream_addr\\t$upstream_status\\t$upstream_connect_time\\t$upstream_response_time\\t&#039;\n                   &#039;$request_method\\t$server_protocol\\t$http_cf_ipcountry\\t$http_cf_ray\\t&#039;;\nP.S.\n\n$server_addr has a tiny performance penalty if the listening socket is not bind to a specific IP address.\nIf the request came from an IP out of the set_real_ip_from CIDR ranges, $realip_remote_addr would fallback to r-&gt;connection-&gt;addr_text, which is the same as $remote_addr (defined in function ngx_http_variable_remote_addr).\nThe trailing \\t can be removed. It was kept for extensibility.\n\nNote: if a server cannot be selected, $upstream_status keeps the pre-filled 502.\nPosition of common variables in main_cf format:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariablePosition$host6$status10$request_uri7$request_time9$http_user_agent12\nGoAccess config:\n# for older versions without `--datetime-format` or if goaccess could not handle `%FT%T%z` with strftime(3)\ngoaccess --date-format=&#039;%Y-%m-%d&#039; --time-format=&#039;%T&#039; --log-format=&#039;%h\\t%^\\t%^\\t%^\\t%dT%t+%^\\t%v\\t%U\\t%^\\t%T\\t%s\\t%b\\t%u\\t%^\\t%^\\t%^\\t%^\\t%m\\t%H\\t%^\\t%^&#039;\n \n# for latest version\ngoaccess --datetime-format=&#039;%Y-%m-%dT%H:%M:%S%z&#039; --log-format=&#039;%h\\t%^\\t%^\\t%^\\t%x\\t%v\\t%U\\t%^\\t%T\\t%s\\t%b\\t%u\\t%^\\t%^\\t%^\\t%^\\t%m\\t%H\\t%^\\t%^&#039;\nNote: avoid datetime-format %FT%T%z because it doesn’t work well with --date-spec=.\nBasic information\n$bytes_sent\nnumber of bytes sent to a client (1.3.8, 1.2.5). Measured at HTTP-level, not including TCP or TLS overhead.\n$body_bytes_sent\nnumber of bytes sent to a client, not counting the response header; this variable is compatible with the “%B” parameter of the mod_log_config Apache module\n$host\nin this order of precedence: host name from the request line, or host name from the “Host” request header field, or the server name matching a request. Read from headers_in.server instead of headers_in.host. The former is normalized with ngx_http_validate_host().\n$hostname\nhost name\n$remote_addr\nclient address\n$server_addr\nan address of the server which accepted a request\nComputing a value of this variable usually requires one system call. To avoid a system call, the listen directives must specify addresses and use the bind parameter.\n$request_length\nrequest length (including request line, header, and request body) (1.3.12, 1.2.7)\n$request_method\nrequest method, usually “GET” or “POST”\n$request_time\nrequest processing time in seconds with a milliseconds resolution (1.3.9, 1.2.6); time elapsed since the first bytes were read from the client. Measured at HTTP-level, not including TCP or TLS handshake time.\n$request_uri\nfull original request URI (with arguments)\n$scheme\nrequest scheme, “http” or “https”\n$server_protocol\nrequest protocol, usually “HTTP/1.0”, “HTTP/1.1”, “HTTP/2.0”, or “HTTP/3.0”\n$status\nresponse status (1.3.2, 1.2.2)\n$time_iso8601, $time_local\nlocal time in the ISO 8601 standard format (1.3.12, 1.2.7) and the Common Log Format (1.3.12, 1.2.7). Records the time (cached) when the log entry is written.\n$http_name\narbitrary request header field; the last part of a variable name is the field name converted to lower case with dashes replaced by underscores\nHTTP/2\n$connection\nconnection serial number (1.3.8, 1.2.5)\n$connection_requests\ncurrent number of requests made through a connection (1.3.8, 1.2.5)\n$connection_time\nconnection time in seconds with a milliseconds resolution (1.19.10)\nTCP information\n$tcpinfo_rtt, $tcpinfo_rttvar, $tcpinfo_snd_cwnd, $tcpinfo_rcv_space\ninformation about the client TCP connection; available on systems that support the TCP_INFO socket option"},"notes/NGINX/NGINX-IPv6-rate-limiting":{"slug":"notes/NGINX/NGINX-IPv6-rate-limiting","filePath":"notes/NGINX/NGINX IPv6 rate limiting.md","title":"NGINX IPv6 rate limiting","links":[],"tags":[],"content":"Use with realip module.\nmap $binary_remote_addr $subnet {\n    &quot;~^(\\C{8})&quot;         $1;\n    default             $binary_remote_addr;\n}\n\nlimit_req_zone $subnet zone=one:10m rate=1r/s;\n\nReferences\n\nmailman.nginx.org/pipermail/nginx/2021-April/060557.html\n"},"notes/NGINX/NGINX-code-walkthrough---Client-closed-request":{"slug":"notes/NGINX/NGINX-code-walkthrough---Client-closed-request","filePath":"notes/NGINX/NGINX code walkthrough - Client closed request.md","title":"NGINX code walkthrough - Client closed request","links":[],"tags":[],"content":"Description\n/*\n * HTTP does not define the code for the case when a client closed\n * the connection while we are processing its request so we introduce\n * own code to log such situation when a client has closed the connection\n * before we even try to send the HTTP header to it\n */\n#define NGX_HTTP_CLIENT_CLOSED_REQUEST     499\nWhile connecting to upstream\nIn ngx_http_upstream_connect(),\n    u-&gt;write_event_handler = ngx_http_upstream_send_request_handler;\n    u-&gt;read_event_handler = ngx_http_upstream_process_header;\nWhen ngx_http_upstream_next() is called,\n    if (r-&gt;connection-&gt;error) {\n        ngx_http_upstream_finalize_request(r, u,\n                                           NGX_HTTP_CLIENT_CLOSED_REQUEST);\n        return;\n    }\nIn ngx_http_upstream_finalize_request(),\n    if (!u-&gt;header_sent\n        || rc == NGX_HTTP_REQUEST_TIME_OUT\n        || rc == NGX_HTTP_CLIENT_CLOSED_REQUEST)\n    {\n        ngx_http_finalize_request(r, rc);\n        return;\n    }\nIn ngx_http_finalize_request(),\n    if (rc == NGX_ERROR\n        || rc == NGX_HTTP_REQUEST_TIME_OUT\n        || rc == NGX_HTTP_CLIENT_CLOSED_REQUEST\n        || c-&gt;error)\n    {\n        if (ngx_http_post_action(r) == NGX_OK) {\n            return;\n        }\n \n        ngx_http_terminate_request(r, rc);\n        return;\n    }\nngx_http_terminate_request() then calls ngx_http_close_request(), which finally calls ngx_http_free_request() and ngx_http_close_connection(). The first logs the request, and the second calls ngx_close_connection(), which leads us to ngx_close_socket() that calls close().\nSome other cases\nngx_http_upstream_init_request() first sets both event handlers to check for broken connections.\n    if (... &amp;&amp; !u-&gt;conf-&gt;ignore_client_abort) {\n        ...\n \n        r-&gt;read_event_handler = ngx_http_upstream_rd_check_broken_connection;\n        r-&gt;write_event_handler = ngx_http_upstream_wr_check_broken_connection;\n    }\nIf request body is not buffered, ngx_http_upstream_send_request_body() sets the read_event_handler to ngx_http_upstream_read_request_handler, but restores it to ngx_http_upstream_rd_check_broken_connection() once the client request body is fully read.\nBoth check functions call ngx_http_upstream_check_broken_connection(), which would finalize the client-side connection in the same way.\n        if (!u-&gt;cacheable) {\n            ngx_http_upstream_finalize_request(r, u,\n                                               NGX_HTTP_CLIENT_CLOSED_REQUEST);\n        }"},"notes/NGINX/NGINX-code-walkthrough---Upstream-connect-timeout":{"slug":"notes/NGINX/NGINX-code-walkthrough---Upstream-connect-timeout","filePath":"notes/NGINX/NGINX code walkthrough - Upstream connect timeout.md","title":"NGINX code walkthrough - Upstream connect timeout","links":[],"tags":[],"content":"Searching for a “stack trace”\nSituation 1: upstream server did not reply to our SYN within proxy_connect_timeout\n... upstream timed out (110: Connection timed out) while connection to upstream, ...\n\nFirst, proxy_connect_timeout is used in ngx_http_upstream_connect() to set a timer on c-&gt;write.\n    if (rc == NGX_AGAIN) {\n        ngx_add_timer(c-&gt;write, u-&gt;conf-&gt;connect_timeout);\n        return;\n    }\nSearch for the string &quot;upstream timed out&quot; returns 4 matches in src/http/ngx_http_upstream.c, and we’d like to find out which function handles such timeouts.\nAmong the 4 functions, ngx_http_upstream_process_upstream() and ngx_http_upstream_process_non_buffered_upstream() are called in ngx_http_upstream_send_response(), which is only called after reading the response header.\nngx_http_upstream_process_upgraded() is called for WebSocket upgrade, so we ignore that as well.\nThen we focus on the remaining ngx_http_upstream_next().\n    if (ft_type == NGX_HTTP_UPSTREAM_FT_TIMEOUT) {\n        ngx_log_error(NGX_LOG_ERR, r-&gt;connection-&gt;log, NGX_ETIMEDOUT,\n                      &quot;upstream timed out&quot;);\n    }\nA new keyword NGX_HTTP_UPSTREAM_FT_TIMEOUT, this brings our focus to ngx_http_upstream_send_request_handler().\n    if (c-&gt;write-&gt;timedout) {\n        ngx_http_upstream_next(r, u, NGX_HTTP_UPSTREAM_FT_TIMEOUT);\n        return;\n    }\nOn the other hand, let’s search for &quot;connecting to upstream&quot;, which is set in c-&gt;log-&gt;action and can be seen from the error log. There are 3 matches, but two of them has a different error text: &quot;connect() failed&quot;.\nThe last match is ngx_http_upstream_connect(). This function calls ngx_event_connect_peer() to establish a connection, and sets u-&gt;write_event_handler to ngx_http_upstream_send_request_handler.\nTherefore, the function call chain is\nngx_http_upstream_connect() → ngx_event_connect_peer() ^&gt; ngx_add_timer(c-&gt;write, u-&gt;conf-&gt;connect_timeout) ^&gt;\nevent loop in ngx_worker_process_cycle() → ngx_process_events_and_timers() → ngx_event_expire_timers() → ev-&gt;handler =\nc-&gt;write-&gt;handler → ngx_http_upstream_handler() → u-&gt;write_event_handler → ngx_http_upstream_send_request_handler() → ngx_http_upstream_next() →\n\nu-&gt;peer.free → ngx_http_upstream_free_round_robin_peer() ^&gt;\nngx_log_error() ^&gt;\n(if no more tries) ngx_http_upstream_finalize_request() →\nngx_close_connection() → ngx_close_socket() i.e. close() ^&gt;\nngx_http_upstream_connect() (retry next server)\n\nNote: ^&gt; represents subsequent execution after returning to the caller function, and → is a function call or pointer dereference.\nIf connection succeeded, the timer will be reset to send_timeout or cleared.\n        if (!c-&gt;write-&gt;ready || u-&gt;request_body_blocked) {\n            ngx_add_timer(c-&gt;write, u-&gt;conf-&gt;send_timeout);\n \n        } else if (c-&gt;write-&gt;timer_set) {\n            ngx_del_timer(c-&gt;write);\n        }\nSequence of events\n\nngx_event_connect_peer(): Connection is attempted.\nngx_http_upstream_handler(): Event loop detects the timeout and calls this handler.\nngx_http_upstream_free_round_robin_peer(): fails is accounted for and compared with max_fails to temporarily disable upstream servers.\nngx_log_error(): “upstream timed out” is logged.\nngx_close_connection(): old connection to upstream is closed.\n\nSituation 2: upstream server did not reply to our SYN within OS timeout\nWhen ngx_event_connect_peer() is called, both c-&gt;read and c-&gt;write are registered to the event loop.\n    rc = connect(s, pc-&gt;sockaddr, pc-&gt;socklen);\n \n    if (ngx_add_event(rev, NGX_READ_EVENT, event) != NGX_OK) {\n        goto failed;\n    }\n \n    if (rc == -1) {\n \n        /* NGX_EINPROGRESS */\n \n        if (ngx_add_event(wev, NGX_WRITE_EVENT, event) != NGX_OK) {\n            goto failed;\n        }\n \n        return NGX_AGAIN;\n    }\nLet’s see what connect(2) in System Calls Manual says about the comment NGX_EINPROGRESS.\n\nEINPROGRESS\nThe socket is nonblocking and the connection cannot be completed immediately. (UNIX domain sockets failed with EAGAIN instead.) It is possible to select(2) or poll(2) for completion by selecting the socket for writing. After select(2) indicates writability, use getsockopt(2) to read the SO_ERROR option at level SOL_SOCKET to determine whether connect() completed successfully (SO_ERROR is zero) or unsuccessfully (SO_ERROR is one of the usual error codes listed here, explaining the reason for the failure).\n\nIn this case, epoll receives the error as a write event and calls its handler. ngx_http_upstream_send_request_handler() then calls ngx_http_upstream_send_request(), which calls ngx_http_upstream_test_connect() and detects the failure.\n            if (flags &amp; NGX_POST_EVENTS) {\n                queue = rev-&gt;accept ? &amp;ngx_posted_accept_events\n                                    : &amp;ngx_posted_events;\n \n                ngx_post_event(rev, queue);\n \n            } else {\n                rev-&gt;handler(rev);\n            }\nIn ngx_http_upstream_test_connect(), error is logged as “connect() failed” on Linux.\n        if (err) {\n            c-&gt;log-&gt;action = &quot;connecting to upstream&quot;;\n            (void) ngx_connection_error(c, err, &quot;connect() failed&quot;);\n            return NGX_ERROR;\n        }\nTherefore, the function call chain is\nngx_http_upstream_connect() → ngx_event_connect_peer() ^&gt; ngx_add_timer(c-&gt;write, u-&gt;conf-&gt;connect_timeout) ^&gt;\nevent loop in ngx_worker_process_cycle() → ngx_process_events_and_timers() → ngx_process_events() = ngx_epoll_process_events() → rev-&gt;handler =\nc-&gt;write-&gt;handler → ngx_http_upstream_handler() → u-&gt;write_event_handler  → ngx_http_upstream_send_request_handler() →\nngx_http_upstream_send_request() →\n\nngx_http_upstream_test_connect() → ngx_connection_error() ^&gt;\nngx_http_upstream_next() → …\n\nSequence of events\n\nngx_event_connect_peer(): Connection is attempted.\nngx_http_upstream_handler(): Event loop detects the error and calls this handler.\nngx_http_upstream_test_connect(): check for failure and log “connect() failed.”\nngx_http_upstream_free_round_robin_peer(): fails is accounted for and compared with max_fails to temporarily disable upstream servers.\nngx_close_connection(): old connection to upstream is released.\n\nNotes\nA possibly better way to do this: set log level to debug, and simulate the connect timeout with a very low proxy_connect_timeout.\nReferences\n\ngithub.com/nginx/nginx/blob/788e462c5b81f5f1aee475488e10f01680c530e9/src/http/ngx_http_upstream.c\n"},"notes/NGINX/NGINX-error-log":{"slug":"notes/NGINX/NGINX-error-log","filePath":"notes/NGINX/NGINX error log.md","title":"NGINX error log","links":[],"tags":[],"content":"Format\nIn ngx_log_error_core, the cached time, log level surrounded by [], pid#tid: and *$connection (connection serial number, if exists) are “printed” first. Then, the error message from the arguments is formatted and printed. The resulting string is then passed to log-&gt;handler to get the final message to log.\nIn ngx_http_request.c, c-&gt;log-&gt;handler is set to ngx_http_log_error, which appends  while ... if there is a log-&gt;action, , client: ... (the connection’s client address), and passes the error message to r-&gt;log_handler.\nr-&gt;log_handler is ngx_http_log_error_handler, also defined in ngx_http_request.c. It appends , server: $server_name, the request line, sub-request if exists, upstream information if exists, Host request header if exists, and Referrer request header if exists.\nTherefore, the final format for an HTTP request is\n1970/09/28 12:00:00 [$err_level] $pid#$tid: *$connection_serial_number $error___message while $action, client: $connection_addr, server: $server_name, request: &quot;$request&quot;, subrequest: &quot;$sr-&gt;uri&quot;, upstream: &quot;schema://peer_name$upstream_uri&quot;, host: &quot;$http_host&quot;, referrer: &quot;$http_referer&quot;\n"},"notes/NGINX/NGINX-graceful-reload":{"slug":"notes/NGINX/NGINX-graceful-reload","filePath":"notes/NGINX/NGINX graceful reload.md","title":"NGINX graceful reload","links":[],"tags":[],"content":"Nginx is mostly graceful when reloading, except in the following situations:\n\nLong-lived connections like WebSocket, SSE and requests that take a long time to complete.\nA new request came in from an HTTP keep-alive connection right after reload is initiated.\nA new TCP connection in the SYN backlog or accept queue gets dropped if reuseport is enabled.\n\nThe second case can be mitigated by setting appropriate worker_shutdown_timeout and keepalive_min_timeout values. keepalive_min_timeout allows a subsequent request on the connection to be processed, and returns Connection: close in the response HTTP header to properly terminate the connection without race conditions.\nThe third case can be resolved with net.ipv4.tcp_migrate_req, a new feature introduced in Linux 5.14."},"notes/NGINX/NGINX-location-directive":{"slug":"notes/NGINX/NGINX-location-directive","filePath":"notes/NGINX/NGINX location directive.md","title":"NGINX location directive","links":[],"tags":[],"content":"proxy_pass redirecting\nIf a prefix-matching location ends with a slash (/), and requests are processed by proxy_pass, requests to the exact string minus the trailing slash are redirected to full URI (domain included) with slash appended.\nCase sensitivity\nOn case-sensitive operating systems, only ~* matches case-insensitively."},"notes/NGINX/NGINX-proxy-cache":{"slug":"notes/NGINX/NGINX-proxy-cache","filePath":"notes/NGINX/NGINX proxy cache.md","title":"NGINX proxy cache","links":[],"tags":[],"content":"Checklist\n\nDo not cache sensitive content without authentication token included in proxy_cache_key. It is recommended to include a random secret in the string to further prevent hash collision attacks.\nAvoid proxy_cache_valid any and use specific status codes.\nIf you want to limit the cache to certain arguments or other patterns, use proxy_no_cache and proxy_cache_bypass with a map-ed variable, where the string can be templated to match a set of conditions efficiently.\nWith proxy_cache_lock enabled, a request returning cached content may have been delayed by a lock, resulting in longer $request_time in logs.\nUse the following config to instruct NGINX to deliver stale content when clients request an item that is expired or is in the process of being updated from the origin server. All updates will be done in the background. The stale file is returned for all requests until the updated file is fully downloaded.\n\nproxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;\nproxy_cache_background_update on;\nproxy_cache_lock on;\n\n\nThe updating parameter to the proxy_cache_use_stale directive, combined with enabling the proxy_cache_background_update directive, instructs NGINX to deliver stale content when clients request an item that is expired or is in the process of being updated from the origin server. All updates will be done in the background. The stale file is returned for all requests until the updated file is fully downloaded.\n\nIf UPDATING starts to appear in $upstream_cache_status, background update is enabled.\nInstrumentation\nadd_header X-Cache-Status $upstream_cache_status;\n\nThis example adds an X-Cache-Status HTTP header in responses to clients. The following are the possible values for $upstream_cache_status:\n\nMISS – The response was not found in the cache and so was fetched from an origin server. The response might then have been cached.\nBYPASS – The response was fetched from the origin server instead of served from the cache because the request matched a proxy_cache_bypass directive (see Can I Punch a Hole Through My Cache? below.) The response might then have been cached.\nEXPIRED – The entry in the cache has expired. The response contains fresh content from the origin server.\nSTALE – The content is stale because the origin server is not responding correctly, and proxy_cache_use_stale was configured.\nUPDATING – The content is stale because the entry is currently being updated in response to a previous request, and proxy_cache_use_stale updating is configured.\nREVALIDATED – The proxy_cache_revalidate directive was enabled and NGINX verified that the current cached content was still valid (If-Modified-Since or If-None-Match).\nHIT – The response contains valid, fresh content direct from the cache.\n\nNotes\n\nCache data is stored in files. The filename in a cache is a result of applying the MD5 function to the cache key.\nIn addition, all active keys and information about data are stored in a shared memory zone, whose name and size are configured by the keys_zone parameter. One megabyte zone can store about 8 thousand keys.\n"},"notes/NGINX/NGINX-realip-configuration-for-Cloudflare":{"slug":"notes/NGINX/NGINX-realip-configuration-for-Cloudflare","filePath":"notes/NGINX/NGINX realip configuration for Cloudflare.md","title":"NGINX realip configuration for Cloudflare","links":[],"tags":[],"content":"If you also want to reject requests that aren’t from Cloudflare:\nhttp {\n    # Load realip module (if not already loaded)\n    load_module modules/ngx_http_realip_module.so;\n\n    # Include Cloudflare IPs for realip module\n    include /etc/nginx/cloudflare-ips.conf;\n\n    # Geo block to check if original IP is from Cloudflare\n    geo $realip_remote_addr $is_cloudflare {\n        default 0;\n        include /etc/nginx/cloudflare-ips-geo.conf;\n    }\n\n    # Use CF-Connecting-IP header for real client IP\n    real_ip_header CF-Connecting-IP;\n\n    server {\n        listen 80;\n        server_name example.com;\n\n        # Deny requests not from Cloudflare IPs\n        if ($is_cloudflare != 1) {\n            return 403;\n        }\n\n        # Rest of your configuration...\n    }\n}\n\nwhich references the following files with simple formats.\n# cloudflare-ips-geo.conf\n# Cloudflare IP ranges for geo module\n2400:cb00::/32 1;\n2606:4700::/32 1;\n2803:f800::/32 1;\n2405:b500::/32 1;\n2405:8100::/32 1;\n2a06:98c0::/29 1;\n\n# cloudflare-ips.conf\n# Cloudflare IP ranges for realip module\nset_real_ip_from 2400:cb00::/32;\nset_real_ip_from 2606:4700::/32;\nset_real_ip_from 2803:f800::/32;\nset_real_ip_from 2405:b500::/32;\nset_real_ip_from 2405:8100::/32;\nset_real_ip_from 2a06:98c0::/29;\n\nUpdating\nHere’s a reference script for fetching updates. You could run it periodically via cron.\n#!/bin/bash\n \n# Fetch Cloudflare IP ranges\ncurl -s www.cloudflare.com/ips-v4 -o /tmp/cf-ips-v4\ncurl -s www.cloudflare.com/ips-v6 -o /tmp/cf-ips-v6\n \n# Generate set_real_ip_from directives\necho &quot;# Cloudflare IP ranges for realip module&quot; &gt; /etc/nginx/cloudflare-ips.conf\ncat /tmp/cf-ips-v4 | while read line; do\n    echo &quot;set_real_ip_from $line;&quot; &gt;&gt; /etc/nginx/cloudflare-ips.conf\ndone\ncat /tmp/cf-ips-v6 | while read line; do\n    echo &quot;set_real_ip_from $line;&quot; &gt;&gt; /etc/nginx/cloudflare-ips.conf\ndone\n \n# Generate geo block entries\necho &quot;# Cloudflare IP ranges for geo module&quot; &gt; /etc/nginx/cloudflare-ips-geo.conf\ncat /tmp/cf-ips-v4 | while read line; do\n    echo &quot;$line 1;&quot; &gt;&gt; /etc/nginx/cloudflare-ips-geo.conf\ndone\ncat /tmp/cf-ips-v6 | while read line; do\n    echo &quot;$line 1;&quot; &gt;&gt; /etc/nginx/cloudflare-ips-geo.conf\ndone\n \n# Test and reload NGINX\nnginx -t &amp;&amp; systemctl reload nginx"},"notes/NGINX/NGINX-thundering-herd-problem":{"slug":"notes/NGINX/NGINX-thundering-herd-problem","filePath":"notes/NGINX/NGINX thundering herd problem.md","title":"NGINX thundering herd problem","links":["notes/Operating-System/Linux/epoll","notes/Operating-System/Linux/SO_REUSEPORT"],"tags":[],"content":"Solution 1: EPOLLEXCLUSIVE flag\nIf EPOLLEXCLUSIVE (Linux 4.5, glibc 2.24) is defined when compiling NGINX, NGINX could make use of it to reduce resource usage when volume of new connection is low.\nNGINX discards EPOLLRDHUP if EPOLLEXCLUSIVE is enabled, keeping EPOLLIN and EPOLLOUT compatible with the CentOS 7 backport.\n#if (NGX_HAVE_EPOLLEXCLUSIVE &amp;&amp; NGX_HAVE_EPOLLRDHUP)\n    if (flags &amp; NGX_EXCLUSIVE_EVENT) {\n        events &amp;= ~EPOLLRDHUP;\n    }\n#endif\nFor every 16 requests handled, NGINX would re-add the socket in ngx_reorder_accept_events() to balance request across workers.\n    if (c-&gt;requests++ % 16 != 0\n        &amp;&amp; ngx_accept_disabled &lt;= 0)\n    {\n        return;\n    }\n \n    if (ngx_del_event(c-&gt;read, NGX_READ_EVENT, NGX_DISABLE_EVENT)\n        == NGX_ERROR)\n    {\n        return;\n    }\n \n    if (ngx_add_event(c-&gt;read, NGX_READ_EVENT, NGX_EXCLUSIVE_EVENT)\n        == NGX_ERROR)\n    {\n        return;\n    }\nSolution 2: listen reuseport\nSO_REUSEPORT could significantly increase the max latency in a degraded state. See blog.cloudflare.com/the-sad-state-of-linux-socket-balancing/.\nAs a side effect, total length of pending connection queue (backlog) is multiplied by the number of workers because each worker has its own socket and therefore gets its own accept queue.\nIf you intend to set reuseport on listen, you should consider enabling the net.ipv4.tcp_migrate_req kernel parameter (Linux v5.14+ only) to reduce impact on in-flight request sockets during the handshake and established sockets in the accept queue during configuration reload."},"notes/NGINX/openresty/Customize-error-page-of-ngx.exit":{"slug":"notes/NGINX/openresty/Customize-error-page-of-ngx.exit","filePath":"notes/NGINX/openresty/Customize error page of ngx.exit.md","title":"Customize error page of ngx.exit","links":[],"tags":[],"content":"This is an example of templating responses for ngx.exit(494) calls from the “legalban” Lua module.\n# in `server` context\nerror_page 494 =451 @legal_ban;\n \nlocation @legal_ban {\n    # Prevent internal redirection cycle.\n    access_by_lua_block {\n        return\n    }\n    root html;\n    try_files /assets/legal/region_block.html =451;\n    charset utf-8;\n    add_header Cache-Control &quot;no-store&quot; always;\n}\n \nlocation /assets/legal {\n    # Always allow static assets to be accessed.\n    access_by_lua_block {\n        return\n    }\n    root html;\n    charset utf-8;\n    expires 30d;\n}\n \n# Restrict access by client IP\naccess_by_lua_block {\n    require(&#039;legalban&#039;).access(ngx.var.remote_addr) # which calls ngx.exit(494) if IP is banned.\n}\nFirst, we defined a custom response code 494 for the ban and its internal redirect to @legal_ban. With this, we can return different pages for the same response code 451. If you only have one predefined response per code to send, we can use it directly and skip the response code override in 494 =451.\nThen, we define the named location @legal_ban that returns a static HTML file from $prefix/html. If the response code is not in the add_header-specific list, you need always to make that directive work. *_by_lua_block { return } is only needed if there is a cycle of internal redirection, which is the case in our example.\nNote that charset utf-8; and properly configuring types (which is included in the default configuration) combined makes NGINX return the correct content-type text/html; charset=utf-8.\nThird, we defined the assets our error page needs, for example .js files and images. These should be referenced by absolute path in our HTML file, and should be always accessible. Therefore, we disable access control with access_by_lua_block { return } and uses a regular location. We also set expires 30d; to allow clients to cache them and reduce server load.\nIf possible, make the HTML file standalone or depend on resources from third-party domains only to remove the third step altogether. This would significantly simplify our configuration.\nFinally, we put access_by_lua_block { ... } here to execute our “legalban” module on every request, and reject those that came from regions we cannot serve for legal reasons."},"notes/NGINX/openresty/OpenResty-Lua-linter":{"slug":"notes/NGINX/openresty/OpenResty-Lua-linter","filePath":"notes/NGINX/openresty/OpenResty Lua linter.md","title":"OpenResty Lua linter","links":[],"tags":[],"content":"Tools\n\nUse lj-releng or luacheck to identify global variable references.\n\nTips\n\nYou can cache ngx to a local variable.\n\nlocal ngx = ngx\n\nAlways include _VERSION in your module. For example, in the conn module,\n\nlocal _M = {\n  _VERSION = &quot;0.0.1&quot;\n}\n \nlocal mt = { __index = _M }\n \nfunction _M.new(options)\n  local self = { ... }\n  return setmetatable(self, mt)\nend\n \nfunction _M.access(self, remote_addr)\n  ...\nend\n \nreturn _M\n\nYou can call the preceding functions via require(&#039;conn&#039;).new({}) and filter:access(remote_addr) where filter is an object of conn.\n"},"notes/NGINX/proxy/Headers-in-NGINX":{"slug":"notes/NGINX/proxy/Headers-in-NGINX","filePath":"notes/NGINX/proxy/Headers in NGINX.md","title":"Headers in NGINX","links":[],"tags":[],"content":"The default set of headers passed to upstream is defined in ngx_http_proxy_headers.\nstatic ngx_keyval_t  ngx_http_proxy_headers[] = {\n    { ngx_string(&quot;Host&quot;), ngx_string(&quot;$proxy_host&quot;) },\n    { ngx_string(&quot;Connection&quot;), ngx_string(&quot;close&quot;) },\n    { ngx_string(&quot;Content-Length&quot;), ngx_string(&quot;$proxy_internal_body_length&quot;) },\n    { ngx_string(&quot;Transfer-Encoding&quot;), ngx_string(&quot;$proxy_internal_chunked&quot;) },\n    { ngx_string(&quot;TE&quot;), ngx_string(&quot;&quot;) },\n    { ngx_string(&quot;Keep-Alive&quot;), ngx_string(&quot;&quot;) },\n    { ngx_string(&quot;Expect&quot;), ngx_string(&quot;&quot;) },\n    { ngx_string(&quot;Upgrade&quot;), ngx_string(&quot;&quot;) },\n    { ngx_null_string, ngx_null_string }\n};"},"notes/NGINX/proxy/Health-Checks-in-NGINX":{"slug":"notes/NGINX/proxy/Health-Checks-in-NGINX","filePath":"notes/NGINX/proxy/Health Checks in NGINX.md","title":"Health Checks in NGINX","links":["notes/NGINX/proxy/How-NGINX-round-robin-upstream-implements-passive-health-checks"],"tags":[],"content":"If NGINX upstream points at a load balancer and overloading is not of concern, you can set max_fails to 0 to turn off passive health checks.\nSee also How NGINX round-robin upstream implements passive health checks."},"notes/NGINX/proxy/How-NGINX-round-robin-upstream-implements-passive-health-checks":{"slug":"notes/NGINX/proxy/How-NGINX-round-robin-upstream-implements-passive-health-checks","filePath":"notes/NGINX/proxy/How NGINX round-robin upstream implements passive health checks.md","title":"How NGINX round-robin upstream implements passive health checks","links":[],"tags":[],"content":"Based on NGINX 1.27.4\nPassive health checks\npeer-&gt;accessed represents the last failure time. It is initialized as 0, and set to the current time ngx_time() along with peer-&gt;checked when any request to the peer failed.\npeer-&gt;checked represents the start of the current error window. It is set to current time when the peer is selected as best, and subsequently updated to the current time if peer is selected again after fail_timeout has passed (i.e. time since last checked is over fail_timeout), or when any request to the peer failed.\npeer-&gt;fails represents the number of failures observed during the current error window. It is incremented on each failure, and reset to 0 if check passed for a request AND peer-&gt;accessed &lt; peer-&gt;checked, i.e. peer-&gt;checked was refreshed but peer-&gt;accessed was not. Given that peer-&gt;accessed is a moving goalpost that bumps on each failure event, it’s possible that fails accumulate across multiple fail_timeout time spans if failures continue to happen.\nIf max_fails is not 0, failure condition is met (peer-&gt;fails &gt;= peer-&gt;max_fails) and we are still within the error window (now - peer-&gt;checked &lt;= peer-&gt;fail_timeout), the peer is skipped in the peer selection process.\nCombination of the conditions above raises an interesting question. If there is a continuous stream of failures that happens at an interval shorter than fail_timeout, will fails accumulate to trigger the peer failure condition, or will it be hard reset after each fail_timeout?\nAn interesting behavior of NGINX is that it decrements effective_weight by peer-&gt;weight / peer-&gt;max_fails (integer division!), and increments it by 1 up to weight whenever the peer is considered for use, so there is a penalty in effective weight for failures if peer-&gt;weight / peer-&gt;max_fails is not 0. This penalty reduces the number of requests the peer receives, and subsequently makes a continuous stream of failures less likely to hold.\nAnd even if a peer is temporarily disabled, no new requests would select that peer, so it’s safe to assume that after fail_timeout the counter will be reset as the error window passes and new requests pass the check. If the first requests completed did not pass the check, peer-&gt;checked will be bumped along with peer-&gt;accessed and the peer will be disabled again immediately.\nNonetheless, imperfection of the algorithm makes it nonconforming to the NGINX documentation, which states that fail_timeout is “the time during which the specified number of unsuccessful attempts to communicate with the server should happen to consider the server unavailable.”\n\n\n                  \n                  NOTE\n                  \n                \n\nTakeaway from this: Always set weight to an integer greater than or equal to max_fails, otherwise the weight penalty is ineffective.\n\n\nHistory\nFrom Maxim Dounin, www.mail-archive.com/nginx-devel@nginx.org/msg00514.html\n\nThis is expected behaviour.  Documentation is a bit simplified\nhere, and fail_timeout is used like session time limit - the\npeer→fails counter is reset once there are no failures within\nfail_timeout.\nWhile this might be non-ideal for some use cases, it’s certainly\nnot a bug.\n\nA proposed fix was rejected because\n\nSuch algorithm forget everything about previous failures once per\nfail_timeout, and won’t detect bursts of failures split across\ntwo fail_timeout intervals.\n\nand in a later email,\n\nWell, in normal world if an upstream constantly fails ~1% of\nrequests - it’s not healthy and should not be used.  I\nunderstand that your use case is a bit special though.\n\n\n\nYes, I know this case, sorry, forgot to mention. However, I think it will\nextend detection period to 2-3 fail_timeouts in real life (in theory up to\nmax_fails fail_timeouts, yes, but it’s almost improbable). If we want correct\nimplementation we need per-second array (with fail_timeout elements), that’s\nan\noverkill in my opinion.\n\nSure, per-second array isn’t a solution.\n\nBy the way, leaky bucket approach (like limit_req but\nwith fails per second) might work well here, what do you think?\n\nYes, leaky/token bucket should work.  That’s actually what I think\nabout if I think about changing the above algorithm to something\nstrictly bound to fail_timeout period.\n\nSo Maxim is against the per-second array solution.\nA few years later, www.mail-archive.com/nginx-devel@nginx.org/msg09804.html\n\nDocumentation somewhat oversimplifies things.  The fail_timeout\nsetting is essentially a session timeout, and things work as\nfollows:\n\n\nAs long as there are failures, the fails counter is\nincremented.  If fail_timeout passes since last failure, the fails\ncounter is reset to 0 on the next successful request.\n\n\nIf the fails counter reaches max_fails, no more requests are\nrouted to the peer for fail_timeout time.  After fail_timeout passes,\none request is allowed.  If the request is successful, the fails\ncounter is reset to 0, and further requests to the peer are\nallowed without any limits.\n\n\n\nReferences:\n\nwww.mail-archive.com/search@nginx.org&amp;q=subject:“%5C[BUG%5C?%5C]fail_timeout%5C/max_fails%5C:+code+doesn’t+do+what+doc+says”&amp;o=newest&amp;f=1\n\nalso on nginx.org as mailman.nginx.org/pipermail/nginx-devel/2013-May/003753.html\n\n\nwww.mail-archive.com/search@nginx.org&amp;q=subject:“incorrect+upstream+max_fails+behaviour”&amp;o=newest&amp;f=1\n\nalso on nginx.org as mailman.nginx.org/pipermail/nginx-devel/2020-March/013070.html\n\n\n\nDemo\nSet up NGINX with 1 worker process and two local servers listening on port 3000 and 3001 that always returns 503, and an upstream that points to both servers with max_fails=120 fail_timeout=3s. Then, set up a third server listening on port 3002 that proxy_pass to this upstream and have proxy_next_upstream error timeout http_503 set. Finally, we request the server with roughly 0.5s interval and observe if the error log contains “no live upstreams”.\nThe result from NGINX 1.27.4 confirms our assumption. About 2 minutes later, which is enough time for both upstream servers to reach 60 fails because each request is retried against both servers, NGINX logs “no live upstreams” for all subsequent requests.\nWe also observed a weird behavior that occasionally, the error log would stop for a while after 6 requests, and then returns to the same pattern of continuous errors or another 6 lines of logs. If the pause is about 2 minutes, the peer-&gt;fails counter might have been reset for both peers, so it’s likely that somehow state &amp; NGX_PEER_FAILED was false when the peer used is freed.\nBackup servers\nNGINX only considers the backup servers stored in peers-&gt;next if either ngx_http_upstream_get_peer() did not get a peer (returns NULL) from the primary servers, or the single primary server is down or has reached max_conns."},"notes/NGINX/proxy/Upstream-Keepalive":{"slug":"notes/NGINX/proxy/Upstream-Keepalive","filePath":"notes/NGINX/proxy/Upstream Keepalive.md","title":"Upstream Keepalive","links":["notes/NGINX/proxy/Headers-in-NGINX"],"tags":[],"content":"To enable keepalive connections to upstream, the keepalive directive must be included in upstream{} blocks, and in the location{} blocks you need to switch HTTP version to 1.1 and clear the default Connection: close request header set by NGINX. See Headers in NGINX.\nproxy_http_version 1.1;\nproxy_set_header   &quot;Connection&quot; &quot;&quot;;\n\n\nIt should be particularly noted that the keepalive directive does not limit the total number of connections to upstream servers that an nginx worker process can open. The _connections_ parameter should be set to a number small enough to let upstream servers process new incoming connections as well.\n\nAlso note that if you have keepalive set in the upstream and max_conns set on a server,\n\nmultiple workers, and the shared memory are enabled, the total number of active and idle connections to the proxied server may exceed the max_conns value.\n\nSo choose the number of keepalive connections carefully.\nYou may also want to customize keepalive_requests and keepalive_timeout, but the defaults are reasonable enough.\nReferences\nnginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive"},"notes/Network/Cloudflare":{"slug":"notes/Network/Cloudflare","filePath":"notes/Network/Cloudflare.md","title":"Cloudflare","links":["notes/NGINX/NGINX-realip-configuration-for-Cloudflare"],"tags":[],"content":"First steps after creating a site\nSet TLS encryption mode to Full (strict).\nngx_http_realip_module\nSee NGINX realip configuration for Cloudflare."},"notes/Network/Configure-additional-static-IP-with-netplan":{"slug":"notes/Network/Configure-additional-static-IP-with-netplan","filePath":"notes/Network/Configure additional static IP with netplan.md","title":"Configure additional static IP with netplan","links":[],"tags":[],"content":"It’s not advised to overwrite the .yaml file cloud-init created. Instead, we could only list the additional IPs like so:\nnetwork:\n  version: 2\n  ethernets:\n    eth0:\n      addresses:\n        - 10.10.10.2/24\nThis works because netplan generates config by merging YAML files, and the rules are that sequence values are concatenated, with the new values appended to the old list. See netplan-generate(8) for details.\nAlternatively, you could create /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg as follows to prevent cloud-init from changing network configuration again:\nnetwork:\n  config: disabled\nHowever, this approach would prevent the image to be reused for another instance."},"notes/Network/DNS-caching":{"slug":"notes/Network/DNS-caching","filePath":"notes/Network/DNS caching.md","title":"DNS caching","links":[],"tags":[],"content":"JVM\nJava SE 17 defaults to caching DNS lookups forever if a Security Manager is installed. Override networkaddress.cache.ttl if you are still using the deprecated Security Manager to avoid connecting to the wrong IP addresses. Without a Security Manager installed, the default TTL is 30 seconds in HotSpot."},"notes/Network/Direct-Server-Return":{"slug":"notes/Network/Direct-Server-Return","filePath":"notes/Network/Direct Server Return.md","title":"Direct Server Return","links":["notes/Cloud/Azure/Azure-Load-Balancer"],"tags":["networking"],"content":"Azure\nImplemented in Azure. See Azure Load Balancer.\nGoogle Cloud\nGoogle Cloud implements this in external and internal passthrough Network Load Balancers. cloud.google.com/load-balancing/docs/network\nAWS\nAWS NLB does not make use of it.\nrepost.aws/questions/QUNtYRmHbDRNyJ1g8ltLwnOA/nlb-ip-preservation-over-peering-target-group\n\nThere is no DSR as you correctly mentioned, the AWS SDN handles the connection in such a way that the Client IP is preserved and traffic is still (symmetrically) routed via NLB.\n"},"notes/Network/Ethernet-frame":{"slug":"notes/Network/Ethernet-frame","filePath":"notes/Network/Ethernet frame.md","title":"Ethernet frame","links":[],"tags":[],"content":"Endianness\nEthernet transmits data with the most-significant octet first. This is considered a big-endian system, with data transmitted in network order.\nWhile higher-level network protocols usually consider octet as their atomic unit, Ethernet belongs to the lowest layers of a network stack and has to deal with ordering of bits within an octet. In Ethernet, the least-significant bit is transmitted first within each octet."},"notes/Network/Get-URL-of-new-tab-opened-by-JavaScript-in-Firefox":{"slug":"notes/Network/Get-URL-of-new-tab-opened-by-JavaScript-in-Firefox","filePath":"notes/Network/Get URL of new tab opened by JavaScript in Firefox.md","title":"Get URL of new tab opened by JavaScript in Firefox","links":[],"tags":[],"content":"\nOpen the browser console with Ctrl + Shift + J.\nSelect multiprocess mode.\n\n“Parent process only” mode only captures the main Firefox browser process, not the child processes that render web content.\n\n\nClick the gear icon on the right and enable network monitoring in the popup menu.\nEnsure “requests” is selected.\n(Optional) clear old logs with the trash bin icon on the left.\nClick the link and check for request logs in the browser console.\n"},"notes/Network/Global-DNS-lookup-and-ping-services":{"slug":"notes/Network/Global-DNS-lookup-and-ping-services","filePath":"notes/Network/Global DNS lookup and ping services.md","title":"Global DNS lookup and ping services","links":["notes/SRE/Latency-Numbers"],"tags":[],"content":"Web\nDNS\n\ngithub.com/ccbikai/DNS.Surf\n\nPing\n\nping.pe/ (DNS resolution is performed once in central location)\nping.sx/\nglobalping.io/ (max 500 endpoints per run, limited to 100000 per hour aggregated)\ntools.bunny.net/latency-test\nmtr.tools/\n\nLocal DNS only\n\nwww.akamai.com/blog/developers/introducing-new-whoami-tool-dns-resolver-information\nbrowserleaks.com/dns\n\nFor China mainland\n\ntools.ipip.net/newping.php (UI in Chinese)\n\nReverse ping (latency to global locations)\n\nwww.meter.net/tools/world-ping-test/\n\nASN lookup\n\nasn.cymru.com/ (You may also query via WHOIS or DNS protocols, see www.team-cymru.com/ip-asn-mapping.)\n\nHTTP request\n\nwww.openstatus.dev/play/checker (no request body allowed)\n\nLatency between IDC locations\n\nLatency Numbers\nwondernetwork.com/pings\n"},"notes/Network/ICMP-ping-packet-size":{"slug":"notes/Network/ICMP-ping-packet-size","filePath":"notes/Network/ICMP ping packet size.md","title":"ICMP ping packet size","links":["notes/Network/Path-MTU-Discovery"],"tags":[],"content":"There are 8 bytes of ICMP header and 20 bytes of IPv4 or 40 bytes of IPv6 header for an Echo Request, so with -s of 8000, each ICMPv6 packet is actually 8048=40+8+8000 bytes, and for ICMP it’s typically 8028=20+8+8000 bytes.\nFor the common 1500 bytes MTU, use ping6 &lt;addr&gt; -s 1452. See also Path MTU Discovery."},"notes/Network/IP-and-BGP-ASN-data-lookup-services":{"slug":"notes/Network/IP-and-BGP-ASN-data-lookup-services","filePath":"notes/Network/IP and BGP ASN data lookup services.md","title":"IP and BGP ASN data lookup services","links":[],"tags":[],"content":"Web\nGlobal\n\nHurricane Electric BGP Toolkit\nbgp.tools/ can discover recursive DNS (“local DNS”) resolver IPs.\nradar.cloudflare.com/ (speed.cloudflare.com/ shows link to current ASN on Radar)\n\nChina (for users in Mainland China)\n\nping.huatuo.qq.com/\n\nAPI\nGlobal\n\nip.guide/\nifconfig.co/\nifconfig.me/\nwww.cloudflare.com/cdn-cgi/trace\n"},"notes/Network/IPv6-firewall":{"slug":"notes/Network/IPv6-firewall","filePath":"notes/Network/IPv6 firewall.md","title":"IPv6 firewall","links":[],"tags":[],"content":"Packets that must not be dropped\nError messages that are essential to the establishment and maintenance of communications:\no  Destination Unreachable (Type 1) - All codes\no  Packet Too Big (Type 2)\no  Time Exceeded (Type 3) - Code 0 only\no  Parameter Problem (Type 4) - Codes 1 and 2 only\nConnectivity checking messages:\no  Echo Request (Type 128)\no  Echo Response (Type 129)\nPath MTU\nDebugging MTU issues is notoriously hard. Path MTU is not guaranteed to work, and varies by source and destination network.\nReferences\n\ndatatracker.ietf.org/doc/html/rfc4890\nblog.cloudflare.com/increasing-ipv6-mtu/\n"},"notes/Network/IPv6-in-IPv4-tunnel":{"slug":"notes/Network/IPv6-in-IPv4-tunnel","filePath":"notes/Network/IPv6 in IPv4 tunnel.md","title":"IPv6 in IPv4 tunnel","links":[],"tags":[],"content":"Protocol 41\n6in4\nHurricane Electric’s IPv6 Tunnel Broker uses this protocol. The prefix allocated is owned by the SP.\n6rd\nAn SP could set up 6rd Border Relays that is delegated a 6rd prefix. The prefix is owned by the SP.\n6to4\n6to4 addresses starts with 2002:, followed by the IPv4 address of its router. The prefix is announced by multiple ASes.\nTeredo\nTeredo addresses starts with 2001:0000:. The prefix is announced by multiple ASes.\nSee also\n\nopenwrt.org/docs/guide-user/network/ipv6/ipv6tunnel-luci\n\nReferences\n\ndatatracker.ietf.org/doc/html/rfc5969\n"},"notes/Network/NIC-offload":{"slug":"notes/Network/NIC-offload","filePath":"notes/Network/NIC offload.md","title":"NIC offload","links":["notes/Network/NIC-scaling-and-steering"],"tags":[],"content":"Hardware offloading\nTCP Segmentation Offload (TSO)\nUses the TCP protocol to send large packets. Uses the NIC to handle segmentation, and then adds the TCP, IP and data link layer protocol headers to each segment.\nUDP Fragmentation Offload (UFO)\nUses the UDP protocol to send large packets. Uses the NIC to handle IP fragmentation into MTU sized packets for large UDP datagrams.\nLarge Receive Offload (LRO)\nUses the TCP protocol. All incoming packets are re-segmented as they are received, reducing the number of segments the system has to process. They can be merged either in the driver or using the NIC. A problem with LRO is that it tends to re-segment all incoming packets, often ignoring differences in headers and other information which can cause errors.\nIt is generally not possible to use LRO when IP forwarding is enabled. LRO in combination with IP forwarding can lead to checksum errors. Forwarding is enabled if /proc/sys/net/ipv4/ip_forward is set to 1.\nWith mlx5 driver, RFS cannot function if LRO is enabled. See also NIC scaling and steering.\nChecksum offload\nThe driver can indicate to the Linux Networking Stack that the hardware successfully validated the IP and L4 checksum so the Linux Networking Stack does not need to deal with IP/L4 Checksum validation.\nSoftware offloading\nGeneric Segmentation Offload (GSO)\nUses the TCP or UDP protocol to send large packets. If the NIC cannot handle segmentation/fragmentation, GSO performs the same operations, bypassing the NIC hardware. This is achieved by delaying segmentation until as late as possible, for example, when the packet is processed by the device driver.\nGeneric Receive Offload (GRO)\nUses either the TCP or UDP protocols. GRO is more rigorous than LRO when resegmenting packets. For example it checks the MAC headers of each packet, which must match, only a limited number of TCP or IP headers can be different, and the TCP timestamps must match. Resegmenting can be handled by either the NIC or the GSO code.\nReferences\n\ndocs.redhat.com/en/documentation/red_hat_enterprise_linux/6/html/performance_tuning_guide/network-nic-offloads\ndocs.nvidia.com/nvidia-mlnx-en-documentation-v23-10-2-1-3-1-lts.pdf\n"},"notes/Network/NIC-scaling-and-steering":{"slug":"notes/Network/NIC-scaling-and-steering","filePath":"notes/Network/NIC scaling and steering.md","title":"NIC scaling and steering","links":["notes/Operating-System/Linux/SO_REUSEPORT"],"tags":[],"content":"Receive (RX)\nflowchart LR\n    nic[NIC hardware buffer]\n    irq[hard IRQ]\n    softirq[soft IRQ]\n    recvq[app socket queue]\n    app[application]\n    nic==&gt;irq==&gt;softirq==&gt;recvq==&gt;app\n\nScaling for multi-core system is implemented with hardware-based Receive-Side Scaling (RSS).\nIf the number of hardware queue of a single network interface card becomes a bottleneck, software-based Receive Packet Steering (RPS) can be used to further distribute load across CPU cores, at the cost of increased inter-processor interrupts.\nReceive Flow Steering (RFS) extends RPS behavior to increase the CPU cache hit rate and thereby reduce network latency. RFS uses the RPS backend to calculate the most appropriate CPU, then forwards packets based on the location of the application consuming the packet.\nAccelerated RFS (aRFS) boosts the speed of RFS by adding hardware assistance. Unlike traditional RFS, however, packets are sent directly to a CPU that is local to the thread consuming the data.\nOn the other hand, the Linux kernel’s SO_ATTACH_REUSEPORT_EBPF option allows a program to attach a fully functional BPF program as a load balancing algorithm, which can be used to steer packets as well.\nBoth aRFS and SO_REUSEPORT locality can improve CPU cache efficiency, but the performance improvement is usually negligible when compared to other CPU or I/O intensive operations.\nTransmit (TX)\nIn hosts with a network interface controller (NIC) that supports multiple queues, transmit packet steering (XPS) distributes the processing of outgoing network packets among several queues. This enables multiple CPUs to process the outgoing network traffic and to avoid transmit queue lock contention and, consequently, packet drops.\nCertain drivers, such as ixgbe, i40e, and mlx5 automatically configure XPS. To identify if the driver supports this capability, consult the documentation of your NIC driver. Consult your NIC driver’s documentation to identify if the driver supports this capability. If the driver does not support XPS auto-tuning, you can manually assign CPU cores to the transmit queues.\nReferences\n\ndocs.kernel.org/networking/scaling.html\ndocs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/tuning-the-network-performance_monitoring-and-managing-system-status-and-performance\n"},"notes/Network/OpenWrt/OpenWrt-DFS-channel-experiment":{"slug":"notes/Network/OpenWrt/OpenWrt-DFS-channel-experiment","filePath":"notes/Network/OpenWrt/OpenWrt DFS channel experiment.md","title":"OpenWrt DFS channel experiment","links":[],"tags":[],"content":"\nThis option allows hostapd to select one of the provided channels when a channel should be automatically selected.\n\nuci set wireless.radio0.channel=auto\nuci add_list wireless.radio0.channels=52-144\nuci commit\n \nwifi"},"notes/Network/OpenWrt/Reload-installed-LuCI-protocols":{"slug":"notes/Network/OpenWrt/Reload-installed-LuCI-protocols","filePath":"notes/Network/OpenWrt/Reload installed LuCI protocols.md","title":"Reload installed LuCI protocols","links":[],"tags":[],"content":"After installing a new protocol for LuCI, it does not appear immediately in the LuCI interface. Restart network from System → Startup to make it happen. This is the same as executing /etc/init.d/network restart over SSH."},"notes/Network/OpenWrt/Restore-eefault-OpenWrt-config":{"slug":"notes/Network/OpenWrt/Restore-eefault-OpenWrt-config","filePath":"notes/Network/OpenWrt/Restore eefault OpenWrt config.md","title":"Restore eefault OpenWrt config","links":[],"tags":[],"content":"You can get the “stock” configuration for OpenWrt from the /rom/etc/config directory.\nFor example, /rom/etc/config/firewall contains the following.\n\n\n                  \n                  Config could be rewritten \n                  \n                \n\nIf changes were made with LuCI or UCI, e.g. luci-app-firewall: migrate syn_flood option to synflood_protect on save.\n\n\nconfig defaults\n\toption syn_flood\t1\n\toption input\t\tREJECT\n\toption output\t\tACCEPT\n\toption forward\t\tREJECT\n# Uncomment this line to disable ipv6 rules\n#\toption disable_ipv6\t1\n \nconfig zone\n\toption name\t\tlan\n\tlist   network\t\t&#039;lan&#039;\n\toption input\t\tACCEPT\n\toption output\t\tACCEPT\n\toption forward\t\tACCEPT\n \nconfig zone\n\toption name\t\twan\n\tlist   network\t\t&#039;wan&#039;\n\tlist   network\t\t&#039;wan6&#039;\n\toption input\t\tREJECT\n\toption output\t\tACCEPT\n\toption forward\t\tREJECT\n\toption masq\t\t1\n\toption mtu_fix\t\t1\n \nconfig forwarding\n\toption src\t\tlan\n\toption dest\t\twan\n \n# We need to accept udp packets on port 68,\n# see dev.openwrt.org/ticket/4108\nconfig rule\n\toption name\t\tAllow-DHCP-Renew\n\toption src\t\twan\n\toption proto\t\tudp\n\toption dest_port\t68\n\toption target\t\tACCEPT\n\toption family\t\tipv4\n \n# Allow IPv4 ping\nconfig rule\n\toption name\t\tAllow-Ping\n\toption src\t\twan\n\toption proto\t\ticmp\n\toption icmp_type\techo-request\n\toption family\t\tipv4\n\toption target\t\tACCEPT\n \nconfig rule\n\toption name\t\tAllow-IGMP\n\toption src\t\twan\n\toption proto\t\tigmp\n\toption family\t\tipv4\n\toption target\t\tACCEPT\n \n# Allow DHCPv6 replies\n# see github.com/openwrt/openwrt/issues/5066\nconfig rule\n\toption name\t\tAllow-DHCPv6\n\toption src\t\twan\n\toption proto\t\tudp\n\toption dest_port\t546\n\toption family\t\tipv6\n\toption target\t\tACCEPT\n \nconfig rule\n\toption name\t\tAllow-MLD\n\toption src\t\twan\n\toption proto\t\ticmp\n\toption src_ip\t\tfe80::/10\n\tlist icmp_type\t\t&#039;130/0&#039;\n\tlist icmp_type\t\t&#039;131/0&#039;\n\tlist icmp_type\t\t&#039;132/0&#039;\n\tlist icmp_type\t\t&#039;143/0&#039;\n\toption family\t\tipv6\n\toption target\t\tACCEPT\n \n# Allow essential incoming IPv6 ICMP traffic\nconfig rule\n\toption name\t\tAllow-ICMPv6-Input\n\toption src\t\twan\n\toption proto\ticmp\n\tlist icmp_type\t\techo-request\n\tlist icmp_type\t\techo-reply\n\tlist icmp_type\t\tdestination-unreachable\n\tlist icmp_type\t\tpacket-too-big\n\tlist icmp_type\t\ttime-exceeded\n\tlist icmp_type\t\tbad-header\n\tlist icmp_type\t\tunknown-header-type\n\tlist icmp_type\t\trouter-solicitation\n\tlist icmp_type\t\tneighbour-solicitation\n\tlist icmp_type\t\trouter-advertisement\n\tlist icmp_type\t\tneighbour-advertisement\n\toption limit\t\t1000/sec\n\toption family\t\tipv6\n\toption target\t\tACCEPT\n \n# Allow essential forwarded IPv6 ICMP traffic\nconfig rule\n\toption name\t\tAllow-ICMPv6-Forward\n\toption src\t\twan\n\toption dest\t\t*\n\toption proto\t\ticmp\n\tlist icmp_type\t\techo-request\n\tlist icmp_type\t\techo-reply\n\tlist icmp_type\t\tdestination-unreachable\n\tlist icmp_type\t\tpacket-too-big\n\tlist icmp_type\t\ttime-exceeded\n\tlist icmp_type\t\tbad-header\n\tlist icmp_type\t\tunknown-header-type\n\toption limit\t\t1000/sec\n\toption family\t\tipv6\n\toption target\t\tACCEPT\n \nconfig rule\n\toption name\t\tAllow-IPSec-ESP\n\toption src\t\twan\n\toption dest\t\tlan\n\toption proto\t\tesp\n\toption target\t\tACCEPT\n \nconfig rule\n\toption name\t\tAllow-ISAKMP\n\toption src\t\twan\n\toption dest\t\tlan\n\toption dest_port\t500\n\toption proto\t\tudp\n\toption target\t\tACCEPT\n \n \n### EXAMPLE CONFIG SECTIONS\n# do not allow a specific ip to access wan\n#config rule\n#\toption src\t\tlan\n#\toption src_ip\t192.168.45.2\n#\toption dest\t\twan\n#\toption proto\ttcp\n#\toption target\tREJECT\n \n# block a specific mac on wan\n#config rule\n#\toption dest\t\twan\n#\toption src_mac\t00:11:22:33:44:66\n#\toption target\tREJECT\n \n# block incoming ICMP traffic on a zone\n#config rule\n#\toption src\t\tlan\n#\toption proto\tICMP\n#\toption target\tDROP\n \n# port redirect port coming in on wan to lan\n#config redirect\n#\toption src\t\t\twan\n#\toption src_dport\t80\n#\toption dest\t\t\tlan\n#\toption dest_ip\t\t192.168.16.235\n#\toption dest_port\t80\n#\toption proto\t\ttcp\n \n# port redirect of remapped ssh port (22001) on wan\n#config redirect\n#\toption src\t\twan\n#\toption src_dport\t22001\n#\toption dest\t\tlan\n#\toption dest_port\t22\n#\toption proto\t\ttcp\n \n### FULL CONFIG SECTIONS\n#config rule\n#\toption src\t\tlan\n#\toption src_ip\t192.168.45.2\n#\toption src_mac\t00:11:22:33:44:55\n#\toption src_port\t80\n#\toption dest\t\twan\n#\toption dest_ip\t194.25.2.129\n#\toption dest_port\t120\n#\toption proto\ttcp\n#\toption target\tREJECT\n \n#config redirect\n#\toption src\t\tlan\n#\toption src_ip\t192.168.45.2\n#\toption src_mac\t00:11:22:33:44:55\n#\toption src_port\t\t1024\n#\toption src_dport\t80\n#\toption dest_ip\t194.25.2.129\n#\toption dest_port\t120\n#\toption proto\ttcp"},"notes/Network/OpenWrt/Using-the-OpenWrt-SDK-to-build-a-custom-odhcp6c":{"slug":"notes/Network/OpenWrt/Using-the-OpenWrt-SDK-to-build-a-custom-odhcp6c","filePath":"notes/Network/OpenWrt/Using the OpenWrt SDK to build a custom odhcp6c.md","title":"Using the OpenWrt SDK to build a custom odhcp6c","links":[],"tags":[],"content":"curl -o openwrt-sdk-24.10.1-mediatek-filogic_gcc-13.3.0_musl.Linux-x86_64.tar.zst https://...\n \n# openwrt.org/docs/guide-developer/toolchain/install-buildsystem\nsudo apt update\nsudo apt install build-essential clang flex bison g++ gawk \\\ngcc-multilib g++-multilib gettext git libncurses5-dev libssl-dev \\\npython3-setuptools rsync swig unzip zlib1g-dev file wget\n \n# decompress\nsudo apt install zstd\ntar -xf openwrt-sdk-24.10.1-mediatek-filogic_gcc-13.3.0_musl.Linux-x86_64.tar.zst\ncd openwrt-sdk-24.10.1-mediatek-filogic_gcc-13.3.0_musl.Linux-x86_64\n \n./scripts/feeds update base\n# Apply your changes now\n# To avoid conflict, odhcp6c-${PKG_SOURCE_DATE}~61797806 must be unique, where 61797806 is extracted from ${PKG_SOURCE_VERSION}.\nvim feeds/base/package/network/ipv6/odhcp6c/Makefile\n./scripts/feeds install odhcp6c\n \nmake menuconfig\nYou probably want to disable some default settings, which build every available package. Enter Global Build Settings and in the submenu, deselect/exclude the following options:\n\nSelect all target specific packages by default\nSelect all kernel module packages by default\nSelect all userspace packages by default\n\nStill in the menu, find the package you want to build and select it by pressing “m”, this will also select all the dependencies, and you will see that they are all tagged with “&lt;M&gt;” in the menu. You can select multiple packages too.\nSave the configuration and exit the menu.\nRun make to build everything selected, or be more specific with\nmake package/odhcp6c/clean\nmake package/odhcp6c/compile\nYou may then copy the binary produced to your router:\ncp ./build_dir/target-aarch64_cortex-a53_musl/odhcp6c-2024.09.25~61797806/.pkgdir/odhcp6c/usr/sbin/odhcp6c ~/\n \n \nscp -O ~/odhcp6c root@192.168.1.1:/tmp/odhcp6c\nThen, replace the binary and restart odhcp6c.\nmv /tmp/odhcp6c /usr/sbin/odhcp6c\nkillall -TERM odhcp6c"},"notes/Network/Path-MTU-Discovery":{"slug":"notes/Network/Path-MTU-Discovery","filePath":"notes/Network/Path MTU Discovery.md","title":"Path MTU Discovery","links":[],"tags":[],"content":"IP layer\nIPv4\nUse ping &lt;addr&gt; -M do -s 8000 on Linux to prohibit fragmentation and conduct PMTUD (Path MTU Discovery).\n$ ping 1.1 -M do -s 8000\nPING 1.1 (1.0.0.1) 8000(8028) bytes of data.\nFrom 140.91.232.7 icmp_seq=1 Frag needed and DF set (mtu = 1500)\nping: local error: message too long, mtu=1500\nping: local error: message too long, mtu=1500\n...\nOn macOS, use ping &lt;addr&gt; -D -s 8000.\nIPv6\nOn Linux the command is the same, just use ping -6 or ping6 to force IPv6.\nOn macOS 14, try sudo ping6 &lt;addr&gt; -s 8000 -Dm to prohibit fragmentation.\n$ sudo ping6 he.net -s 8000 -Dm\nPING6(8048=40+8+8000 bytes) xxxx:xxxx --&gt; 2001:470:0:503::2\nping6: sendmsg: Message too long\nping6: wrote he.net 8008 chars, ret=-1\nThe need for PMTUD is more widespread in IPv6 environments because of enforced no fragmentation for IPv6, less NAT middle boxes that apply MSS clamping, and the reasons below.\n\nBut why did this problem not appear for IPv4 traffic? We believe the same issue exists on IPv4, but it’s less damaging due to the different nature of the network. IPv4 is more mature and the great majority of end-hosts support either MTU 1500 or have their MSS option well configured - or clamped by some middle box. This is different in IPv6 where a large proportion of users use tunnels, have Path MTU strictly smaller than 1500 and use incorrect MSS settings in the TCP header. Finally, Linux implements RFC4821 for IPv4 but not IPv6. RFC4821 (PLPMTUD) has its disadvantages, but does slightly help to alleviate the ICMP blackhole issue.\n\nFirewall\nMake sure to allow ICMPv6 “Packet Too Big” (PTB) messages for all IPv6 hosts you need to communicate with. Otherwise, PMTUD would not work and you can get hanging connections.\nOpenWRT 6rd tunnel MTU\nTake 6rd for example, with a 1500 MTU upstream link, the 6rd interface has a default MTU of 1280 per RFC spec, but IPv4 still has 1500 bytes MTU.\n\nIf the MTU is well-managed such that the IPv4 MTU on the CE WAN side interface is set so that no fragmentation occurs within the boundary of the SP, then the 6rd Tunnel MTU should be set to the known IPv4 MTU minus the size of the encapsulating IPv4 header (20 bytes).  For example, if the IPv4 MTU is known to be 1500 bytes, the 6rd Tunnel MTU might be set to 1480 bytes.  Absent more specific information, the 6rd Tunnel MTU SHOULD default to 1280 bytes.\n\nOn Linux, even though ip link may show mtu 1500, MTU for IPv6 may differ. You can check the actual value at /proc/sys/net/ipv6/conf/&lt;interface&gt;/mtu. This values is automatically adjusted according to the Router Advertisement sent by the router, and OpenWRT takes care of it magically by inheriting the upstream MTU.\nIf for some reason a client sends packets bigger than 1280 bytes, the router returns ICMPv6 PTB messages to ask the client to resend the data in smaller datagrams.\nUpper layer\nTCP\nFor TCP connections, PMTUD is handled automatically by the kernel or NIC.\nUDP\nIf don’t-fragment flag is set on a UDP or raw IP socket, an EMSGSIZE error is returned upon recognizing datagrams that are bigger than the known path MTU. See ip(4) on FreeBSD and ip(7) on Linux for respective socket options IP_PMTUDISC_DO and IP_DONTFRAG.\n\nNote: an implementation can avoid the use of an asynchronous notification mechanism for PMTU decreases by postponing notification until the next attempt to send a packet larger than the PMTU estimate.  In this approach, when an attempt is made to SEND a packet that is larger than the PMTU estimate, the SEND function should fail and return a suitable error indication.  This approach may be more suitable to a connectionless packetization layer (such as one using UDP), which (in some implementations) may be hard to “notify” from the ICMPv6 layer.  In this case, the normal timeout-based retransmission mechanisms would be used to recover from the dropped packets.\n\nVPN\nFor Layer 3 VPNs (L3VPN) that need to transmit IPv6 packets, 1280 bytes plus packet encapsulation overhead is the minimum MTU required.\nThis causes fragmentation on a default OpenWrt 6rd setup, which has 1280 bytes of MTU. You can verify this with tcpdump -i eth0.X host &lt;6rd_peeraddr&gt; on the router. If ping6 he.net -s 1233 on the client triggers ipv6-frag in tcpdump output, that means a 1281-byte IPv6 packet needs to be fragmented to be sent over IPv4 to the 6rd peer.\nBecause of this, for best VPN performance, it is recommended to explicitly set the 6rd tunnel MTU to 1480 bytes if the IPv6 MTU is 1500 bytes, and then verify that packets are not fragmented over the wire with tcpdump.\nReferences\n\ndatatracker.ietf.org/doc/html/rfc8201\nblog.cloudflare.com/increasing-ipv6-mtu\n"},"notes/Network/Prefer-IPv4-over-IPv6":{"slug":"notes/Network/Prefer-IPv4-over-IPv6","filePath":"notes/Network/Prefer IPv4 over IPv6.md","title":"Prefer IPv4 over IPv6","links":[],"tags":[],"content":"Operating Systems\n\nLinux: gai.conf\nWindows:\n\nModify registry key DisabledComponents under HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Tcpip6\\Parameters\nOR\nModify prefixpolicies to prefer IPv4-mapped IPv6 address, see netsh interface ipv6 show prefixpolicies for current list\n\n\nmacOS: N/A\n\nBrowsers\n\nFirefox: about:config → network.dns.disableIPv6 (disables IPv6, which makes IPv6-only sites inaccessible)\n\nReferences\n\nlearn.microsoft.com/en-us/troubleshoot/windows-server/networking/configure-ipv6-in-windows\n"},"notes/Network/RHEL-9-networking":{"slug":"notes/Network/RHEL-9-networking","filePath":"notes/Network/RHEL 9 networking.md","title":"RHEL 9 networking","links":[],"tags":[],"content":"Retiring ifcfg-rh\nQuote from Red Hat blog\n\nIn RHEL 9, /etc/sysconfig/network-scripts (also known as ifcfg files) will no longer be the primary storage for network configuration files. While the ifcfg style is still available, it is no longer the default location where NetworkManager stores new network profiles.\nHistorically, various Linux distributions have spread interface configurations over many places: Debian and its derivatives traditionally use /etc/network/interfaces, CentOS and related distros use /etc/sysconfig/network-scripts, and so on. With more distros adopting NetworkManager, keyfiles in /etc/NetworkManager/system-connections have become the canonical place for network connections on Linux.\n\nNetworkManager plugins\nEven if plugins is explicitly set to ifcfg-rh, keyfile is still loaded with lowest priority.\n\nNote that NetworkManager’s native keyfile plugin is always appended to the end of this list (if it doesn’t already appear earlier in the list).\n\nsettings: Loaded settings plugin: ifcfg-rh (&quot;/usr/lib64/NetworkManager/...&quot;)\nsettings: Loaded settings plugin: keyfile (internal)\n\nGiven the configuration plugins=ifcfg-rh, and rd.neednet=1 (cmdline), preference order is pre-existing connections (e.g. Wired Connection), ifcfg-rh (e.g. System eth0), keyfile (e.g. eth0).\nUnsetting plugins makes it the default keyfile,ifcfg-rh, reversing preference of the last two.\nNetworkManager configuration\nYou can configure multiple connection or device sections by having different sections with a name that all start with “connection” or “device”. For example,\n[connection]\nipv6.ip6-privacy=0\nconnection.autoconnect-slaves=1\nvpn.timeout=120\n \n[connection-wifi-wlan0]\nmatch-device=interface-name:wlan0\nipv4.route-metric=50\n \n[connection-wifi-other]\nmatch-device=type:wifi\nipv4.route-metric=55\nipv6.ip6-privacy=1\nAuto config\nPrevent generation of in-memory connection\nOn startup, NetworkManager tries to not interfere with interfaces that are already configured. It does so by generating a in-memory connection based on the interface current configuration.\nTo let NetworkManager interfere with pre-existing configured interfaces, add\n# /etc/NetworkManager/conf.d/20-discard-eth0-config.conf\n[device]\nmatch-device=interface-name:eth0\nkeep-configuration=no\nThis alone does not apply to connections generated by nm-initrd-generator during early boot, which is native to NetworkManager.\nnm-initrd-generator\nnm-initrd-generator creates configuration files for an early instance of NetworkManager run from the initial ramdisk.\ndracut.cmdline(7) describes all kernel command line parameters processed by dracut. When netroot or rd.neednet is set, a “Wired Connection” is created with a random UUID in /var/run/NetworkManager/system-connections.\nsudo cat /var/run/NetworkManager/system-connections/default_connection.nmconnection\n# Created by nm-initrd-generator\n\n[connection]\nid=Wired Connection\nuuid=xxx-...\ntype=ethernet\nautoconnect-priority=-100\nautoconnect-retries=1\nmulti-connect=3\nwait-device-timeout=60000\n\n[ethernet]\n\n[ipv4]\ndhcp-timeout=10\nmethod=auto\nrequired-timeout=20000\n\n[ipv6]\ndhcp-timeout=10\nmethod=auto\n\n[proxy]\n\n[user]\norg.freedesktop.NetworkManager.origin=nm-initrd-generator\n\nTo let NetworkManager re-configure interfaces after switch root, add\n# /etc/NetworkManager/conf.d/20-discard-eth0-config.conf\n[device-eth0]\nmatch-device=interface-name:eth0\nkeep-configuration=no\nallowed-connections=except:origin:nm-initrd-generator\nReferences\n\nwww.redhat.com/en/blog/rhel-9-networking-say-goodbye-ifcfg-files-and-hello-keyfiles\ngitlab.freedesktop.org/NetworkManager/NetworkManager/-/issues/685\ngitlab.freedesktop.org/NetworkManager/NetworkManager/-/commit/bace14fe1f374db26e49e4e7d61d2fbfce4241cc\n"},"notes/Network/Reverse-Path-Forwarding":{"slug":"notes/Network/Reverse-Path-Forwarding","filePath":"notes/Network/Reverse-Path Forwarding.md","title":"Reverse-Path Forwarding","links":[],"tags":[],"content":"Strict RPF\nStrict Reverse Path is only applicable in places where routing is symmetrical - where IP datagrams in one direction and responses from the other deterministically follow the same path.\nReferences\n\ndatatracker.ietf.org/doc/html/rfc3704\nrp_filter kernel parameter in Linux\n"},"notes/Network/SNMPv2-TCP-statistics":{"slug":"notes/Network/SNMPv2-TCP-statistics","filePath":"notes/Network/SNMPv2 TCP statistics.md","title":"SNMPv2 TCP statistics","links":[],"tags":["networking"],"content":"Source: RFC 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObjectDescriptionRtoAlgorithmThe algorithm used to determine the timeout value used for retransmitting unacknowledged octets.RtoMinThe minimum value permitted by a TCP implementation for the retransmission timeout, measured in milliseconds. More refined semantics for objects of this type depend upon the algorithm used to determine the retransmission timeout. In particular, when the timeout algorithm is rsre(3), an object of this type has the semantics of the LBOUND quantity described in RFC 793.RtoMaxThe maximum value permitted by a TCP implementation for the retransmission timeout, measured in milliseconds. More refined semantics for objects of this type depend upon the algorithm used to determine the retransmission timeout. In particular, when the timeout algorithm is rsre(3), an object of this type has the semantics of the UBOUND quantity described in RFC 793.MaxConnThe limit on the total number of TCP connections the entity can support. In entities where the maximum number of connections is dynamic, this object should contain the value -1.ActiveOpensThe number of times TCP connections have made a direct transition to the SYN-SENT state from the CLOSED state.PassiveOpensThe number of times TCP connections have made a direct transition to the SYN-RCVD state from the LISTEN state.AttemptFailsThe number of times TCP connections have made a direct transition to the CLOSED state from either the SYN-SENT state or the SYN-RCVD state, plus the number of times TCP connections have made a direct transition to the LISTEN state from the SYN-RCVD state.EstabResetsThe number of times TCP connections have made a direct transition to the CLOSED state from either the ESTABLISHED state or the CLOSE-WAIT state.CurrEstabThe number of TCP connections for which the current state is either ESTABLISHED or CLOSE-WAIT.InSegsThe total number of segments received, including those received in error. This count includes segments received on currently established connections.OutSegsThe total number of segments sent, including those on current connections but excluding those containing only retransmitted octets.RetransSegsThe total number of segments retransmitted - that is, the number of TCP segments transmitted containing one or more previously transmitted octets.ConnTableA table containing TCP connection-specific information.InErrsThe total number of segments received in error (for example, bad TCP checksums).OutRstsThe number of TCP segments sent containing the RST flag."},"notes/Network/Speed-test-website-and-tools":{"slug":"notes/Network/Speed-test-website-and-tools","filePath":"notes/Network/Speed test website and tools.md","title":"Speed test website and tools","links":[],"tags":[],"content":"Web\n\nspeed.cloudflare.com/\nfast.com/\nspeed.measurementlab.net/ (also available at www.google.com/search+test)\nwww.speedtest.net/ (no full IPv6 support yet)\n"},"notes/Network/Static-NDP-proxying-on-Linux":{"slug":"notes/Network/Static-NDP-proxying-on-Linux","filePath":"notes/Network/Static NDP proxying on Linux.md","title":"Static NDP proxying on Linux","links":[],"tags":[],"content":"Basics\nLinux comes with a feature called NDP proxying. You can declare a list of IP addresses to answer neighbor solicitation requests for, and the system will answer them for you, allowing you to receive packets for them.\nFirst, you have to enable this feature by setting the sysctl option net.ipv6.conf.all.proxy_ndp to 1. You can do this by adding the following line to /etc/sysctl.conf (or whatever the equivalent on your system is):\nnet.ipv6.conf.all.proxy_ndp = 1\n\nOnce you do this, run sysctl -p as root to activate it immediately.\nThen, for every IP address you wish the VPS to route, you have to run:\nip -6 neigh add proxy &lt;ip&gt; dev &lt;interface&gt;\n\nFor example, if you want to answer for 2001:db8::2 on eth0, run:\nip -6 neigh add proxy 2001:db8::2 dev eth0\n\nAfterwards, your server will tell your external router, connected to eth0, that it should receive packets for 2001:db8::2. Your server now routes the traffic properly!\nPersistent configuration\nCreate an executable script /etc/networkd-dispatcher/routable.d/90-proxy-ndp:\n#!/bin/sh\n \nif [ &quot;$IFACE&quot; = &quot;eth0&quot; ]; then\n  ip -6 neigh add proxy 2001:db8::2 dev eth0\n  # ...\nfi\n \nexit 0\nand configure /etc/sysctl.conf to enable proxy_ndp.\nnet.ipv6.conf.all.proxy_ndp = 1\nIf you enabled UFW on the server, you need to add routing rules with ufw route RULE.\nReferences\n\nquantum5.ca/2019/03/08/ndp-proxy-route-ipv6-vpn-addresses/\nnetplan.io/faq#use-pre-up-post-up-etc-hook-scripts\n"},"notes/Network/Strong-and-weak-host-models":{"slug":"notes/Network/Strong-and-weak-host-models","filePath":"notes/Network/Strong and weak host models.md","title":"Strong and weak host models","links":[],"tags":[],"content":"Linux\nThe IP implementation in Linux defaults to the weak host model.\nFreeBSD\nThe IP implementation in FreeBSD partially implement the Strong End System model, but it’s off by default and only works in non-forwarding mode. Since FreeBSD 14, you need to set net.inet.rfc1122_strong_es to enable this feature. See inet(4) for details.\nOpenBSD\nSince OpenBSD 6.6, the strong host model is the default in non-forwarding mode.\nPF (Packet Filter) offers a Unicast Reverse Path Forwarding (uRPF) feature. It’s similar to antispoof, and can be used to implement the strong host model with IP forwarding enabled.\nThe uRPF check can be performed on packets via the urpf-failed keyword in filter rules:\nblock in quick from urpf-failed label uRPF\n\nReferences\nblog.kanbach.org/post/network-security-implications-of-host-models/"},"notes/Network/TCP-handshake":{"slug":"notes/Network/TCP-handshake","filePath":"notes/Network/TCP handshake.md","title":"TCP handshake","links":[],"tags":[],"content":"Terminology\nNumbers\nSequence Number:  32 bits\nThe sequence number of the first data octet in this segment (except\nwhen SYN is present). If SYN is present the sequence number is the\ninitial sequence number (ISN) and the first data octet is ISN+1.\n\nAcknowledgment Number:  32 bits\nIf the ACK control bit is set this field contains the value of the\nnext sequence number the sender of the segment is expecting to\nreceive.  Once a connection is established this is always sent.\n\nCurrent segment variables\nSEG.SEQ segment sequence number\nSEG.ACK segment acknowledgment number\nSEG.LEN segment length\nSEG.WND segment window\nSEG.UP  segment urgent pointer\nSEG.PRC segment precedence value\n\nSequence and acknowledgement numbers\nFirst packet (sent by client):\nSEG.SEQ = x # assigned sequence number for the SYN virtual octet\nSEG.ACK = 0\nSecond packet (sent by server):\nSEG.SEQ = y # assigned sequence number for the SYN virtual octet\nSEG.ACK = x+1 # the next sequence number expected to receive, which is the data octect after SYN. relative sequence number in Wireshark is actual number minus `x`, and in this segment is 1.\nThird packet (sent by client):\nSEG.SEQ = x+1 # assigned sequence number for the SYN virtual octet\nSEG.ACK = y+1 # the next sequence number expected to receive from the server\nSEG.LEN = 0\nNext packet sent does not need to wait for acknowledgment of the third packet.\nFourth packet (sent by client):\nSEG.SEQ = x+1 # assigned sequence number for the SYN virtual octet\nSEG.ACK = y+1 # the next sequence number expected to receive from the server\nSEG.LEN = 4 # calculated by deducting Data Offset (header length in Wireshark) from TCP segment size, not on wire\nThe fourth packet usually have PSH bit set to reduce latency."},"notes/Network/TCP-port-scanning":{"slug":"notes/Network/TCP-port-scanning","filePath":"notes/Network/TCP port scanning.md","title":"TCP port scanning","links":[],"tags":[],"content":"Preparation\nYou can run rustscan first to find open ports, and then use nmap to analyze the services exposed.\nrustscan -u 10000 --scripts none -a &lt;comma-delimited list of CIDRs, IPs, or hosts&gt;\nRustScan’s scripting engine is extensible but difficult to set up, so you could disable it with --scripts none and run nmap yourself.\nYou may need to lower the batch size to accommodate your network environment. For example, add -b 2500 and rustscan will scan 2500 ports at a same time.\nYou may need to increase the local router’s nf_conntrack_max sysctl variable. 262144 connections tracked should take less than 100 MiB of RAM, but usually 131072 is enough and saves more RAM for other use.\nsysctl net.netfilter.nf_conntrack_max=262144\n\nYou may also consider reducing net.netfilter.nf_conntrack_tcp_timeout_syn_sent to let connection tracking end sooner if the remote port is unresponsive, that is, filtered in nmap terms. The default 120 seconds is too long.\nScanning\nFirst, gather a list of IP addresses to scan. For servers without NAT, you can use the following command to gather a list:\nip addr | awk &#039;$1==&quot;inet&quot;{split($2,a,&quot;/&quot;); if(a[1] !~ /^(10|127|169\\.254|172\\.(1[6-9]|2[0-9]|3[0-1])|192\\.168)\\./) print a[1]} $1==&quot;inet6&quot;{split($2,a,&quot;/&quot;); if(a[1] ~ /^[23]/) print a[1]}&#039;\nand convert them to a comma separated list:\n... | grep -E &#039;\\.|:&#039; | grep -v &#039;^100\\.&#039; | sort | uniq | tr &#039;\\n&#039; &#039;,&#039; ; echo\nFinally, run rustscan and save its output.\nYou can also scan them with nmap using the script nmap_runner.sh below. For example, cat ports.txt | ./nmap_runner.sh | tee port-scan.txt.\n#!/bin/bash\n \npattern=&#039;^([^[:space:]]+)[[:space:]]*-&gt;[[:space:]]*\\[([0-9,]+)\\]$&#039;\n \nwhile read -r line; do\n    # Skip empty lines and comments (lines starting with #)\n    [[ -z &quot;$line&quot; || &quot;$line&quot; == \\#* ]] &amp;&amp; continue\n \n    if [[ &quot;$line&quot; =~ $pattern ]]; then\n        ip=&quot;${BASH_REMATCH[1]}&quot;\n        ports=&quot;${BASH_REMATCH[2]}&quot;\n        if [[ &quot;$ip&quot; == *:* ]]; then\n            nmap -6 -Pn -A -p &quot;${ports}&quot; &quot;${ip}&quot;\n        else\n            nmap -Pn -A -p &quot;${ports}&quot; &quot;${ip}&quot;\n        fi\n    else\n        echo &quot;Error: Invalid input format - $line&quot; &gt;&amp;2\n    fi\ndone\nNmap flags\n\n-oX &lt;file&gt;: Output scan in XML format to &lt;file&gt;. Use - for stdout. You could also use -oN or -oG for normal and Grep-able format, respectively.\n-v: Increase verbosity level. Most changes only affect interactive and normal output. Use if you want to watch scan progress.\n\nConnect Scan Timing: About 1.03% done; ETC: 20:25 (1:00:00 remaining)\n\n\n-sV: Probe open ports to determine service/version info.\n-A: Presently this enables OS detection (-O), version scanning (-sV), script scanning (-sC) and traceroute (--traceroute). Note that both OS detection and traceroute require root privileges, so normal users just get -sV -sC.\n-Pn: Treat all hosts as online — skip host discovery.\n-T paranoid|sneaky|polite|normal|aggressive|insane: Set timing template (higher is faster). You can specify them with the -T option and their number (0–5) or their name. If you are on a decent broadband or ethernet connection, I would recommend always using -T4.\n--min-rate &lt;number&gt;: Override Nmap’s dynamic timing to send packets no slower than &lt;number&gt; per second. When the option is given, Nmap will do its best to send packets as fast as or faster than the given rate.\n\nReferences\n\nnmap.org/nsedoc/categories/default.html\n"},"notes/Network/VXLAN":{"slug":"notes/Network/VXLAN","filePath":"notes/Network/VXLAN.md","title":"VXLAN","links":[],"tags":[],"content":"The Linux kernel uses UDP port 8472 for VXLAN, which is identified as otv in /etc/services."},"notes/Network/Valiant-Load-Balancing":{"slug":"notes/Network/Valiant-Load-Balancing","filePath":"notes/Network/Valiant Load Balancing.md","title":"Valiant Load Balancing","links":[],"tags":[],"content":"Architecture\nVLB is a very simple design. With full-mesh connected backbone nodes, and two-hop load balancing, each link only needs \\frac{2r}{N} capacity to achieve a guaranteed 100% throughput. N is the number of backbone nodes, and r is the maximum ingress and egress rate.\nFault tolerance\nVLB requires only a small fraction of extra capacity to tolerate failures in the network. To tolerate k node failures, the require link capacity is \\frac{2r}{N-k}. Analyzing link failures is more complicated, but capacity needed is still on the order of \\frac{2r}{N-k}.\nFor example, a 100 node network only needs to be over-provisioned by about 5.3% to tolerate any 5 link failures. Existing backbone networks typically use significantly more over-provisioning, but are unable to make any guarantees.\nReferences\n\nDesigning a Predictable Internet Backbone Network\nDesigning a Predictable Internet Backbone with Valiant Load-Balancing\nEfficient and Robust Routing of Highly Variable Traffic\n"},"notes/Network/Wi-Fi-6E":{"slug":"notes/Network/Wi-Fi-6E","filePath":"notes/Network/Wi-Fi 6E.md","title":"Wi-Fi 6E","links":[],"tags":[],"content":"Vendors\nApple\nSupported devices\n\nMacBook Pro (14-inch, 2023) or MacBook Pro (16-inch, 2023)\nMac mini (2023)\nMac Studio (2023)\nMac Pro (2023)\niPhone 15 Pro or iPhone 15 Pro Max\niPad Pro 11-inch (4th generation) or iPad Pro 12.9 inch (6th generation)\n\nRegulations\nSingapore\nIMDA will amend its Regulations to allocate the radio frequency spectrum 5,925 MHz–6,425 MHz for Wi-Fi use in Singapore.\nIMDA expects Wi-Fi 6E-enabled equipment and devices to be commercially available in Singapore by 3Q 2023.\nReferences\n\nsupport.apple.com/en-us/HT213433\nwww.imda.gov.sg/resources/press-releases-factsheets-and-speeches/factsheets/2023/imda-to-allocate-more-radio-frequency-spectrum-for-wi-fi-connectivity-in-singapore\n"},"notes/Note-Making/Ideaverse-Kit-plugins":{"slug":"notes/Note-Making/Ideaverse-Kit-plugins","filePath":"notes/Note Making/Ideaverse Kit plugins.md","title":"Ideaverse Kit plugins","links":[],"tags":[],"content":"Note\nIn light of obsidian.md/blog/less-is-safer/, only keep a subset of plugins you actually need.\nFunctionality\nAdvanced Tables\nMarkdown table improvements.\nExcalidraw and ExcaliBrain\nPowerful graph view.\nExcaliBrain: Add “related” to Left-Side Friends.\nList Callouts\nDeferred. Not exportable.\nPeriodic Notes\nDeferred. Already have daily notes.\nQuick Switcher++\nGood search functionality. Can replace default quick switcher hotkey.\nSortable\nRequired for sort in tables.\nTag Wrangler\nDeferred until extensive use of tags.\nZoom\nLogseq-like zoom into sections. Deferred.\nTheming\nStyle Settings\nRequired for some themes like Prism.\nIcon Folder\nRequired for theming. Set “Emoji Style” to “Native” to get emojis.\nOptionally, add Lucide icon pack for more icons.\nCallout Manager\nAdd “box” callout with box icon from Lucide icon pack.\nUtilities\nAuto Link Title\nDisabled due to security concerns.\nCommander\nDeferred. Create shortcut buttons for commands.\nLink Favicons\nDisplay website icons. Disabled due to security concerns.\nHover Editor\nDeferred. A useful utility plugin for editing properties.\nNatural Language Dates\nDeferred. May be helpful when wrangling with calendar.\nNote Refactor\nGood refactoring tool. Extract content to separate note.\nText Format\nFix capitalization of pasted text.\nPaste URL into selection\nGood utility. Deferred."},"notes/Note-Making/Obsidian":{"slug":"notes/Note-Making/Obsidian","filePath":"notes/Note Making/Obsidian.md","title":"Obsidian","links":["notes/Note-Making/Ideaverse-Kit-plugins"],"tags":[],"content":"iCloud syncing\nYou should turn off “Low Data Mode” in iPhone Settings app if you have abundant data. iCloud sync is paused on low data mode, even for interactive uses in Obsidian.\nCore configuration\nEditor\nDisable “Readable line length” for code blocks with long lines.\nFiles and links\nLink format: Shortest path (the default)\nAttachement folder path: Garden/images\nTemplates\nTemplate folder location: Garden/templates\nDaily notes new location: Calendar/notes\nDaily notes template: Garden/templates/Templates, Properties, Daily Note\nHotkeys\n\nAssign Cmd+D to “Open today’s daily note”.\nIn Files &amp; Links, use shortest path possible in vault for new links.\n\nPlugins\n\nExcalidraw\nMinimal Theme Settings\nQuick Switcher++\n\nSee also Ideaverse Kit plugins."},"notes/Note-Making/Open-source-diagram-editors":{"slug":"notes/Note-Making/Open-source-diagram-editors","filePath":"notes/Note Making/Open source diagram editors.md","title":"Open source diagram editors","links":[],"tags":[],"content":"Online diagram editors\nMindmap\n\ngithub.com/wanglin2/mind-map\n\nText to diagram\nSee github.com/yuzutech/kroki.\n\nBlockDiag (BlockDiag, SeqDiag, ActDiag, NwDiag, PacketDiag, RackDiag), BPMN, Bytefield, C4 (with PlantUML), D2, DBML, Diagrams.net (experimental), Ditaa, Erd, Excalidraw, GraphViz, Mermaid, Nomnoml, Pikchr, PlantUML, SvgBob, Symbolator, UMLet, Vega, Vega-Lite, WaveDrom and WireViz.\n"},"notes/Note-Making/Reduce-header-level-in-Markdown-document":{"slug":"notes/Note-Making/Reduce-header-level-in-Markdown-document","filePath":"notes/Note Making/Reduce header level in Markdown document.md","title":"Reduce header level in Markdown document","links":[],"tags":[],"content":"sed &#039;s/^##\\([ #]\\)/#\\1/&#039; ...\nThis doesn’t work well if you have code blocks with comments like ##  because those would be replaced as well."},"notes/Observability/Alloy-collector-configuration-example":{"slug":"notes/Observability/Alloy-collector-configuration-example","filePath":"notes/Observability/Alloy collector configuration example.md","title":"Alloy collector configuration example","links":[],"tags":[],"content":"node_exporter\nBased on the template at grafana.com/docs/grafana-cloud/monitor-infrastructure/integrations/integration-reference/integration-linux-node/.\nChanges:\n\nAdd netstat block to collect additional metrics.\n\nTODOs:\n\nSimilar to github.com/prometheus/node_exporter/pull/2867, propose adding AttemptFails to the default collector.netstat.fields. EstabResets might be worth adding too.\nRestore Alloy configuration to the template if the proposed node_exporter changes are merged to Alloy.\n\ndiscovery.relabel &quot;integrations_node_exporter&quot; {\n  targets = prometheus.exporter.unix.integrations_node_exporter.targets\n\n  rule {\n    target_label = &quot;instance&quot;\n    replacement  = constants.hostname\n  }\n\n  rule {\n    target_label = &quot;job&quot;\n    replacement = &quot;integrations/node_exporter&quot;\n  }\n}\n\nprometheus.exporter.unix &quot;integrations_node_exporter&quot; {\n  disable_collectors = [&quot;ipvs&quot;, &quot;btrfs&quot;, &quot;infiniband&quot;, &quot;xfs&quot;, &quot;zfs&quot;]\n\n  filesystem {\n    fs_types_exclude     = &quot;^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|tmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$&quot;\n    mount_points_exclude = &quot;^/(dev|proc|run/credentials/.+|sys|var/lib/docker/.+)($|/)&quot;\n    mount_timeout        = &quot;5s&quot;\n  }\n\n  netclass {\n    ignored_devices = &quot;^(veth.*|cali.*|[a-f0-9]{15})$&quot;\n  }\n\n  netdev {\n    device_exclude = &quot;^(veth.*|cali.*|[a-f0-9]{15})$&quot;\n  }\n\n  netstat {\n    fields = &quot;&quot;^(.*_(InErrors|InErrs)|Ip_Forwarding|Ip(6|Ext)_(InOctets|OutOctets)|Icmp6?_(InMsgs|OutMsgs)|TcpExt_(Listen.*|Syncookies.*|TCPSynRetrans|TCPTimeouts)|Tcp_(ActiveOpens|AttemptFails|InSegs|OutSegs|OutRsts|PassiveOpens|RetransSegs|CurrEstab)|Udp6?_(InDatagrams|OutDatagrams|NoPorts|RcvbufErrors|SndbufErrors))$&quot;&quot;\n  }\n}\n\nprometheus.scrape &quot;integrations_node_exporter&quot; {\n  targets    = discovery.relabel.integrations_node_exporter.output\n  forward_to = [prometheus.relabel.integrations_node_exporter.receiver]\n}\n\nprometheus.relabel &quot;integrations_node_exporter&quot; {\n  forward_to = [prometheus.remote_write.metrics_service.receiver]\n\n  rule {\n    source_labels = [&quot;__name__&quot;]\n    regex         = &quot;node_scrape_collector_.+&quot;\n    action        = &quot;drop&quot;\n  }\n}\n"},"notes/Observability/Checking-Grafana-server-version":{"slug":"notes/Observability/Checking-Grafana-server-version","filePath":"notes/Observability/Checking Grafana server version.md","title":"Checking Grafana server version","links":[],"tags":[],"content":"There are two ways to find out the Grafana server’s version.\n\nFind the question mark in UI.\nHover or click it.\nAccess the /api/health endpoint.\n"},"notes/Observability/Grafana-alerts":{"slug":"notes/Observability/Grafana-alerts","filePath":"notes/Observability/Grafana alerts.md","title":"Grafana alerts","links":[],"tags":[],"content":"Data-source managed alerts\nAPIs\nAlert generator compliance specification\ngithub.com/prometheus/compliance/blob/main/alert_generator/specification.md\nAPI endpoints\n\nGET /api/v1/alerts\nGET /api/v1/rules\n\nRuler API\nRuler API configures recording rules and alerts, and a backend storage is required to store them.\nReferences\n\ncortexmetrics.io/docs/api/#ruler\ngrafana.com/docs/mimir/latest/references/http-api/#ruler\n\nImplementations\nVictoriaMetrics\nAlert Generator Compliance Specification 1.0 is implemented.\nRuler API endpoints are not implemented yet. See github.com/VictoriaMetrics/VictoriaMetrics/issues/4939.\nGrafana Mimir\nFully supported."},"notes/Observability/Grafana-dashboard-annotations":{"slug":"notes/Observability/Grafana-dashboard-annotations","filePath":"notes/Observability/Grafana dashboard annotations.md","title":"Grafana dashboard annotations","links":[],"tags":[],"content":"Annotation queries return events that can be visualized as event markers in graphs across the dashboard.\nFor example, node_boot_time_seconds{job=~&quot;$job&quot;,instance=~&quot;$instance&quot;}*1000 &gt; $__from &lt; $__to can detect reboot events and automatically annotate all graphs.\nManual annotations\nManual annotations are stored per dashboard in Grafana’s database, and queried from Annotations &amp; Alerts (Built-in) when displaying the original dashboard."},"notes/Observability/Grafana-dashboards":{"slug":"notes/Observability/Grafana-dashboards","filePath":"notes/Observability/Grafana dashboards.md","title":"Grafana dashboards","links":["notes/Observability/Grafana-visualizations"],"tags":[],"content":"Issues encountered\nBroken Links\n$__cell does not work in the latest Grafana table panel. Replace them with ${__value.text} instead.\nDashboard examples\n\ngithub.com/portefaix/portefaix-kubernetes/tree/8e46651ba91f724c938b6aa5108f32979c179c56/gitops/argocd/charts/monitoring/kube-prometheus-stack/dashboards (K8s and node exporter)\ngithub.com/VictoriaMetrics/VictoriaMetrics/tree/master/dashboards/vm (VictoriaMetrics)\ngithub.com/Vonng/pigsty/tree/master/files/grafana (PostgreSQL as a service)\n\nSee also Grafana visualizations."},"notes/Observability/Grafana-variables":{"slug":"notes/Observability/Grafana-variables","filePath":"notes/Observability/Grafana variables.md","title":"Grafana variables","links":[],"tags":[],"content":"Built-in variables\nGlobal\ngrafana.com/docs/grafana/latest/dashboards/variables/add-template-variables/#global-variables\nLoki\ngrafana.com/docs/grafana-cloud/connect-externally-hosted/data-sources/loki/template-variables/"},"notes/Observability/Grafana-visualizations":{"slug":"notes/Observability/Grafana-visualizations","filePath":"notes/Observability/Grafana visualizations.md","title":"Grafana visualizations","links":[],"tags":[],"content":"Time series\nThis public demo dashboard contains many different examples of how a time series visualization can be configured and styled."},"notes/Observability/Prometheus-node-exporter":{"slug":"notes/Observability/Prometheus-node-exporter","filePath":"notes/Observability/Prometheus node exporter.md","title":"Prometheus node exporter","links":[],"tags":[],"content":"Reduce number of metrics\nCentOS\nModify /etc/default/prometheus-node-exporter.\nARGS=&#039;--collector.disable-defaults --web.disable-exporter-metrics --collector.cpu --collector.meminfo --collector.time --collector.stat --collector.filesystem --collector.netdev --collector.diskstats --collector.os&#039;\n\nFreeBSD\nModify /etc/rc.conf.\nnode_exporter_enable=&quot;YES&quot;\nnode_exporter_args=&quot;--collector.disable-defaults --web.disable-exporter-metrics --collector.cpu --collector.meminfo --collector.boottime --collector.time --collector.filesystem --collector.netdev --collector.devstat --collector.os&quot;\n"},"notes/Observability/pwru":{"slug":"notes/Observability/pwru","filePath":"notes/Observability/pwru.md","title":"pwru","links":[],"tags":[],"content":"Requirements\n\npwru requires &gt;= 5.3 kernel to run.\nFor --output-skb &gt;= 5.9 kernel is required.\n(Auto-detected) For --backend=kprobe-multi &gt;= 5.18 kernel is required.\n\nCommands\nBasic command that writes traces with tuple and skb information to a file:\npwru --output-tuple --output-skb --output-file packet.trace-1.txt &#039;tcp port 8080&#039;\n\ntcp port 8080 (TCP packets with source or destination port set to 8080) can be replaced with any pcap-filter.\nFor example, src host 1.1.1.1 and tcp src port 443 can be used to trace packets received from 1.1.1.1:443 to diagnose RX path issues. However unlikely to happen, the src port 443 part of the expression excludes packets from 1.1.1.1 but sent to port 443.\nAdd --filter-func kfree_skb_reason --output-caller to find the function that called kfree_skb_reason(). If it does not provide sufficient information, try --output-stack instead of --output-caller.\nRun with Docker\nYou can also run it in Docker with:\ndocker run --privileged --rm -t --pid=host -v /sys/kernel/debug/:/sys/kernel/debug/ cilium/pwru pwru --output-tuple &#039;tcp port 8080&#039;\n"},"notes/Operating-System/Android/Root-access-to-AVD":{"slug":"notes/Operating-System/Android/Root-access-to-AVD","filePath":"notes/Operating System/Android/Root access to AVD.md","title":"Root access to AVD","links":[],"tags":[],"content":"Google Play Store system images don’t support su or adb root. You need Google APIs or Android Open Source (not available for Android 16.0 and above) images for that."},"notes/Operating-System/Android/TLS-traffic-analysis-on-AVD":{"slug":"notes/Operating-System/Android/TLS-traffic-analysis-on-AVD","filePath":"notes/Operating System/Android/TLS traffic analysis on AVD.md","title":"TLS traffic analysis on AVD","links":["notes/Operating-System/Android/Root-access-to-AVD"],"tags":[],"content":"With friTap\nFirst, you need to set up Root access to AVD and make sure you have allocated enough RAM for the virtual device.\nThen, install friTap with pipx and follow fkie-cad.github.io/friTap/platforms/android/ to install frida-server on your emulator.\nYou should then find the specific app you want to analyze.\n# List all installed packages\nadb shell pm list packages\n \n# Search for specific app\nadb shell pm list packages | grep instagram\n \n# Get package details\nadb shell dumpsys package com.instagram.android | grep version\nand use these commands to extract TLS keys or decrypted PCAP file. Use -v to show errors otherwise hidden from command output, and also add -do if it’s not enough.\n# Extract TLS keys from Android app\nfritap -m -k instagram_keys.log com.instagram.android\n \n# Capture decrypted traffic\nfritap -m --pcap instagram_traffic.pcap com.instagram.android\n \n# Spawn app from beginning\nfritap -m -s -k keys.log com.example.app\n \n# Verbose analysis with debug output\nfritap -m -v -k keys.log -do com.example.app\nIf --pcap is not working, or that you prefer capturing PCAP directly via adb and tcpdump, use\nadb exec-out &quot;tcpdump -U -w - 2&gt;/dev/null&quot; | wireshark -k -S -i -\nto stream the captured packets live and set the (Pre)-Master-Secret log file to instagram_keys.log in Wireshark preferences Protocols → TLS. Replace the filename instagram_keys.log as needed."},"notes/Operating-System/FreeBSD/DTrace":{"slug":"notes/Operating-System/FreeBSD/DTrace","filePath":"notes/Operating System/FreeBSD/DTrace.md","title":"DTrace","links":["notes/Programming/C/Flame-Graph"],"tags":[],"content":"One-liners and scripts\nwiki.freebsd.org/DTrace/One-Liners\nCapture stacks\nFor use with Flame Graph.\n# Capture user-level stack at 197 Hz for 60 seconds\nsudo dtrace -x ustackframes=100 -n &#039;profile-197 /execname == &quot;python3.9&quot;/ { @[ustack()] = count(); } tick-60s { exit(0); }&#039; -o out.stacks\n \n# Kernel stack\nsudo dtrace -x stackframes=100 -n &#039;profile-197 /pid == 12345/ { @[stack()] = count(); } tick-60s { exit(0); }&#039; -o out.kstacks\nCapture function argument, return value and latency\nsudo dtrace -s getaddrinfo.d -p 12345\n#!/usr/sbin/dtrace -s\n/*\n * getaddrinfo.d\n */\n \n#pragma D option quiet\n \ndtrace:::BEGIN\n{\n\tprintf(&quot;%-20s  %-4s %-12s %s\\n&quot;, &quot;TIME&quot;, &quot;RET&quot;, &quot;LATENCY(ms)&quot;, &quot;HOST&quot;);\n}\n \npid$target::getaddrinfo:entry\n{\n\tself-&gt;host = copyinstr(arg0);\n\tself-&gt;start = timestamp;\n}\n \npid$target::getaddrinfo:return\n/self-&gt;start/\n{\n\tthis-&gt;delta = (timestamp - self-&gt;start) / 1000000;\n\tprintf(&quot;%-20Y  %-4d %-12d %s\\n&quot;, walltimestamp, arg1, this-&gt;delta, self-&gt;host);\n\tself-&gt;host = 0;\n\tself-&gt;start = 0;\n}"},"notes/Operating-System/FreeBSD/FreeBSD-NIC-settings":{"slug":"notes/Operating-System/FreeBSD/FreeBSD-NIC-settings","filePath":"notes/Operating System/FreeBSD/FreeBSD NIC settings.md","title":"FreeBSD NIC settings","links":[],"tags":[],"content":"ifconfig -m &lt;interface&gt;\n-m display the capability list and all of the supported media for the specified interface. Check the capabilities= line for offload settings.\nCapabilities can be modified with ifconfig as well:\nifconfig &lt;interface&gt; tso4 # Enable tcp(4) segmentation offloading for ip(4) only\nifconfig &lt;interface&gt; -tso4 # Disable tcp(4) segmentation offloading for ip(4) only\nReferences\n\nIFCONFIG(8)\n"},"notes/Operating-System/FreeBSD/FreeBSD-file-systems":{"slug":"notes/Operating-System/FreeBSD/FreeBSD-file-systems","filePath":"notes/Operating System/FreeBSD/FreeBSD file systems.md","title":"FreeBSD file systems","links":[],"tags":[],"content":"\nAnd for comparison with UFS: This is a solid “classic” filesystem. It does provide journaling, to protect data in case of crashes, power outages and the like. Very roughly speaking, it’s comparable to Linux’ ext4. It does NOT provide builtin RAID, checksumming, datasets, virtual volumes, snapshots, clones and all the stuff ZFS can do.\nSo, when to still prefer UFS? IMHO two possible reasons:\n\nYou don’t have the RAM needed for ZFS’ ARC to work well. A rule of thumb for a recommended minimum I’ve often seen is 1GB per TB of storage.\nYou have a special workload that performs much better on UFS. This should be pretty rare, but might happen.\n\n\n\nShort version: if you have 4GB or more go with zfs.\n\nReferences\n\nhttps://forums.FreeBSD.org/threads/zfs-and-ufs-difference.80114/post-508607\n"},"notes/Operating-System/FreeBSD/HDD-power-management-on-FreeBSD":{"slug":"notes/Operating-System/FreeBSD/HDD-power-management-on-FreeBSD","filePath":"notes/Operating System/FreeBSD/HDD power management on FreeBSD.md","title":"HDD power management on FreeBSD","links":[],"tags":[],"content":"Send an ATA identify command to retrieve its power management settings.\ncamcontrol identify /dev/ada0"},"notes/Operating-System/FreeBSD/PF-firewall":{"slug":"notes/Operating-System/FreeBSD/PF-firewall","filePath":"notes/Operating System/FreeBSD/PF firewall.md","title":"PF firewall","links":[],"tags":[],"content":"Rules\nRules are evaluated from top to bottom, in the sequence they are written.\nFor each packet or connection evaluated by PF, the last matching rule in the ruleset is the one which is applied.\nHowever, when a packet matches a rule which contains the quick keyword, the rule processing stops and the packet is treated according to that rule.\nSupported operating systems\n\nFreeBSD\nOpenBSD\n"},"notes/Operating-System/FreeBSD/Upgrading-FreeBSD":{"slug":"notes/Operating-System/FreeBSD/Upgrading-FreeBSD","filePath":"notes/Operating System/FreeBSD/Upgrading FreeBSD.md","title":"Upgrading FreeBSD","links":[],"tags":[],"content":"freebsd-update\nfreebsd-update is not meant to be run in parallel with the same workdir (-d).\nMinor version upgrades\n\nPrebuilt binary packages will also be provided for all major branches and Tier 1 platforms and will be made available via pkg(8). Package builds will use the oldest supported minor release within each major branch to ensure ABI and KBI backwards compatibility within each major branch, and support all minor versions of each major branch, including -RELEASE and -STABLE.\n\nIt’s safe to use pkg from a EoL-ed minor version, as long as the major branch has not reached its EOL date yet.\nbootcode update\nIf you have the good old MBR, try this to update the bootcode.\ngpart bootcode -b /boot/pmbr -p /boot/gptzfsboot -i 1 ada0\n\nReferences\n\ndocs.freebsd.org/en/books/handbook/cutting-edge/#updating-bootcode\nman.freebsd.org/cgi/man.cgi\n"},"notes/Operating-System/Linux/Asahi-Linux":{"slug":"notes/Operating-System/Linux/Asahi-Linux","filePath":"notes/Operating System/Linux/Asahi Linux.md","title":"Asahi Linux","links":["notes/Operating-System/Linux/Building-an-RPM-package-from-source"],"tags":[],"content":"Features\ngithub.com/AsahiLinux/docs/wiki/Feature-Support\nSpeakers\nBuilt-in speaker is supported on M1 and M2 MacBooks.\nGPU\nDo not use apps from Flatpak on Asahi Linux. They can not use system GPU drivers yet. Instead, build it from source.\n\nFlatpak cannot use system GPU drivers, and there is no Flatpak runtime for the Asahi drivers yet. You cannot currently use GPU acceleration with Flatpak apps. - www.reddit.com/r/AsahiLinux/comments/105mbgo/comment/j3br7ju/\n"},"notes/Operating-System/Linux/BBR":{"slug":"notes/Operating-System/Linux/BBR","filePath":"notes/Operating System/Linux/BBR.md","title":"BBR","links":[],"tags":[],"content":"Configuration\nOnly sysctl net.ipv4.tcp_congestion_control is needed since Linux 4.13.\n\nJust a quick announcement that Eric Dumazet has checked in a nice feature in Linux 4.13-rc1 that implements TCP-level pacing in Linux TCP:\ngit.kernel.org/pub/scm/linux/kernel/git/davem/net-next.git/commit/\nThat means that the TCP layer itself can handle the pacing requirements of BBR, if the fq qdisc is not in place. In turn, that means when enabling BBR there is no need to change anything in your qdisc setup, if you don’t want to.\n\nStill, you should tune your qdisc setup for optimal performance."},"notes/Operating-System/Linux/BPF-development-with-Aya-on-aarch64":{"slug":"notes/Operating-System/Linux/BPF-development-with-Aya-on-aarch64","filePath":"notes/Operating System/Linux/BPF development with Aya on aarch64.md","title":"BPF development with Aya on aarch64","links":[],"tags":[],"content":"Prerequisites\nRust toolchain\nInstall with rustup.\ncargo-generate\nInstall openssl headers first.\nBuild bpf-linker with Nix’s LLVM\nbpf-linker requires LLVM. It’s a good idea to use Nix, but it does not provide the prefix needed if installed with nix-env -i.\nerror: No suitable version of LLVM was found system-wide or pointed\n              to by LLVM_SYS_180_PREFIX.\n       \n              Consider using `llvmenv` to compile an appropriate copy of LLVM, and\n              refer to the llvm-sys documentation for more information.\n       \n              llvm-sys: crates.io/crates/llvm-sys\n              llvmenv: crates.io/crates/llvmenv\n\nIt’s recommended to use nix-shell for one-shot builds like this.\nnix-shell -p llvm_18 -p libxml2 --run &quot;cargo install bpf-linker --no-default-features&quot;\n\nNote that we used LLVM 18 here. The LLVM version used to build bpf-linker must match the LLVM version from the rust nightly toolchain defined in {{project-name}}-ebpf/rust-toolchain.toml, which is used to build the eBPF program in your project. For LLVM 18, that means we should specify nightly-2024-07-31 or earlier in the toolchain config file.\nAlbeit not mentioned in bpf-linker’s README, libxml2 is also required.\nMap types\n\nBPF_MAP_TYPE_LRU_HASH provides general purpose hash map storage, and will automatically evict the least recently used entries when the hash table reaches capacity.\n\nPinning\nFrom Map::pin():\n\nWhen a map is pinned it will remain loaded until the corresponding file is deleted.\n\nLog\nSupported display hints: github.com/aya-rs/aya/blob/5397c1ca4b77cd27082e96aab9ab931631df7fa8/aya-log-parser/src/lib.rs#L55-L65\nReading Kconfig\nKernel configs are defined in Kconfig.* files. For example, HZ is defined in github.com/torvalds/linux/blob/b831f83e40a24f07c8dcba5be408d93beedc820f/kernel/Kconfig.hz.\nThere is a PR that implements the same extern data support as libbpf, but only a sample C BPF program is provided. github.com/aya-rs/aya/pull/1017\nPrograms\nsock_ops\n\n\n                  \n                  NOTE\n                  \n                \n\nUntil github.com/aya-rs/aya/issues/987 is implemented, killing the program does not unload the cgroup attachment automatically. However, a new attachment would replace the existing one.\n\n\nOn return values of the sock_ops BPF program:\n\nReturning 0 is a convenient way to set reply to -1.\nOn success, return 1.\n\nThe detailed explanation is:\nOn Linux kernel versions before v5.18, if the program return code is not 1, __cgroup_bpf_run_filter_sock_ops considers it a failure and returns -EPERM.\n/**\n * __cgroup_bpf_run_filter_sock_ops() - Run a program on a sock\n * @sk: socket to get cgroup from\n * @sock_ops: bpf_sock_ops_kern struct to pass to program. Contains\n * sk with connection information (IP addresses, etc.) May not contain\n * cgroup info if it is a req sock.\n * @type: The type of program to be exectuted\n *\n * socket passed is expected to be of type INET or INET6.\n *\n * The program type passed in via @type must be suitable for sock_ops\n * filtering. No further check is performed to assert that.\n *\n * This function will return %-EPERM if any if an attached program was found\n * and if it returned != 1 during execution. In all other cases, 0 is returned.\n */\nint __cgroup_bpf_run_filter_sock_ops(struct sock *sk,\n\t\t\t\t     struct bpf_sock_ops_kern *sock_ops,\n\t\t\t\t     enum cgroup_bpf_attach_type atype)\n{\n\tstruct cgroup *cgrp = sock_cgroup_ptr(&amp;sk-&gt;sk_cgrp_data);\n\tint ret;\n \n\tret = BPF_PROG_RUN_ARRAY_CG(cgrp-&gt;bpf.effective[atype], sock_ops,\n\t\t\t\t    bpf_prog_run);\n\treturn ret == 1 ? 0 : -EPERM;\n}\nEXPORT_SYMBOL(__cgroup_bpf_run_filter_sock_ops);\nIn Linux kernel v5.18 and later the logic was moved to BPF_PROG_RUN_ARRAY_CG, where if the program return code is not 0 it is considered a success unless retval is specified:\n\nIf run_prog(prog, ctx) returns 0 and retval is not set to an error by the BPF program, return value is set to -EPERM because the default retval 0 does not match the range [-4095, -1]. This preserves compatibility with existing BPF programs returning 0.\nOtherwise, that is, if the program return code is not 0 or that retval is set to an error, the BPF program is free to set a retval with bpf_{get,set}_retval helpers, which will be returned by BPF_PROG_RUN_ARRAY_CG as is. If left unset, the default retval 0 will be returned.\nLater in kernel v5.19 an if (ret_flags) check was added to bpf_prog_run_array_cg() which modifies func_ret, but sock_ops has ret_flags set to NULL so it’s never executed, preserving compatibility.\nIf no BPF program were attached, BPF_PROG_RUN_ARRAY_CG returns the default retval set in its arguments, which is 0 for __cgroup_bpf_run_filter_sock_ops.\n\n__cgroup_bpf_run_filter_sock_ops is lightly wrapped by the BPF_CGROUP_RUN_PROG_SOCK_OPS macro, and its return value is processed by tcp_call_bpf().\n/* Call BPF_SOCK_OPS program that returns an int. If the return value\n * is &lt; 0, then the BPF op failed (for example if the loaded BPF\n * program does not support the chosen operation or there is no BPF\n * program loaded).\n */\n#ifdef CONFIG_BPF\nstatic inline int tcp_call_bpf(struct sock *sk, int op, u32 nargs, u32 *args)\n{\n\tstruct bpf_sock_ops_kern sock_ops;\n\tint ret;\n \n\tmemset(&amp;sock_ops, 0, offsetof(struct bpf_sock_ops_kern, temp));\n\tif (sk_fullsock(sk)) {\n\t\tsock_ops.is_fullsock = 1;\n\t\tsock_owned_by_me(sk);\n\t}\n \n\tsock_ops.sk = sk;\n\tsock_ops.op = op;\n\tif (nargs &gt; 0)\n\t\tmemcpy(sock_ops.args, args, nargs * sizeof(*args));\n \n\tret = BPF_CGROUP_RUN_PROG_SOCK_OPS(&amp;sock_ops);\n\tif (ret == 0)\n\t\tret = sock_ops.reply;\n\telse\n\t\tret = -1;\n\treturn ret;\n}\n-EPERM is not 0, so if func_ret (return value of the BPF program, NOT retval) is 0, the value returned by tcp_call_bpf is -1, and the reply value is ignored.\nIn case of success, sock_ops.reply is returned to the caller, which is defined in linux/bpf.h as below.\n/* User bpf_sock_ops struct to access socket values and specify request ops\n * and their replies.\n * Some of this fields are in network (bigendian) byte order and may need\n * to be converted before use (bpf_ntohl() defined in samples/bpf/bpf_endian.h).\n * New fields can only be added at the end of this structure\n */\nstruct bpf_sock_ops {\n\t__u32 op;\n\tunion {\n\t\t__u32 args[4];\t\t/* Optionally passed to bpf program */\n\t\t__u32 reply;\t\t/* Returned by bpf program\t    */\n\t\t__u32 replylong[4];\t/* Optionally returned by bpf prog  */\n\t};\nContributing to Aya\nIf a PR touches public API, run the following command to update xtask/public-api/*.txt files and commit them.\ncargo +nightly xtask public-api --bless\naya-ebpf.txt can be regenerated on macOS, but others may require Linux.\nerror[E0432]: unresolved imports `libc::SYS_bpf`, `libc::SYS_perf_event_open`\n  --&gt; aya/src/sys/mod.rs:19:19\n   |\n19 | use libc::{pid_t, SYS_bpf, SYS_perf_event_open};\n   |                   ^^^^^^^  ^^^^^^^^^^^^^^^^^^^ no `SYS_perf_event_open` in the root\n   |                   |\n   |                   no `SYS_bpf` in the root\n\nReferences\n\naya-rs.dev/book/start/development/\ngithub.com/aya-rs/bpf-linker\ngithub.com/torvalds/linux/blob/5e0497553643b6c6acd16c389afb9cec210f4ea9/Documentation/bpf/map_hash.rst\ngithub.com/iovisor/bcc/blob/master/docs/kernel-versions.md#xdp (driver support for XDP in different kernel versions)\ngithub.com/aya-rs/aya/commit/7b71c7e1cd8d6948764d02afb0279151c6eae437#diff-db79c2f426cf46ef19a0265b625663ded9aaf593faa23ab5ca90007f38493e4dR313\ndocs.rs/aya/0.12.0/aya/maps/enum.Map.html#method.pin (“proper” link for the preceding one but docs.rs failed to build it.)\ngithub.com/torvalds/linux/blob/v5.17/kernel/bpf/cgroup.c#L1166-L1181\ngithub.com/torvalds/linux/blob/v5.17/include/uapi/linux/bpf.h#L5828-L5840\n"},"notes/Operating-System/Linux/BPF":{"slug":"notes/Operating-System/Linux/BPF","filePath":"notes/Operating System/Linux/BPF.md","title":"BPF","links":[],"tags":[],"content":"BPF is a flexible and efficient virtual machine-like construct in the Linux kernel allowing to execute bytecode at various hook points in a safe manner. It is used in a number of Linux kernel subsystems, most prominently networking, tracing and security.\nReferences\n\ndocs.cilium.io/en/stable/bpf/\n"},"notes/Operating-System/Linux/Building-an-RPM-package-from-source":{"slug":"notes/Operating-System/Linux/Building-an-RPM-package-from-source","filePath":"notes/Operating System/Linux/Building an RPM package from source.md","title":"Building an RPM package from source","links":[],"tags":[],"content":"Fedora\ngit clone src.fedoraproject.org/rpms/...\n \nsudo dnf install fedpkg\nsudo usermod -a -G mock &lt;current user&gt; # use admin user only\n \n# Pick mock config\nls /etc/mock\n \n# Build packages for Fedora 39 (AArch64)\n# Avoid `build` which requests build on Fedora&#039;s Koji server.\nfedpkg mockbuild --root fedora-39-aarch64\nGeneric\nsudo dnf install rpmdevtools\nrpmdev-setuptree\n \nrpm -i your.src.rpm\n \ncd ~/rpmbuild/SPECS\nvim pkg.spec # and save\n \n# Prepare build dependencies and sources\nsudo dnf builddep pkg.spec\nspectool -gR pkg.spec\n \n# Build the package\nrpmbuild -bb pkg.spec\n \ncd ~/rpmbuild/RPMS/&lt;arch&gt; # replace &lt;arch&gt; with the corresponding architecture\nsudo dnf install ./pkg-xxx.rpm\nCentOS\ndocs.centos.org/centos-stream-docs/sources/\nAll CentOS Stream RPM Sources live on GitLab."},"notes/Operating-System/Linux/Building-the-Linux-kernel-on-Copr-Build-Service":{"slug":"notes/Operating-System/Linux/Building-the-Linux-kernel-on-Copr-Build-Service","filePath":"notes/Operating System/Linux/Building the Linux kernel on Copr Build Service.md","title":"Building the Linux kernel on Copr Build Service","links":[],"tags":[],"content":"Preparing source repository\nThe kernel source tar is too big to put in a regular git repository, so upstream usually does not commit it. Therefore, you need to get the source files from SRPM via dnf download --source kernel.\nRemember to check the corresponding changelog with dnf changelog kernel, or from the extracted kernel.spec file.\nIn order to reduce the tar file size, xz compression is preferred.\nVersioning\n\nDebian tags backported packages with ~bpoXY+Z suffix.\npackages.debian.org/bookworm-backports/kernel/linux-image-6.6.13+bpo-amd64\nRocky Linux SIG/Security tags packages with .security.0.X suffix.\n\ncurl -O dl.rockylinux.org/pub/sig/9/security/x86_64/security-common/Packages/o/openssh-8.7p1-38.1.el9_4.security.0.7.x86_64.rpm\n\n$ rpm -qip openssh-8.7p1-38.1.el9_4.security.0.7.x86_64.rpm\nName        : openssh\nVersion     : 8.7p1\nRelease     : 38.1.el9_4.security.0.7\n\nCreating a project\nIt is recommended to create separate projects for each kernel X.Y version you maintain.\nCreating a package\nIf you pulled the source repo from upstream, there could be multiple *.spec files around. Remember to specify which spec file to use, otherwise the first spec file found in lexical order will be used.\nDownloading artifacts\nRecursively download .rpm files with wget.\nwget -m -np -A rpm -R &#039;*debug*&#039; -R &#039;kernel-source*&#039; https://...\nExample\nThis is a build of the Linux kernel on openEuler 22.03 LTS SP4 (x86_64) with Copr. Note that .oe2203sp4 is not appended to the release string, which is different from official openEuler packages.\n$ rpm -qip kernel-6.6.0-33.0.0.40.x86_64.rpm\nwarning: kernel-6.6.0-33.0.0.40.x86_64.rpm: Header V4 RSA/SHA256 Signature, key ID bf50dae3: NOKEY\nName        : kernel\nVersion     : 6.6.0\nRelease     : 33.0.0.40\nArchitecture: x86_64\nInstall Date: (not installed)\nGroup       : Unspecified\nSize        : 118902540\nLicense     : GPLv2\nSignature   : RSA/SHA256, Sun 14 Jul 2024 04:47:18 AM UTC, Key ID 03c33fb2bf50dae3\nSource RPM  : kernel-6.6.0-33.0.0.40.src.rpm\nBuild Date  : Sun 14 Jul 2024 03:04:30 AM UTC\nBuild Host  : eur-prod-workerlocal-x86-64-normal-prod-00214392-20240714-02502\nVendor      : openEuler Copr - user l2dy\nURL         : www.kernel.org/\nSummary     : Linux Kernel\nDescription :\nThe Linux Kernel, the operating system core itself.\n"},"notes/Operating-System/Linux/De-prioritize-Linux-process":{"slug":"notes/Operating-System/Linux/De-prioritize-Linux-process","filePath":"notes/Operating System/Linux/De-prioritize Linux process.md","title":"De-prioritize Linux process","links":[],"tags":[],"content":"Credits: cron.daily/mlocate, replace $$ with PID of process.\nrenice +19 -p $$ &gt;/dev/null 2&gt;&amp;1\nionice -c2 -n7 -p $$ &gt;/dev/null 2&gt;&amp;1\nHowever, these days on distributions with systemd, nice value mostly works for interactive sessions, but it no longer works globally. See Revisiting Linux CPU scheduling."},"notes/Operating-System/Linux/Desktop-Linux-performance-optimization":{"slug":"notes/Operating-System/Linux/Desktop-Linux-performance-optimization","filePath":"notes/Operating System/Linux/Desktop Linux performance optimization.md","title":"Desktop Linux performance optimization","links":[],"tags":[],"content":"Kernel\n\nZen (Tunes the kernel for responsiveness at the cost of throughput and power usage)\nCachyOS wiki.cachyos.org/cachyos-kernels/\n\nMemory\n\ngithub.com/systemd/zram-generator (manage compressed block devices with systemd)\n\nScheduler\n\ngithub.com/AdnanHodzic/auto-cpufreq (Automatic CPU speed &amp; power optimizer)\ngitlab.com/ananicy-cpp/ananicy-cpp (auto nice daemon, with community rules support)\n"},"notes/Operating-System/Linux/Docker-log-drivers":{"slug":"notes/Operating-System/Linux/Docker-log-drivers","filePath":"notes/Operating System/Linux/Docker log drivers.md","title":"Docker log drivers","links":[],"tags":["docker"],"content":"On Ubuntu 24.04 Noble,\n       --log-driver=&quot;json-file|syslog|journald|gelf|fluentd|awslogs|splunk|etwlogs|gcplogs|none&quot;\n         Logging driver for the container. Default is defined by daemon --log-driver flag.\n         Warning: the docker logs command works only for the json-file and\n         journald logging drivers.\n\nThe default json-file logging driver is inefficient and does not enable log rotation by default.\nDocker 18.09 introduced a new local logging driver. While it does not appear in docker-run(1) from Ubuntu’s docker.io package, docker logs works just fine in the following test. It’s likely just an error in the man page.\nsudo docker logs -f &quot;$(sudo docker run -d --log-driver=local --rm alpine:latest sh -c &#039;echo a;\n sleep 10; echo b&#039;)&quot;\nReferences\n\nmanpages.ubuntu.com/manpages/noble/en/man1/docker-run.1.html\n"},"notes/Operating-System/Linux/Docker-stdout-and-stderr-output":{"slug":"notes/Operating-System/Linux/Docker-stdout-and-stderr-output","filePath":"notes/Operating System/Linux/Docker stdout and stderr output.md","title":"Docker stdout and stderr output","links":[],"tags":[],"content":"When you run docker exec or docker run with the -t flag, stdout and stderr are indistinguishable and not suitable for redirections."},"notes/Operating-System/Linux/Enable-post-quantum-key-exchange-algorithms-for-OpenSSH-on-RHEL-10":{"slug":"notes/Operating-System/Linux/Enable-post-quantum-key-exchange-algorithms-for-OpenSSH-on-RHEL-10","filePath":"notes/Operating System/Linux/Enable post-quantum key exchange algorithms for OpenSSH on RHEL 10.md","title":"Enable post-quantum key exchange algorithms for OpenSSH on RHEL 10","links":[],"tags":[],"content":"echo &quot;KexAlgorithms mlkem768x25519-sha256,sntrup761x25519-sha512,sntrup761x25519-sha512@openssh.com,curve25519-sha256,curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521&quot; | sudo tee /etc/ssh/sshd_config.d/10-custom-crypto-policies.conf\nsudo systemctl restart sshd.service"},"notes/Operating-System/Linux/Enable-sysstat-(sar)-on-Ubuntu-24.04":{"slug":"notes/Operating-System/Linux/Enable-sysstat-(sar)-on-Ubuntu-24.04","filePath":"notes/Operating System/Linux/Enable sysstat (sar) on Ubuntu 24.04.md","title":"Enable sysstat (sar) on Ubuntu 24.04","links":[],"tags":[],"content":"Data collection\nsudo systemctl enable --now sysstat.service\nThis enables and activates both sysstat-collect.timer and sysstat-summary.timer, which perform data collection and summarization.\nUse the following command to check if systemd timers exist:\nsystemctl list-unit-files | grep sysstat\nOn ancient versions of Ubuntu and Debian, you may need sed -i &#039;s/^ENABLED=&quot;false&quot;/ENABLED=&quot;true&quot;/&#039; /etc/default/sysstat instead."},"notes/Operating-System/Linux/Encrypted-swap-with-random-keys-on-Ubuntu":{"slug":"notes/Operating-System/Linux/Encrypted-swap-with-random-keys-on-Ubuntu","filePath":"notes/Operating System/Linux/Encrypted swap with random keys on Ubuntu.md","title":"Encrypted swap with random keys on Ubuntu","links":[],"tags":[],"content":"\n\n                  \n                  Swap partition or swap files \n                  \n                \n\n\nDo not use swap files with encryption. When the system is low on RAM, dm-crypt might not be able to handle a swap file.\nDo not use swap on HDD disks. Random access on HDD is very slow.\n\n\n\nIdentify swap partition\nFirst, identify your swap partition with blkid and get its UUID.\nThen, find the partition in /dev/disk/by-partuuid/.\nDisable hibernation and resume\nYou will need to reboot after executing the following commands.\necho RESUME=none | sudo tee /etc/initramfs-tools/conf.d/resume\nsudo update-initramfs -u\n \nsudo systemctl mask sleep.target suspend.target hibernate.target hybrid-sleep.target\nConfigure encrypted swap\nThen, set up your /etc/crypttab file and verify it with cryptdisks_start cryptswap.\n# &lt;target name&gt; &lt;source device&gt;         &lt;key file&gt;      &lt;options&gt;\ncryptswap /dev/disk/by-partuuid/XXXX /dev/urandom plain,swap,cipher=aes-xts-plain64,size=256,sector-size=4096\n\nIf you specified sector-size=4096, the whole device must be multiple of it, and you should make the partition 4k aligned with your disk.\nNote that sectors are numbered from 0 in fdisk, so you should keep the start sector of a partition and size of the partition a multiple of 8, assuming that the sector size is 512 bytes.\nTo partition that with fdisk, you should align First sector to multiples of 8, and Last sector to multiples of 8 minus 1. If you are using +sectors to specify the last sector, the number should be multiples of 8 minus 1 too because even +0 occupies a sector.\nFinally, add the following line to /etc/fstab, test it with swapon -a, run update-initramfs -u again and reboot.\n/dev/mapper/cryptswap none swap sw 0 0\n\nYou can use the following commands to check the swap status.\n# Available swap\nfree -h\n# Encryption status\ncryptsetup status cryptswap"},"notes/Operating-System/Linux/Firewalld-specify-zone-by-IP-address":{"slug":"notes/Operating-System/Linux/Firewalld-specify-zone-by-IP-address","filePath":"notes/Operating System/Linux/Firewalld specify zone by IP address.md","title":"Firewalld specify zone by IP address","links":[],"tags":[],"content":"\n\n                  \n                  Warning\n                  \n                \n\nMake sure to add services from the previous zone before adding IP to the new zone.\n\n\nfirewall-cmd --new-zone=minecraft-access --permanent\n\nfirewall-cmd --zone=minecraft-access --add-service=ssh --permanent\nfirewall-cmd --zone=minecraft-access --add-source=a.b.c.d/32 --permanent\nfirewall-cmd --zone=minecraft-access --add-port=25565/tcp --permanent\nfirewall-cmd --reload\n\nRemove --permanent flags and skip the reload command to make runtime changes that are lost on reboot, which is great for experimenting with unfamiliar changes.\nIf the client can change its IP address, risk of locking yourself out is low."},"notes/Operating-System/Linux/Firewalld":{"slug":"notes/Operating-System/Linux/Firewalld","filePath":"notes/Operating System/Linux/Firewalld.md","title":"Firewalld","links":["notes/Operating-System/Linux/Firewalld-specify-zone-by-IP-address"],"tags":[],"content":"Firewall backend\nIn Rocky Linux 9, nftables is the default firewall backend for firewalld.\nZone assignment\nIt is possible to assign zones to connections (e.g. NetworkManager), interfaces and source addresses.\nTo add source addresses to a zone. See Firewalld specify zone by IP address.\nFeatures\nList all\nfirewall-cmd --list-all-zones\nfirewall-cmd --list-all-policies\nfirewall-cmd --get-active-zones\nfirewall-cmd --get-default-zone # for all other interfaces\nPort redirection (IPv4)\nfirewall-cmd --add-forward-port=port=2222:proto=tcp:toport=22:toaddr=10.0.0.1\nIntra-zone forwarding\nforward: yes only works intra-zone. It does not cross zone barriers.\n\nWhen enabled in the default zone, intra zone forwarding can only be applied to the interfaces and sources that have been explicitly added to the current default zone. It can not use a catch-all for all outgoing interfaces as this would allow packets to forward to an interface or source assigned to a different zone.\n\nInter-zone forwarding with policy objects\nInter-zone forwarding is rejected by default.\nchain filter_FWD_public {\n\tjump filter_FWD_public_allow\n[..snip..]\n\treject with icmpx admin-prohibited\n}\n\nchain filter_FWD_public_allow {\n\toifname &quot;enp0s3&quot; accept\n}\n\nWith negative priorities, policies apply before rules in zones and can be used to override default behavior.\n# Policy setup\nfirewall-cmd --permanent --new-policy demo\nfirewall-cmd --permanent --policy=demo --add-ingress-zone=internal\nfirewall-cmd --permanent --policy=demo --add-egress-zone=public\nfirewall-cmd --permanent --zone=public --add-masquerade # masquerade on egress\n \n# Apply restrictions\nfirewall-cmd --permanent --policy=demo --add-rich-rule=&#039;rule service name=&quot;smtp&quot; reject&#039;\nfirewall-cmd --permanent --policy=demo --add-rich-rule=&#039;rule family=&quot;ipv4&quot; destination address=&quot;172.16.0.0/24&quot; accept&#039;\n \n# Ignore rules in following policies and zones\nfirewall-cmd --permanent --policy=demo --set-target REJECT\n \nfirewall-cmd --reload\nfirewall-cmd --info-policy=demo\n# priority: -1\nReferences\n\nfirewalld.org/2020/04/intra-zone-forwarding\nmajor.io/p/forwarding-ports-with-firewalld/\nfirewalld.org/2020/09/policy-objects-introduction\n"},"notes/Operating-System/Linux/Get-information-about-block-devices-and-filesystems":{"slug":"notes/Operating-System/Linux/Get-information-about-block-devices-and-filesystems","filePath":"notes/Operating System/Linux/Get information about block devices and filesystems.md","title":"Get information about block devices and filesystems","links":[],"tags":[],"content":"It is recommended to use lsblk(8) command to get information about block devices, or lsblk --fs to get an overview of filesystems, or findmnt(8) to search in already mounted filesystems.\n# List block devices without partitions\nlsblk -d\n# List block devices and partitions\nlsblk\n# List filesystem types and UUID\nlsblk --fs\n# List mountpoints, filesystem type and mount options\nfindmnt"},"notes/Operating-System/Linux/Handling-configuration-updates-on-rpm-based-distros":{"slug":"notes/Operating-System/Linux/Handling-configuration-updates-on-rpm-based-distros","filePath":"notes/Operating System/Linux/Handling configuration updates on rpm-based distros.md","title":"Handling configuration updates on rpm-based distros","links":[],"tags":[],"content":"Install and run rpmconf, which presents a dialog similar to dpkg.\nrpmconf -a"},"notes/Operating-System/Linux/Hibernation-on-Ubuntu-with-LVM-and-LUKS-encryption":{"slug":"notes/Operating-System/Linux/Hibernation-on-Ubuntu-with-LVM-and-LUKS-encryption","filePath":"notes/Operating System/Linux/Hibernation on Ubuntu with LVM and LUKS encryption.md","title":"Hibernation on Ubuntu with LVM and LUKS encryption","links":[],"tags":[],"content":"References\nrdrn.me/ubuntu-hibernate-luks/"},"notes/Operating-System/Linux/Hide-Ubuntu-Pro-ads-in-Ubuntu":{"slug":"notes/Operating-System/Linux/Hide-Ubuntu-Pro-ads-in-Ubuntu","filePath":"notes/Operating System/Linux/Hide Ubuntu Pro ads in Ubuntu.md","title":"Hide Ubuntu Pro ads in Ubuntu","links":[],"tags":[],"content":"mv /etc/apt/apt.conf.d/20apt-esm-hook.conf /etc/apt/apt.conf.d/20apt-esm-hook.conf.disabled\n# for /etc/update-motd.d/90-updates-available\ntouch /var/lib/update-notifier/hide-esm-in-motd\nrm -f /var/lib/update-notifier/updates-available &amp;&amp; \\\n/usr/lib/update-notifier/update-motd-updates-available\nsed -i &quot;/^ENABLED=/ s/1/0/&quot; /etc/default/motd-news\nsed -i &quot;/^printf / s/^/#/&quot; /etc/update-motd.d/10-help-text"},"notes/Operating-System/Linux/IBus-on-Wayland":{"slug":"notes/Operating-System/Linux/IBus-on-Wayland","filePath":"notes/Operating System/Linux/IBus on Wayland.md","title":"IBus on Wayland","links":[],"tags":[],"content":"\nIBus should be called from the desktop session in %s. For KDE, you can launch ‘%s’ utility and go to “Input Devices” → “Virtual Keyboard” section and select “%s” icon and click “Apply” button to configure IBus in %s. For other desktop sessions, you can copy the ‘Exec=’ line in %s file to a configuration file of the session. Please refer each document about the “Wayland input method” configuration. Before you configure the “Wayland input method”, you should make sure that QT_IM_MODULE and GTK_IM_MODULE environment variables are unset in the desktop session.\n\nOn Fedora 39,\nIBus should be called from the desktop session in Wayland. For KDE, you can launch ‘systemsettings5’ utility and go to “Input Devices” → “Virtual Keyboard” section and select “IBus Wayland” icon and click “Apply” button to configure IBus in Wayland.\nFor other desktop sessions, you can copy the ‘Exec=’ line in org.freedesktop.IBus.Panel.Wayland.Gtk3.desktop file to a configuration file of the session. Please refer each document about the “Wayland input method” configuration. Before you configure the “Wayland input method”, you should make sure that QT_IM_MODULE and GTK_IM_MODULE environment variables are unset in the desktop session."},"notes/Operating-System/Linux/IP-network-hardening-sysctl":{"slug":"notes/Operating-System/Linux/IP-network-hardening-sysctl","filePath":"notes/Operating System/Linux/IP network hardening sysctl.md","title":"IP network hardening sysctl","links":[],"tags":[],"content":"For Ubuntu:\nnet.ipv4.conf.all.send_redirects=0\nnet.ipv4.conf.default.send_redirects=0\nnet.ipv4.conf.all.secure_redirects=0\nnet.ipv4.conf.default.secure_redirects=0\nnet.ipv4.conf.all.log_martians=1\nnet.ipv4.conf.default.log_martians=1\nnet.ipv6.conf.all.accept_ra=0\nnet.ipv6.conf.default.accept_ra=0\n\n# redundant parameters (defaults on Ubuntu 24.04 LTS)\nnet.ipv4.icmp_echo_ignore_broadcasts=1\nnet.ipv4.icmp_ignore_bogus_error_responses=1\nnet.ipv4.tcp_syncookies=1\nnet.ipv4.conf.all.accept_redirects=0\nnet.ipv4.conf.default.accept_redirects=0\nnet.ipv4.conf.all.accept_source_route=0\nnet.ipv6.conf.all.accept_source_route=0\n"},"notes/Operating-System/Linux/Killing-inactive-SSH-Sessions-on-Server":{"slug":"notes/Operating-System/Linux/Killing-inactive-SSH-Sessions-on-Server","filePath":"notes/Operating System/Linux/Killing inactive SSH Sessions on Server.md","title":"Killing inactive SSH Sessions on Server","links":[],"tags":[],"content":"w # find the TTY to kill\nwho -u | grep pts/XXX # grep for TTY to find PID (last column)\nps aux | grep &lt;PID&gt; # verify what the process is\n \n# If &lt;PID&gt; is an interactive shell,\nkill -HUP &lt;PID&gt;\n# Otherwise\nkill &lt;PID&gt;\nReferences\n\nbash(1)\n"},"notes/Operating-System/Linux/Linux-distributions-adoption-statistics":{"slug":"notes/Operating-System/Linux/Linux-distributions-adoption-statistics","filePath":"notes/Operating System/Linux/Linux distributions adoption statistics.md","title":"Linux distributions adoption statistics","links":[],"tags":[],"content":"Fedora REPL\nSpec: docs.fedoraproject.org/en-US/infra/sysadmin_guide/dnf-counting/\nData: data-analysis.fedoraproject.org/\nopenSUSE\nmetrics.opensuse.org/"},"notes/Operating-System/Linux/Linux-kernel-hackers":{"slug":"notes/Operating-System/Linux/Linux-kernel-hackers","filePath":"notes/Operating System/Linux/Linux kernel hackers.md","title":"Linux kernel hackers","links":[],"tags":[],"content":"Kairui Song\n@ryncsn on GitHub and @silsrc on X, primarily worked on swap improvements in 2025."},"notes/Operating-System/Linux/Linux-kernel-mailing-lists":{"slug":"notes/Operating-System/Linux/Linux-kernel-mailing-lists","filePath":"notes/Operating System/Linux/Linux kernel mailing lists.md","title":"Linux kernel mailing lists","links":[],"tags":[],"content":"Web viewers\n\nlore.kernel.org/ (display a full thread with /T/ suffix in URL)\n"},"notes/Operating-System/Linux/List-Out-of-Tree-modules-in-Linux":{"slug":"notes/Operating-System/Linux/List-Out-of-Tree-modules-in-Linux","filePath":"notes/Operating System/Linux/List Out-of-Tree modules in Linux.md","title":"List Out-of-Tree modules in Linux","links":[],"tags":[],"content":"cat /proc/modules, where:\n\nO means TAINT_OOT_MODULE (out-of-tree module)\nE means TAINT_UNSIGNED_MODULE (unsigned module)\n+ means MODULE_STATE_COMING (module-is-being-loaded)\n- means MODULE_STATE_GOING (module-is-being-unloaded)\n\nReferences\n\ngithub.com/torvalds/linux/blob/71d7b52cc33bc3b6697cce8a0a5ac9032f372e47/kernel/module/main.c#L3217\ngithub.com/torvalds/linux/blob/71d7b52cc33bc3b6697cce8a0a5ac9032f372e47/kernel/module/main.c#L875\ngithub.com/torvalds/linux/blob/master/kernel/panic.c#L477\n"},"notes/Operating-System/Linux/Name-resolution-on-Linux":{"slug":"notes/Operating-System/Linux/Name-resolution-on-Linux","filePath":"notes/Operating System/Linux/Name resolution on Linux.md","title":"Name resolution on Linux","links":["notes/Operating-System/Linux/nsswitch.conf"],"tags":[],"content":"With glibc, name resolution goes getaddrinfo() → nsswitch.conf (for Name Service Switch, which is not Network Security Services) → /etc/hosts or DNS. If DNS: → libresolv → host.conf → /etc/hosts or real DNS.\nWith musl, name resolution goes getaddrinfo() → /etc/hosts or DNS. name_from_hosts() reads /etc/hosts directly, and name_from_dns_search() calls name_from_dns() for each search domain with resolver configuration read from /etc/resolv.conf.\nBoth glibc and musl defaults to returning all valid addresses for a host that appears in the /etc/hosts file, instead of only the first. musl’s behavior is not configurable and has a fixed limit of at most 48 results. glibc’s behavior can be configured with the multi keyword in the /etc/host.conf file, and can be overridden by the RESOLV_MULTI environment variable.\ngethostbyname()\ngethostbyname() is obsolete, does not support IPv6 and only returns one IP address even if there are multiple entries.\nApplications\nSome applications do name resolution on their own, some always pick the first address returned from getaddrinfo(). The behavior is very application-specific and you should always test it before making conclusion."},"notes/Operating-System/Linux/NetworkManager":{"slug":"notes/Operating-System/Linux/NetworkManager","filePath":"notes/Operating System/Linux/NetworkManager.md","title":"NetworkManager","links":[],"tags":[],"content":"Common commands\nTo list the currently available network connections:\n~]$ nmcli con show\nNAME              UUID                                  TYPE            DEVICE\nAuto Ethernet     9b7f2511-5432-40ae-b091-af2457dfd988  802-3-ethernet  --\nens3              fb157a65-ad32-47ed-858c-102a48e064a2  802-3-ethernet  ens3\nMyWiFi            91451385-4eb8-4080-8b82-720aab8328dd  802-11-wireless wlp61s0\n\nTo apply changes after a modified connection using nmcli, activate again the connection:\nnmcli con up con-name\nIPv4 configuration\nIt’s possible to configure additional addresses while keep using the automatic DHCP."},"notes/Operating-System/Linux/No-password-sudo":{"slug":"notes/Operating-System/Linux/No-password-sudo","filePath":"notes/Operating System/Linux/No password sudo.md","title":"No password sudo","links":[],"tags":[],"content":"sudo visudo -f /etc/sudoers.d/ubuntu-nopasswd\nubuntu ALL=(ALL) NOPASSWD: ALL\nThe format is User_Spec ::= User_List Host_List &#039;=&#039; Cmnd_Spec_List, so the first ALL means any host and (ALL) is the Runas_Spec ::= &#039;(&#039; Runas_List? (&#039;:&#039; Runas_List)? &#039;)&#039; as part of Cmnd_Spec_List that determines the user and/or the group that a command may be run as.\nThe next part NOPASSWD: is (Tag_Spec &#039;:&#039;)* and the last ALL is Cmnd.\nUser_Spec also supports additional entries prefixed by ’:’ like so: (&#039;:&#039; Host_List &#039;=&#039; Cmnd_Spec_List)*, but it’s clearer to write separate lines."},"notes/Operating-System/Linux/Partition-table-and-mounting-file-systems":{"slug":"notes/Operating-System/Linux/Partition-table-and-mounting-file-systems","filePath":"notes/Operating System/Linux/Partition table and mounting file systems.md","title":"Partition table and mounting file systems","links":[],"tags":[],"content":"Inform kernel to re-read the partition table\nUse partprobe(1).\nCheck filesystem mount status\n$ systemctl status home.mount\n● home.mount - /home\n     Loaded: loaded (/etc/fstab; generated)\n     Active: active (mounted) since Wed 2023-09-27 12:35:59 UTC; 1 week 3 days ago\n      Until: Wed 2023-09-27 12:35:59 UTC; 1 week 3 days ago\n      Where: /home\n       What: /dev/mapper/rl-home\n       Docs: man:fstab(5)\n             man:systemd-fstab-generator(8)\n      Tasks: 0 (limit: 75668)\n     Memory: 4.0K\n        CPU: 6ms\n     CGroup: /system.slice/home.mount\n\nsystemd[1]: Mounting /home...\nsystemd[1]: Mounted /home.\n"},"notes/Operating-System/Linux/Post-quantum-key-agreement-on-RHEL-10":{"slug":"notes/Operating-System/Linux/Post-quantum-key-agreement-on-RHEL-10","filePath":"notes/Operating System/Linux/Post-quantum key agreement on RHEL 10.md","title":"Post-quantum key agreement on RHEL 10","links":[],"tags":[],"content":"/etc/ssh/sshd_config.d/40-redhat-crypto-policies.conf includes /etc/crypto-policies/back-ends/opensshserver.config, which specifies\nKexAlgorithms curve25519-sha256,curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group14-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512\n\nThe mlkem768x25519-sha256 algorithm is not included in this list.\nBased on www.redhat.com/en/blog/post-quantum-cryptography-red-hat-enterprise-linux-10, you need to run the following commands:\ndnf install crypto-policies-pq-preview crypto-policies-scripts\nupdate-crypto-policies --set DEFAULT:TEST-PQ\nNote that the package and system-wide cryptographic policy name are subject to change when post-quantum cryptography exits the technology preview state."},"notes/Operating-System/Linux/Rebasing-a-patched-Linux-kernel-on-openEuler-Copr-(EUR)":{"slug":"notes/Operating-System/Linux/Rebasing-a-patched-Linux-kernel-on-openEuler-Copr-(EUR)","filePath":"notes/Operating System/Linux/Rebasing a patched Linux kernel on openEuler Copr (EUR).md","title":"Rebasing a patched Linux kernel on openEuler Copr (EUR)","links":[],"tags":[],"content":"curl -O &#039;repo.openeuler.org/openEuler-24.03-LTS/update/source/Packages/kernel-6.6.0-72.0.0.64.oe2403.src.rpm&#039;\nbsdtar -xvf kernel-6.6.0-72.0.0.64.oe2403.src.rpm kernel.tar.gz\ngzip -d kernel.tar.gz &amp;&amp; xz kernel.tar # gzipped-file may be too large for your Git forge.\n \ncd kernel/\ngit fetch gitee.com/src-openeuler/kernel.git openEuler-24.03-LTS\ngit log FETCH_HEAD\ngit rebase -i &lt;commit hash&gt;\n# include commit that updates all references to kernel.tar.gz to kernel.tar.xz\n# amend the commit that adds the kernel source tarball.\ncp ../kernel.tar.xz ./\ngit add kernel.tar.xz\ngit commit --amend\ngit rebase --continue\n \n# check result and push if satisfied\ngit push --force-with-lease"},"notes/Operating-System/Linux/SO_REUSEPORT":{"slug":"notes/Operating-System/Linux/SO_REUSEPORT","filePath":"notes/Operating System/Linux/SO_REUSEPORT.md","title":"SO_REUSEPORT","links":[],"tags":[],"content":"Traditional approaches\nTraditional approaches without SO_REUSEPORT limit the application to one accept queue for each TCP listening port, this creates a bottleneck and the thundering herd problem can cause lock contention. [[epoll#epollexclusive-flag|EPOLLEXCLUSIVE Flag]] solved the thundering herd problem, but connections are not evenly distributed. NGINX had to re-add the socket periodically to workaround this.\nLinux with EPOLLEXCLUSIVE usually notifies only the process which\nwas first to add the listening socket to the epoll instance.  As\na result most of the connections are handled by the first worker\nprocess.  To fix this, we re-add the socket periodically, so other\nworkers will get a chance to accept connections.\n\nSO_REUSEPORT\nSO_REUSEPORT allows multiple sockets to listen on the same port, but an implementation problem was acknowledged when it was being merged. Closing a socket could reset connections during their 3-way handshake, so a hot reload as implemented in NGINX would lose some connections in the process even with connection draining.\nIn Linux 5.14, socket migration was added to address this problem.\nSO_REUSEPORT locality\nNew connections flowing into the network stack are distributed using the usual 5-tuple hash. Packets from any of the RX queues, hitting any CPU, might flow into any of the accept queues.\nBut as Cloudflare says:\n\nWe weren’t able to prove definitely if improving packet locality actually improves performance for a high-level TCP application like an HTTP server. In hindsight it makes sense - the added benefit is minuscule compared to the overhead of running an HTTP server, especially with logic in a high level language like Lua.\n\n\nWe got reminded of the obvious - out of the box Linux is remarkably well tuned.\n\nReferences\n\nlpc.events/event/11/contributions/946/attachments/783/1472/Socket_migration_for_SO_REUSEPORT.pdf\nwww.youtube.com/watch\nblog.cloudflare.com/perfect-locality-and-three-epic-systemtap-scripts\ngithub.com/nginx/nginx/blob/145b228530c364452c14d3184f1eee5e09b324aa/src/event/ngx_event_accept.c#L321-L323\ngit.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/\n"},"notes/Operating-System/Linux/Shrink-root-partition-in-live-CD-environment":{"slug":"notes/Operating-System/Linux/Shrink-root-partition-in-live-CD-environment","filePath":"notes/Operating System/Linux/Shrink root partition in live CD environment.md","title":"Shrink root partition in live CD environment","links":[],"tags":[],"content":"sudo e2fsck -f /dev/sdX1\nsudo resize2fs /dev/sdX1 50G\n \nsudo dumpe2fs -h /dev/sdX1 | grep -E &#039;Block (size|count)&#039;\nWith fdisk, print the partition table first with p, then delete the old partition with d and create a new one with the same partition number at the same start sector and +50G for the end sector. Finally, verify the output with p and write to disk with w.\nNote that the fdisk p output shows you the unit and sector size (generally units are sectors of 1). You should verify that the final p output’s Sectors column matches block size * block count / sector size in bytes."},"notes/Operating-System/Linux/SysRq-key":{"slug":"notes/Operating-System/Linux/SysRq-key","filePath":"notes/Operating System/Linux/SysRq key.md","title":"SysRq key","links":[],"tags":[],"content":"/proc/sysrq-trigger\nFor example, echo l &gt; /proc/sysrq-trigger prints a stack backtrace for all active CPUs.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCommandFunctionbWill immediately reboot the system without syncing or unmounting your disks.cWill perform a system crash and a crashdump will be taken if configured.dShows all locks that are held.eSend a SIGTERM to all processes, except for init.fWill call the oom killer to kill a memory hog process, but do not panic if nothing can be killed.gUsed by kgdb (kernel debugger)hWill display help (actually any other key than those listed here will display help. but h is easy to remember :-)iSend a SIGKILL to all processes, except for init.jForcibly “Just thaw it” - filesystems frozen by the FIFREEZE ioctl.kSecure Access Key (SAK) Kills all programs on the current virtual console. NOTE: See important comments below in SAK section.lShows a stack backtrace for all active CPUs.mWill dump current memory info to your console.nUsed to make RT tasks nice-ableoWill shut your system off (if configured and supported).pWill dump the current registers and flags to your console.qWill dump per CPU lists of all armed hrtimers (but NOT regular timer_list timers) and detailed information about all clockevent devices.rTurns off keyboard raw mode and sets it to XLATE.sWill attempt to sync all mounted filesystems.tWill dump a list of current tasks and their information to your console.uWill attempt to remount all mounted filesystems read-only.vForcefully restores framebuffer consolevCauses ETM buffer dump [ARM-specific]wDumps tasks that are in uninterruptible (blocked) state.xUsed by xmon interface on ppc/powerpc platforms. Show global PMU Registers on sparc64. Dump all TLB entries on MIPS.yShow global CPU Registers [SPARC-64 specific]zDump the ftrace buffer0-9Sets the console log level, controlling which kernel messages will be printed to your console. (0, for example would make it so that only emergency messages like PANICs or OOPSes would make it to your console.)\nReferences\n\ndocs.kernel.org/admin-guide/sysrq.html\n"},"notes/Operating-System/Linux/Systemd-overrides":{"slug":"notes/Operating-System/Linux/Systemd-overrides","filePath":"notes/Operating System/Linux/Systemd overrides.md","title":"Systemd overrides","links":[],"tags":[],"content":"Remove entries from list\nNote that for drop-in files, if one wants to remove entries from a setting that is parsed as a list (and is not a dependency), such as AssertPathExists= (or e.g.  ExecStart= in service units), one needs to first clear the list before re-adding all entries except the one that is to be removed. Example:\n[Unit]\n# Reset all assertions and then re-add the condition we want\nAssertPathExists=\nAssertPathExists=/srv/www\n\nDependencies (After=, etc.) cannot be reset to an empty list, so dependencies can only be added in drop-ins.\nsystemd-networkd-wait-online.service\nOn Debian 12, for some reason, /lib/systemd/systemd-networkd-wait-online --any --ipv6 still blocks when all interfaces have appeared, and it’s the same without --any.\nTherefore if you have also encountered this issue and the interface name is constant, add -i &lt;interface&gt; to fix this issue.\n# /etc/systemd/system/systemd-networkd-wait-online.service.d/override.conf\n[Service]\nExecStart=\nExecStart=/lib/systemd/systemd-networkd-wait-online -i eth0 --ipv6\n"},"notes/Operating-System/Linux/Systemd-service-hardening":{"slug":"notes/Operating-System/Linux/Systemd-service-hardening","filePath":"notes/Operating System/Linux/Systemd service hardening.md","title":"Systemd service hardening","links":[],"tags":[],"content":"Run systemd-analyze security [UNIT...] to check other available protections.\nExamples\nCreate the user with $HOME at /run/&lt;username&gt; and configure RuntimeDirectory, so that systemd will create and chown the directory automatically.\nSet RuntimeDirectoryPreserve to no to discard its content when service stops or restarts. If you need more persistence, use StateDirectory and /var/lib/&lt;username&gt; instead.\nGrant CAP_NET_BIND_SERVICE so that the service could bind to well-known ports (0 to 1023). If you don’t need this, you could add PrivateUsers=yes to the user isolation section.\n[Unit]\nDescription=&lt;description&gt;\nAfter=network.target\n\n[Service]\nType=simple\nExecStart=&lt;start-command&gt;\nUser=&lt;user&gt;\nGroup=&lt;user&gt;\n\n# Grant user writable access to home and working directory that persists until system reboot,\n# because /run is a mount point of &quot;tmpfs&quot;.\nWorkingDirectory=~\nRuntimeDirectory=&lt;username&gt;\nRuntimeDirectoryPreserve=yes\n\n# Hardening\nNoNewPrivileges=true\nRestrictNamespaces=yes\nRestrictAddressFamilies=AF_INET AF_INET6 AF_UNIX\nRestrictSUIDSGID=yes\n\n# User isolation\nPrivateTmp=yes\nProtectHome=yes\n\n# Mount entire file system hierarchy read-only as much as possible\nProtectSystem=strict\nPrivateDevices=yes\nProtectKernelTunables=yes\nProtectControlGroups=yes\nProtectProc=invisible\n\n# Limit capabilities\nCapabilityBoundingSet=CAP_NET_BIND_SERVICE\n\n# Grant capabilities\nAmbientCapabilities=CAP_NET_BIND_SERVICE\n\n[Install]\nWantedBy=multi-user.target\n\nTo use BindPaths=, ProtectHome=tmpfs should be used instead and DynamicUser= should be avoided.\n# Hardening\nNoNewPrivileges=true\nRestrictNamespaces=yes\nRestrictAddressFamilies=AF_INET AF_INET6\nRestrictSUIDSGID=yes\n\n# User isolation\nRemoveIPC=yes\nPrivateTmp=yes\nPrivateUsers=yes\nProtectHome=tmpfs\nBindPaths=/home/&lt;user&gt; /home/other/storage\n\n# Mount entire file system hierarchy read-only as much as possible\nProtectSystem=strict\nPrivateDevices=yes\nProtectKernelTunables=yes\nProtectControlGroups=yes\nProtectProc=invisible\n\n# Limit capabilities\nCapabilityBoundingSet=\n"},"notes/Operating-System/Linux/TCP-client-SYN-retries-on-Linux":{"slug":"notes/Operating-System/Linux/TCP-client-SYN-retries-on-Linux","filePath":"notes/Operating System/Linux/TCP client SYN retries on Linux.md","title":"TCP client SYN retries on Linux","links":[],"tags":[],"content":"Number of retries\nCan be configured with sysctl net.ipv4.tcp_syn_retries. The default is 6.\n#define TCP_SYN_RETRIES\t 6\t/* This is how many retries are done\n\t\t\t\t * when active opening a connection.\n\t\t\t\t * RFC1122 says the minimum retry MUST\n\t\t\t\t * be at least 180secs.  Nevertheless\n\t\t\t\t * this value is corresponding to\n\t\t\t\t * 63secs of retransmission with the\n\t\t\t\t * current initial RTO.\n\t\t\t\t */\nTimeout\nDefault initial RTO is 1 second.\n#define TCP_TIMEOUT_INIT ((unsigned)(1*HZ))\t/* RFC6298 2.1 initial RTO value\t*/\nBefore Linux 6.5, the default 6 retries correspond to 63 (1+2+4+…+32) seconds from the first SYN packet till the last retransmission, and 127 seconds (64 seconds later) till the final timeout.\nAfter Linux 6.5, the expected time is 67 seconds (with tcp_syn_linear_timeouts = 4) for last retransmission and 131 seconds for final timeout.\n\nnet.ipv4.tcp_syn_linear_timeouts - INTEGER (since Linux 6.5)\nThe number of times for an active TCP connection to retransmit SYNs with a linear backoff timeout before defaulting to an exponential backoff timeout. This has no effect on SYNACK at the passive TCP side.\nWith an initial RTO of 1 and tcp_syn_linear_timeouts = 4 we would expect SYN RTOs to be: 1, 1, 1, 1, 1, 2, 4, … (4 linear timeouts, and the first exponential backoff using 2^0 * initial_RTO). Default: 4\n\nHowever, actual time from the last retransmission to connection timeout may vary in different environments. You can test the behavior with:\n# nc from nmap\ntime nc -zv -w 200000ms 1.1.1.1 2345\n \n# OpenBSD netcat\ntime nc -zv -w 200 1.1.1.1 2345\n \n# BusyBox nc\ntime nc 1.1.1.1 2345\nFor reference, time till final timeout on macOS is 75 seconds.\n$ time nc -zv -w 200 1.1.1.1 2345\nnc: connectx to 1.1.1.1 port 2345 (tcp) failed: Operation timed out\nnc -zv -w 200 1.1.1.1 2345  0.00s user 0.00s system 0% cpu 1:15.01 total\n\nReferenes\n\ngithub.com/torvalds/linux/blob/795c58e4c7fc6163d8fb9f2baa86cfe898fa4b19/include/net/tcp.h#L110-L117\ngithub.com/torvalds/linux/blob/795c58e4c7fc6163d8fb9f2baa86cfe898fa4b19/include/net/tcp.h#L152\ngithub.com/torvalds/linux/blob/795c58e4c7fc6163d8fb9f2baa86cfe898fa4b19/net/ipv4/tcp_timer.c#L260-L262\ndocs.kernel.org/networking/ip-sysctl.html\n\nComments on kernel source code\n\n3WHS means three-way handshake.\ntcp_init_transfer and subsequently tcp_init_metrics are only called after the connection has been established, so TCP_TIMEOUT_FALLBACK is not used during the three-way handshake.\n"},"notes/Operating-System/Linux/TCP-kernel-parameters":{"slug":"notes/Operating-System/Linux/TCP-kernel-parameters","filePath":"notes/Operating System/Linux/TCP kernel parameters.md","title":"TCP kernel parameters","links":["notes/Operating-System/Linux/BBR"],"tags":["tcp"],"content":"Parameter description\nReference\n\nwww.ibm.com/docs/en/linux-on-systems\nsysctl-explorer.net/\n\nnet.ipv4.tcp_congestion_control\nSee BBR.\nnet.ipv4.tcp_rmem\nContains three values that represent the minimum, default and maximum size of the TCP socket receive buffer.\nThe minimum represents the smallest receive buffer size guaranteed, even under memory pressure. The minimum value defaults to 1 page or 4096 bytes.\nThe default value represents the initial size of a TCP sockets receive buffer. This value supersedes net.core.rmem_default used by other protocols. The default value for this setting is 87380 bytes. It also sets the tcp_adv_win_scale and initializes the TCP window size to 65535 bytes.\nThe maximum represents the largest receive buffer size automatically selected for TCP sockets. This value does not override net.core.rmem_max. The default value for this setting is somewhere between 87380 bytes and 6M bytes based on the amount of memory in the system.\nThe recommendation is to use the maximum value of 16M bytes or higher (kernel level dependent) especially for 10 Gigabit adapters.\nnet.ipv4.tcp_wmem\nSimilar to the net.ipv4.tcp_rmem this parameter consists of 3 values, a minimum, default, and maximum.\nThe minimum represents the smallest receive buffer size a newly created socket is entitled to as part of its creation. The minimum value defaults to 1 page or 4096 bytes.\nThe default value represents the initial size of a TCP sockets receive buffer. This value supersedes net.core.rmem_default used by other protocols. It is typically set lower than net.core.wmem_default. The default value for this setting is 16K bytes.\nThe maximum represents the largest receive buffer size for auto-tuned send buffers for TCP sockets. This value does not override net.core.rmem_max. The default value for this setting is somewhere between 64K bytes and 4M bytes based on the amount of memory available in the system.\nThe recommendation is to use the maximum value of 16M bytes or higher (kernel level dependent) especially for 10 Gigabit adapters.\nnet.ipv4.tcp_max_tw_buckets\nSpecifies the maximum number of sockets in the “time-wait” state allowed to exist at any time. If the maximum value is exceeded, sockets in the “time-wait” state are immediately destroyed and a warning is displayed. This setting exists to thwart certain types of “Denial of Service” attacks. Care should be exercised before lowering this value. When changed, its value should be increased, especially when more memory has been added to the system or when the network demands are high and environment is less exposed to external threats.\nThe default value is 262,144. When network demands are high and the environment is less exposed to external threats the value can be increased to 450,000.\nnet.ipv4.tcp_fin_timeout\nThis parameter determines the length of time an orphaned (unreferenced) connection will wait before it is aborted at the local end. This parameter is especially helpful for when something happens to the remote peer which prevents or excessively delays a response. Since each socket used for connections consumes approximately 1.5K bytes of memory, the kernel must pro-actively abort and purge dead or stale resources.\nThe default value for this parameter is typically 60 (seconds).\n[root@kvmhost ~] # sysctl net.ipv4.tcp_fin_timeout net.ipv4.tcp_fin_timeout = 60\nFor workloads or systems that generate or support high levels of network traffic, it can be advantageous to more aggressively reclaim dead or stale resources. For these configurations, it is recommended to reduce this value to below 10 (seconds).\nRecommendations\nCloudflare (high BDP HTTP requests)\nFor high bandwidth-delay product sessions, the maximum amount of data on the network at any time (equiv. BDP) is large.\nTherefore, a large TCP receive window must be used, which is prone to introduce latency spikes.\nThe goal is to open the throughput floodgates for high BDP connections while simultaneously ensuring very low HTTP request latency, and Cloudflare achieved it with kernel patching and the following parameters.\nnet.ipv4.tcp_rmem = 8192 262144 536870912\nnet.ipv4.tcp_wmem = 4096 16384 536870912\nnet.ipv4.tcp_adv_win_scale = -2\nnet.ipv4.tcp_collapse_max_bytes = 6291456 # with Cloudflare kernel patch\nnet.ipv4.tcp_notsent_lowat = 131072\n\nReference: blog.cloudflare.com/optimizing-tcp-for-high-throughput-and-low-latency\nNote that net.ipv4.tcp_adv_win_scale is obsolete since linux-6.6, replaced with per socket scaling factor."},"notes/Operating-System/Linux/Ubuntu-HWE-kernels":{"slug":"notes/Operating-System/Linux/Ubuntu-HWE-kernels","filePath":"notes/Operating System/Linux/Ubuntu HWE kernels.md","title":"Ubuntu HWE kernels","links":[],"tags":[],"content":"\nlaunchpad.net/ubuntu/noble/+package/linux-generic-hwe-24.04 This package will always depend on the latest complete generic Linux kernel and headers\nlaunchpad.net/ubuntu/+source/linux-meta-hwe-6.14 Versioned builds.\nbugs.launchpad.net/kernel-sru-workflow Brings you to the same bug on bugs.launchpad.net/ubuntu/noble/+bugs?field.searchtext=linux-hwe-6.14.\n"},"notes/Operating-System/Linux/Ubuntu-release-upgrades":{"slug":"notes/Operating-System/Linux/Ubuntu-release-upgrades","filePath":"notes/Operating System/Linux/Ubuntu release upgrades.md","title":"Ubuntu release upgrades","links":["notes/CLI/apt"],"tags":[],"content":"Preparations\nI recommend installing either ubuntu-server or ubuntu-desktop before the upgrade, unless you are upgrading Ubuntu in a container.\nError remediations\nIf do-release-upgrade succeeded with errors, you may attempt to fix those errors with:\napt install -f\nand run autoremove manually:\napt list &#039;?obsolete&#039; # manually review the list\napt autopurge &lt;pkgs&gt; # same as apt autoremove --purge\nSee also apt."},"notes/Operating-System/Linux/Update-initramfs-on-Linux":{"slug":"notes/Operating-System/Linux/Update-initramfs-on-Linux","filePath":"notes/Operating System/Linux/Update initramfs on Linux.md","title":"Update initramfs on Linux","links":[],"tags":[],"content":"Ubuntu\nFor Ubuntu,\n\ndpkg-reconfigure the relevant linux-image package.\n\nThis runs depmod if dkms has a module to install.\nThis always runs update-initramfs and update-grub.\n\n\nUse the following commands as needed.\n\ndepmod -a $(uname -r) # if this kernel&#039;s modules changed\nupdate-initramfs -u -k all # updates existing kernels&#039; initramfs\nupdate-grub # only if have made changes to /etc/default/grub as well\nReferences\n\n/var/lib/dpkg/info/linux-image-$(uname -r).postinst\n/etc/kernel/postinst.d/*\n\nRHEL 10\ndepmod -a $(uname -r) # if this kernel&#039;s modules changed\ndracut -fv /boot/initramfs-$(uname -r).img $(uname -r)"},"notes/Operating-System/Linux/Verify-rpmfusion-signed-RPMs":{"slug":"notes/Operating-System/Linux/Verify-rpmfusion-signed-RPMs","filePath":"notes/Operating System/Linux/Verify rpmfusion-signed RPMs.md","title":"Verify rpmfusion-signed RPMs","links":[],"tags":[],"content":"sudo dnf install distribution-gpg-keys\n \n# You can also use `rpmkeys`, the difference is unknown.\nsudo rpmkeys --import /usr/share/distribution-gpg-keys/rpmfusion/RPM-GPG-KEY-rpmfusion-free-el-10\n \nrpmkeys -K libva-intel-driver-2.4.1%5E20241027gitd30e013-1.el10.x86_64.rpm\nReferences\n\nrpm-misc(8)\n\n-K, --checksig\n       See and use rpmkeys(8).\n"},"notes/Operating-System/Linux/View-RPM-packge-info":{"slug":"notes/Operating-System/Linux/View-RPM-packge-info","filePath":"notes/Operating System/Linux/View RPM packge info.md","title":"View RPM packge info","links":[],"tags":[],"content":"# locally installed and remote package\ndnf info &lt;pkg&gt;\n \n# locally installed package\nrpm -qi &lt;pkg&gt;\n \n# local .rpm file\nrpm -qip &lt;pkg.rpm&gt;"},"notes/Operating-System/Linux/When-to-send-RST-packets-on-close()":{"slug":"notes/Operating-System/Linux/When-to-send-RST-packets-on-close()","filePath":"notes/Operating System/Linux/When to send RST packets on close().md","title":"When to send RST packets on close()","links":[],"tags":[],"content":"Background\nRelevant RFCs:\n\nReset Generation in RFC 793, page 36-37\nRFC 2525, section 2.17\n\nCode\n\ndata was lost when tcp_close() is called.\n\n\t} else if (data_was_unread) {\n\t\t/* Unread data was tossed, zap the connection. */\n\t\tNET_INC_STATS(sock_net(sk), LINUX_MIB_TCPABORTONCLOSE);\n\t\ttcp_set_state(sk, TCP_CLOSE);\n\t\ttcp_send_active_reset(sk, sk-&gt;sk_allocation,\n\t\t\t\t      SK_RST_REASON_NOT_SPECIFIED);\n\nUnder these states, tcp_disconnect() can send RST packets.\n\n/* These states need RST on ABORT according to RFC793 */\n \nstatic inline bool tcp_need_reset(int state)\n{\n\treturn (1 &lt;&lt; state) &amp;\n\t       (TCPF_ESTABLISHED | TCPF_CLOSE_WAIT | TCPF_FIN_WAIT1 |\n\t\tTCPF_FIN_WAIT2 | TCPF_SYN_RECV);\n}\n\t} else if (tcp_need_reset(old_state) ||\n\t\t   (tp-&gt;snd_nxt != tp-&gt;write_seq &amp;&amp;\n\t\t    (1 &lt;&lt; old_state) &amp; (TCPF_CLOSING | TCPF_LAST_ACK))) {\n\t\t/* The last check adjusts for discrepancy of Linux wrt. RFC\n\t\t * states\n\t\t */\n\t\ttcp_send_active_reset(sk, gfp_any(), SK_RST_REASON_NOT_SPECIFIED);\n\t\tWRITE_ONCE(sk-&gt;sk_err, ECONNRESET);\n\nIf the connection is in TCP_CLOSE state (skb is gone), an RST packet is sent in response to any incoming segment except another reset, e.g. if TCP_SYN_SENT transitioned to TCP_CLOSE, and an SYN &amp; ACK packet was received later.\n\nlookup:\n\tsk = __inet_lookup_skb(net-&gt;ipv4.tcp_death_row.hashinfo,\n\t\t\t       skb, __tcp_hdrlen(th), th-&gt;source,\n\t\t\t       th-&gt;dest, sdif, &amp;refcounted);\n\tif (!sk)\n\t\tgoto no_tcp_socket;\n \n# code is simplified for reading\nno_tcp_socket:\n\tdrop_reason = SKB_DROP_REASON_NO_SOCKET;\n\tif (tcp_checksum_complete(skb)) {\n\t\tdrop_reason = SKB_DROP_REASON_TCP_CSUM;\n\t} else {\n\t\ttcp_v4_send_reset(NULL, skb, sk_rst_convert_drop_reason(drop_reason));\n\t}\nBoth tcp_send_active_reset() and tcp_v4_send_reset() / tcp_v6_send_reset() call trace_tcp_send_reset(), which is defined in include/trace/events/tcp.h.\n/*\n * skb of trace_tcp_send_reset is the skb that caused RST. In case of\n * active reset, skb should be NULL\n */\nTRACE_EVENT(tcp_send_reset,\n \n\tTP_PROTO(const struct sock *sk,\n\t\t const struct sk_buff *skb,\n\t\t const enum sk_rst_reason reason),\n \n\tTP_ARGS(sk, skb, reason),\n \n\tTP_STRUCT__entry(\n\t\t__field(const void *, skbaddr)\n\t\t__field(const void *, skaddr)\n\t\t__field(int, state)\n\t\t__field(enum sk_rst_reason, reason)\n\t\t__array(__u8, saddr, sizeof(struct sockaddr_in6))\n\t\t__array(__u8, daddr, sizeof(struct sockaddr_in6))\n\t),\n \n\tTP_fast_assign(\n\t\t__entry-&gt;skbaddr = skb;\n\t\t__entry-&gt;skaddr = sk;\n\t\t/* Zero means unknown state. */\n\t\t__entry-&gt;state = sk ? sk-&gt;sk_state : 0;\n \n\t\tmemset(__entry-&gt;saddr, 0, sizeof(struct sockaddr_in6));\n\t\tmemset(__entry-&gt;daddr, 0, sizeof(struct sockaddr_in6));\n \n\t\tif (sk &amp;&amp; sk_fullsock(sk)) {\n\t\t\tconst struct inet_sock *inet = inet_sk(sk);\n \n\t\t\tTP_STORE_ADDR_PORTS(__entry, inet, sk);\n\t\t} else if (skb) {\n\t\t\tconst struct tcphdr *th = (const struct tcphdr *)skb-&gt;data;\n\t\t\t/*\n\t\t\t * We should reverse the 4-tuple of skb, so later\n\t\t\t * it can print the right flow direction of rst.\n\t\t\t */\n\t\t\tTP_STORE_ADDR_PORTS_SKB(skb, th, entry-&gt;daddr, entry-&gt;saddr);\n\t\t}\n\t\t__entry-&gt;reason = reason;\n\t),\n \n\tTP_printk(&quot;skbaddr=%p skaddr=%p src=%pISpc dest=%pISpc state=%s reason=%s&quot;,\n\t\t  __entry-&gt;skbaddr, __entry-&gt;skaddr,\n\t\t  __entry-&gt;saddr, __entry-&gt;daddr,\n\t\t  __entry-&gt;state ? show_tcp_state_name(__entry-&gt;state) : &quot;UNKNOWN&quot;,\n\t\t  __print_symbolic(__entry-&gt;reason, DEFINE_RST_REASON(FN, FNe)))\n);\nThis version of trace_tcp_send_reset is from Linux v6.10. On older versions of the kernel, sk_rst_reason is not available, and RST packets on time-wait sockets or no socket are not traced.\nReferences\n\ngithub.com/torvalds/linux/blob/528dd46d0fc35c0176257a13a27d41e44fcc6cb3/net/ipv4/tcp.c\n"},"notes/Operating-System/Linux/epoll":{"slug":"notes/Operating-System/Linux/epoll","filePath":"notes/Operating System/Linux/epoll.md","title":"epoll","links":[],"tags":[],"content":"EPOLLEXCLUSIVE flag\nLimitations\nThe following values may be specified in conjunction with EPOLLEXCLUSIVE: EPOLLIN, EPOLLOUT, EPOLLWAKEUP, and EPOLLET.  EPOLLHUP and EPOLLERR can also be specified, but this is not required.\nCentOS 7\nBackport to CentOS 7.3 only supports EPOLLIN and EPOLLOUT events alongside the implicit EPOLLHUP and EPOLLERR events.\n* Mon May 02 2016 Rafael Aquini &lt;aquini@redhat.com&gt; [3.10.0-386.el7]\n- [fs] epoll: restrict EPOLLEXCLUSIVE to POLLIN and POLLOUT (Hannes Frederic Sowa) [1245628]\n- [fs] epoll: add EPOLLEXCLUSIVE flag (Hannes Frederic Sowa) [1245628]\n\ngit.centos.org/rpms/kernel/raw/244b67caa40f10db4d00ce3856382c07cef5b651/f/SPECS/kernel.spec"},"notes/Operating-System/Linux/firejail":{"slug":"notes/Operating-System/Linux/firejail","filePath":"notes/Operating System/Linux/firejail.md","title":"firejail","links":[],"tags":[],"content":"mkdir ~/jail\nfirejail --private=~/jail bash"},"notes/Operating-System/Linux/iptables":{"slug":"notes/Operating-System/Linux/iptables","filePath":"notes/Operating System/Linux/iptables.md","title":"iptables","links":[],"tags":[],"content":"Tables and chains\nen.wikibooks.org/wiki/Communication_Networks/IP_Tables\n\nA simplified diagram focused on iptables is available at stuffphilwrites.com/2014/09/iptables-processing-flowchart/.\nIP sets\nipset expresses complex IP addresses and port based rulesets with one single iptables rule, making it very efficient compared to multiple iptable rules."},"notes/Operating-System/Linux/kdump":{"slug":"notes/Operating-System/Linux/kdump","filePath":"notes/Operating System/Linux/kdump.md","title":"kdump","links":[],"tags":[],"content":"Estimating kdump file size\nmakedumpfile -f --mem-usage /proc/kcore\n\nThe makedumpfile command reports in pages. This means that you must calculate the size of memory in use against the kernel page size, which in the Red Hat Enterprise Linux kernel, is 4 kilobytes for AMD64 and Intel 64 architectures, and 64 kilobytes for IBM POWER architecture.\n\nReferences\n\ndocs.redhat.com/en/documentation/red_hat_enterprise_linux/7/html/kernel_administration_guide/kernel_crash_dump_guide#sect-estimating-kdump-usage\n"},"notes/Operating-System/Linux/nftables":{"slug":"notes/Operating-System/Linux/nftables","filePath":"notes/Operating System/Linux/nftables.md","title":"nftables","links":[],"tags":[],"content":"The nft command\nList rules\nnft list ruleset\nTrace all trafiic\nnft add chain filter trace_chain { type filter hook prerouting priority -301\\; }\nnft add rule filter trace_chain meta nftrace set 1\n \nnft monitor trace\n \nnft delete chain filter trace_chain\nConfiguration\nfrancis.begyn.be/blog/nixos-home-router is a great example if you are familiar with iptables, but note that you can name the tables and chains differently. pavluk.org/blog/2022/01/26/nixos_router.html is another more complicated setup."},"notes/Operating-System/Linux/nsswitch.conf":{"slug":"notes/Operating-System/Linux/nsswitch.conf","filePath":"notes/Operating System/Linux/nsswitch.conf.md","title":"nsswitch.conf","links":[],"tags":[],"content":"nsswitch.conf, the Name Service Switch configuration file, is used by glibc and certain other applications. Most notably, it controls the user, group and host lookup processes.\nRHEL 9, based on Fedora 34, has glibc 2.34 that supports automatically reloading nsswitch.conf if it is changed.\nSince Fedora 36, nsswitch.conf is managed by authselect instead of being directly under glibc.\nReferences\n\ndevelopers.redhat.com/blog/2021/01/15/coming-in-glibc-2-33-reloadable-nsswitch-conf\ndocs.fedoraproject.org/en-US/quick-docs/fedora-and-red-hat-enterprise-linux/\nfedoraproject.org/wiki/Changes/Make_Authselect_Mandatory\n"},"notes/Operating-System/Linux/syslogd":{"slug":"notes/Operating-System/Linux/syslogd","filePath":"notes/Operating System/Linux/syslogd.md","title":"syslogd","links":[],"tags":[],"content":"Local socket\n/dev/log is a local Unix domain socket from where local syslog messages are read. The can alleviate disk I/O from application processes."},"notes/Operating-System/Linux/yay":{"slug":"notes/Operating-System/Linux/yay","filePath":"notes/Operating System/Linux/yay.md","title":"yay","links":[],"tags":[],"content":"Install\n/usr/bin/core_perl must be added to PATH when you run yay. Re-login to fix pod2man not found issue.\nClean build\nClean build is effectively git reset --hard origin/HEAD; git clean -fdx before building the package."},"notes/Operating-System/Linux/zram-on-Debian-12":{"slug":"notes/Operating-System/Linux/zram-on-Debian-12","filePath":"notes/Operating System/Linux/zram on Debian 12.md","title":"zram on Debian 12","links":[],"tags":[],"content":"apt-get install systemd-zram-generator\n# modify config if necessary\ncat /etc/systemd/zram-generator.conf\n \nsystemctl daemon-reload\nsystemctl status systemd-zram-setup@zram0.service"},"notes/Operating-System/NixOS/Experimental-Nix-commands":{"slug":"notes/Operating-System/NixOS/Experimental-Nix-commands","filePath":"notes/Operating System/NixOS/Experimental Nix commands.md","title":"Experimental Nix commands","links":[],"tags":[],"content":"nix shell - run a shell in which the specified packages are available\nnix develop - run a bash shell that provides the build environment of a derivation\nnix run - run a Nix application\nReferences\n\nblog.ysndr.de/posts/guides/2021-12-01-nix-shells/\n"},"notes/Operating-System/NixOS/nix-shell":{"slug":"notes/Operating-System/NixOS/nix-shell","filePath":"notes/Operating System/NixOS/nix shell.md","title":"nix shell","links":[],"tags":[],"content":"nix shell nixpkgs#bash nixpkgs#hello nixpkgs#cowsay --command bash\n"},"notes/Operating-System/NixOS/nix-update-script-for":{"slug":"notes/Operating-System/NixOS/nix-update-script-for","filePath":"notes/Operating System/NixOS/nix-update-script for.md","title":"nix-update-script for","links":[],"tags":[],"content":"Repo: github.com/Mic92/nix-update\nSee wiki.nixos.org/wiki/Nixpkgs/Update_Scripts and nix-community.org/update-bot/ for details."},"notes/Operating-System/NixOS/nixpkgs":{"slug":"notes/Operating-System/NixOS/nixpkgs","filePath":"notes/Operating System/NixOS/nixpkgs.md","title":"nixpkgs","links":["notes/Software/Nix-channel-status"],"tags":[],"content":"Nix and nixpkgs API documentation\nnoogle.dev/\nNix channels\nnixos.org/manual/nixpkgs/unstable/#overview-of-nixpkgs\n\nPackages, including the Nix packages collection, are distributed through channels. The collection is distributed for users of Nix on non-NixOS distributions through the channel nixpkgs-unstable. Users of NixOS generally use one of the nixos-* channels, e.g. nixos-22.11, which includes all packages and modules for the stable NixOS 22.11. Stable NixOS releases are generally only given security updates. More up to date packages and modules are available via the nixos-unstable channel.\nBoth nixos-unstable and nixpkgs-unstable follow the master branch of the nixpkgs repository, although both do lag the master branch by generally a couple of days. Updates to a channel are distributed as soon as all tests for that channel pass, e.g. this table shows the status of tests for the nixpkgs-unstable channel.\n\n\nnixpkgs-unstable: builds all packages for supported platforms.\nnixos-*: builds all packages only for Linux.\n\nSee also Nix channel status.\nLocales on non-NixOS Linux distros\nnixos.wiki/wiki/Locales\nOn Rocky Linux, you should install glibc-all-langpacks, which provides the locale-archive file needed.\nWithout github.com/NixOS/nixpkgs/commit/de64f4939609ba9c258446eb17f9ec7425934f77, which the nixos-24.11 branch does not have, you also need to set LOCALE_ARCHIVE explicitly to avoid using the nixpkgs-bundled locale-archive with just C.UTF-8.\nexport LOCALE_ARCHIVE=/usr/lib/locale/locale-archive\nAlternatively, you could install glibcLocales from nixpkgs and reference the symlink in your .nix-profile via .zshenv.\nexport LOCALE_ARCHIVE=~/.nix-profile/lib/locale/locale-archive # zsh expands ~ to $HOME\nTerminfo on non-NixOS Linux distros\nSimilarly, you may also need to export TERMINFO_DIRS in .zshenv.\nexport TERMINFO_DIRS=/usr/share/terminfo\nBEAM language packages\nraw.githubusercontent.com/NixOS/nixpkgs/master/pkgs/top-level/all-packages.nix\n  inherit (beam.interpreters)\n    erlang erlang_27 erlang_26 erlang_25\n    elixir elixir_1_18 elixir_1_17 elixir_1_16 elixir_1_15 elixir_1_14\n    elixir-ls;\n# ...\n  beamPackages = dontRecurseIntoAttrs beam27Packages;\n  beamMinimalPackages = dontRecurseIntoAttrs beamMinimal27Packages;\n \n  beam25Packages = recurseIntoAttrs beam.packages.erlang_25;\n  beam26Packages = recurseIntoAttrs beam.packages.erlang_26;\n  beam27Packages = recurseIntoAttrs beam.packages.erlang_27;\nraw.githubusercontent.com/NixOS/nixpkgs/master/pkgs/development/beam-modules/default.nix\n      # BEAM-based languages.\n      elixir = elixir_1_18;\ngithub.com/NixOS/nixpkgs/blob/master/doc/languages-frameworks/beam.section.md\n\nAll BEAM-related expressions are available via the top-level beam attribute, which includes:\n\ninterpreters: a set of compilers running on the BEAM, including multiple Erlang/OTP versions (beam.interpreters.erlang_22, etc), Elixir (beam.interpreters.elixir) and LFE (Lisp Flavoured Erlang) (beam.interpreters.lfe).\npackages: a set of package builders (Mix and rebar3), each compiled with a specific Erlang/OTP version, e.g. beam.packages.erlang22.\n\nThe default Erlang compiler, defined by beam.interpreters.erlang, is aliased as erlang. The default BEAM package set is defined by beam.packages.erlang and aliased at the top level as beamPackages.\nTo create a package builder built with a custom Erlang version, use the lambda, beam.packagesWith, which accepts an Erlang/OTP derivation and produces a package builder similar to beam.packages.erlang.\nMany Erlang/OTP distributions available in beam.interpreters have versions with ODBC and/or Java enabled or without wx (no observer support). For example, there’s beam.interpreters.erlang_22_odbc_javac, which corresponds to beam.interpreters.erlang_22 and beam.interpreters.erlang_22_nox, which corresponds to beam.interpreters.erlang_22.\n\nelixir-ls\nelixir-ls is built with the default elixir in BEAM modules. To use a different version of Elixir, you need to override it. For example:\npackages.${system} = rec {\n  erlang = pkgs.beam.interpreters.erlang_27;\n  elixir = pkgs.beam.packages.erlang_27.elixir_1_18;\n  elixir-ls =\n    (pkgs.beam.packages.erlang_27.elixir-ls.override { inherit elixir; });\n}\nYou may still need to install hex locally and run elixir-ls once to “install the ElixirLS release” locally.\nmix local.hex\nelixir-ls\n# press Enter to quit\nIf you see the following error, configure locales per Locales on non-NixOS Linux distros.\nwarning: the VM is running with native name encoding of latin1 which may cause Elixir to malfunction as it expects utf8. Please ensure your locale is set to UTF-8 (which can be verified by running &quot;locale&quot; in your shell) or set the ELIXIR_ERL_OPTIONS=&quot;+fnu&quot; environment variable\n\nFor Emacs, lsp-mode has lsp-elixir-server-command set to &#039;(&quot;language_server.sh&quot;) by default, so you need to change that to elixir-ls, which is used to name the executable in nixpkgs.\nAd hoc commands\nImage conversion and compression examples:\nnix run -- nixpkgs#imagemagick identify a.png\nnix run -- nixpkgs#imagemagick a.png a.jpg\n \nnix run -- nixpkgs#oxipng -o 4 --strip safe --alpha a.png\nReferences\n\nnixos.org/guides/nix-pills/14-override-design-pattern\ngithub.com/NixOS/nixpkgs/blob/89d341f70f7666c346c353a6eb09186f3d6fabb1/doc/using/overrides.chapter.md#pkgoverride-sec-pkg-override\n"},"notes/Operating-System/OpenWRT/WiFi":{"slug":"notes/Operating-System/OpenWRT/WiFi","filePath":"notes/Operating System/OpenWRT/WiFi.md","title":"WiFi","links":[],"tags":[],"content":"Debug commands\niw phy0 info # supported frequencies and TX power\niw phy0 reg get # regulatory domain\niw phy0 channels # DFS state\niw phy0 get txq\niw wlan0 info # current ssid, type, channel &amp; width and txpower\niw dev wlan0 station dump # list of associated stations\n \n# All interfaces&#039; info\niw phy\niw dev\nAP optimization\nRegulatory domain\nThe default country 00 is more restrictive than others. For example, under country SG,\n\nChannel 32 (5150 - 5170) becomes available.\nMaximum transmit power (txpower) increases from 20 to 23 dBm (subject to device capabilities).\n\nroot@OpenWrt:~# iw phy0 reg get\nglobal\ncountry 00: DFS-UNSET\n\t(755 - 928 @ 2), (N/A, 20), (N/A), PASSIVE-SCAN\n\t(2402 - 2472 @ 40), (N/A, 20), (N/A)\n\t(2457 - 2482 @ 20), (N/A, 20), (N/A), AUTO-BW, PASSIVE-SCAN\n\t(2474 - 2494 @ 20), (N/A, 20), (N/A), NO-OFDM, PASSIVE-SCAN\n\t(5170 - 5250 @ 80), (N/A, 20), (N/A), AUTO-BW\n\t(5250 - 5330 @ 80), (N/A, 20), (0 ms), DFS, AUTO-BW, PASSIVE-SCAN\n\t(5490 - 5730 @ 160), (N/A, 20), (0 ms), DFS, PASSIVE-SCAN\n\t(5735 - 5835 @ 80), (N/A, 20), (N/A), PASSIVE-SCAN\n\t(57240 - 63720 @ 2160), (N/A, 0), (N/A)\n \nroot@OpenWrt:~# iw phy0 reg get\nglobal\ncountry SG: DFS-FCC\n\t(2400 - 2483 @ 40), (N/A, 23), (N/A)\n\t(5150 - 5250 @ 80), (N/A, 23), (N/A), AUTO-BW\n\t(5250 - 5350 @ 80), (N/A, 20), (0 ms), DFS, AUTO-BW\n\t(5470 - 5725 @ 160), (N/A, 27), (0 ms), DFS\n\t(5725 - 5850 @ 80), (N/A, 30), (N/A)\n\t(57000 - 66000 @ 2160), (N/A, 40), (N/A)\nSee also git.kernel.org/pub/scm/linux/kernel/git/sforshee/wireless-regdb.git/tree/db.txt\n# This is the world regulatory domain\ncountry 00:\n\t# There is no global intersection for 802.11ah, so just mark the entire\n\t# possible band as NO-IR\n\t(755 - 928 @ 2), (20), NO-IR\n\t(2402 - 2472 @ 40), (20)\n\t# Channel 12 - 13.\n\t(2457 - 2482 @ 20), (20), NO-IR, AUTO-BW\n\t# Channel 14. Only JP enables this and for 802.11b only\n\t(2474 - 2494 @ 20), (20), NO-IR, NO-OFDM\n\t# Channel 36 - 48\n\t(5170 - 5250 @ 80), (20), NO-IR, AUTO-BW\n\t# Channel 52 - 64\n\t(5250 - 5330 @ 80), (20), NO-IR, DFS, AUTO-BW\n\t# Channel 100 - 144\n\t(5490 - 5730 @ 160), (20), NO-IR, DFS\n\t# Channel 149 - 165\n\t(5735 - 5835 @ 80), (20), NO-IR\n\t# IEEE 802.11ad (60GHz), channels 1..3\n\t(57240 - 63720 @ 2160), (0)\nWiFi channel confusion\nWith an 80 MHz wide channel, the center frequency falls in between 20 MHz channels. OpenWRT and iw consider this central frequency in the lower frequency channel.\nFor example, the 80 MHz wide channel formed from channels 36 and 48 is considered “channel 40”, while the new naming convention for 802.11ac recommends 42 instead.\nsupport.metageek.com/hc/en-us/articles/203532644-802-11ac-Channels\nClient mode\nconfig wifi-iface &#039;wifinet1&#039;\n\toption device &#039;radio0&#039;\n\toption mode &#039;sta&#039;\n\toption ssid &#039;AP_SSID&#039;\n\toption encryption &#039;psk2&#039;\n\toption bssid &#039;xx:xx:xx:xx:xx:xx&#039;\n\toption key &#039;xxxxxxxx&#039;\n\toption network &#039;wan&#039;\n\nDon’t use AP+STA on one physical radio without travelmate.\n\nA logical combination of AP+STA mode on one physical radio allows most of OpenWrt supported router devices to connect to a wireless hotspot/station (STA) and provide a wireless access point (AP) from that hotspot at the same time. Downside of this solution: whenever the STA interface looses the connection it will go into an active scan cycle which renders the radio unusable for AP mode operation, therefore the AP is taken down if the STA looses its association.\nTo avoid these kind of deadlocks, travelmate will set all station interfaces to an “always off” mode and connects automatically to available/configured hotspots.\n\ngithub.com/openwrt/packages/blob/openwrt-21.02/net/travelmate/files/README.md\nDFS\nDebug script\n\nSave list of unusable channels when radar is detected.\n\nThe DFS-RADAR-DETECTED message doesn’t show which channels are occupied by radar. freq and chan_width data is from the channel configured on device.\n#!/bin/ash\nset -e\n \nwhile :; do\n  logread -l 100 | grep DFS-RADAR-DETECTED &amp;&amp; break || sleep 10\ndone\n \ndate &gt;&gt; /tmp/radar_channels.log\niw phy0 channels &gt;&gt; /tmp/radar_channels.log"},"notes/Operating-System/Windows/Install-.appx-packages-on-Windows-11-LTSC":{"slug":"notes/Operating-System/Windows/Install-.appx-packages-on-Windows-11-LTSC","filePath":"notes/Operating System/Windows/Install .appx packages on Windows 11 LTSC.md","title":"Install .appx packages on Windows 11 LTSC","links":[],"tags":[],"content":"\nOpen PowerShell as Admin.\nUse the following command to install the .appx package:\n\nAdd-AppxPackage &lt;path to .appx file&gt;"},"notes/Operating-System/Windows/Process-monitoring-on-Windows":{"slug":"notes/Operating-System/Windows/Process-monitoring-on-Windows","filePath":"notes/Operating System/Windows/Process monitoring on Windows.md","title":"Process monitoring on Windows","links":[],"tags":[],"content":"System Informer\ngithub.com/winsiderss/systeminformer\nProcess Explorer from Sysinternals\nlearn.microsoft.com/en-us/sysinternals/downloads/process-explorer\nGood old freeware utility, nowadays maintained by Microsoft."},"notes/Operating-System/Windows/Remote-connection-managers-on-Windows":{"slug":"notes/Operating-System/Windows/Remote-connection-managers-on-Windows","filePath":"notes/Operating System/Windows/Remote connection managers on Windows.md","title":"Remote connection managers on Windows","links":[],"tags":[],"content":"mRemoteNG\nmRemoteNG is an open source multi-protocol remote connection manager for Windows.\nMobaXterm\nMobaXterm Home Edition can be used in a commercial or company environment, provided that the end-user downloaded a copy from their official website. Redistribution or automated deployment is not allowed, and multiple users cannot share a single installation.\nWindTerm\nA cross-platform SSH client. Native ZMODEM feature is planned for v2.8.\nRDCMan from Sysinternals\nA picture is worth a thousand words. techcommunity.microsoft.com/blog/exchange/introducing-remote-desktop-connection-manager-rdcman-2-2/592989"},"notes/Operating-System/macOS/Download-macOS-installer":{"slug":"notes/Operating-System/macOS/Download-macOS-installer","filePath":"notes/Operating System/macOS/Download macOS installer.md","title":"Download macOS installer","links":[],"tags":[],"content":"Download recent releases\nsoftwareupdate --fetch-full-installer --full-installer-version 10.15\nVersion can be taken from the list below.\n$ softwareupdate --list-full-installers\nFinding available software\nSoftware Update found the following full installers:\n* Title: macOS Sonoma, Version: 14.5, Size: 13353373KiB, Build: 23F79, Deferred: NO\n* Title: macOS Sonoma, Version: 14.4.1, Size: 13298513KiB, Build: 23E224, Deferred: NO\n* Title: macOS Sonoma, Version: 14.4, Size: 13297753KiB, Build: 23E214, Deferred: NO\n* Title: macOS Sonoma, Version: 14.3.1, Size: 13073278KiB, Build: 23D60, Deferred: NO\n* Title: macOS Ventura, Version: 13.6.7, Size: 11924125KiB, Build: 22G720, Deferred: NO\n* Title: macOS Ventura, Version: 13.6.6, Size: 11917983KiB, Build: 22G630, Deferred: NO\n* Title: macOS Ventura, Version: 13.6.5, Size: 11916934KiB, Build: 22G621, Deferred: NO\n* Title: macOS Ventura, Version: 13.6.4, Size: 11912664KiB, Build: 22G513, Deferred: NO\n* Title: macOS Monterey, Version: 12.7.5, Size: 12116686KiB, Build: 21H1222, Deferred: NO\n* Title: macOS Monterey, Version: 12.7.4, Size: 12117810KiB, Build: 21H1123, Deferred: NO\n* Title: macOS Monterey, Version: 12.7.3, Size: 12109975KiB, Build: 21H1015, Deferred: NO\n* Title: macOS Big Sur, Version: 11.7.10, Size: 12125478KiB, Build: 20G1427, Deferred: NO\n* Title: macOS Catalina, Version: 10.15.7, Size: 8055650KiB, Build: 19H15, Deferred: NO\n* Title: macOS Catalina, Version: 10.15.7, Size: 8055522KiB, Build: 19H2, Deferred: NO\n* Title: macOS Catalina, Version: 10.15.6, Size: 8055450KiB, Build: 19G2021, Deferred: NO\nOlder releases\nUse github.com/ninxsoft/Mist for older releases, including Mac OS X Lion 10.7.5."},"notes/Operating-System/macOS/Enhanced-text-to-speech-on-macOS":{"slug":"notes/Operating-System/macOS/Enhanced-text-to-speech-on-macOS","filePath":"notes/Operating System/macOS/Enhanced text-to-speech on macOS.md","title":"Enhanced text-to-speech on macOS","links":[],"tags":[],"content":"\nOpen System Settings.app\nSearch for “system voice” under Accessibility → Spoken Content\nClick the info icon on the right of system voice\nClick the Voice dropdown button\nPick a (Enhanced) or (Premium) voice you like and download it\nSelect the voice and confirm\n"},"notes/Operating-System/macOS/Homebrew":{"slug":"notes/Operating-System/macOS/Homebrew","filePath":"notes/Operating System/macOS/Homebrew.md","title":"Homebrew","links":[],"tags":[],"content":"Package Index\nSince Homebrew 4.0.0, it defaults to using JSON files downloaded from API rather than local core and cask taps. The API provides links to binaries hosted on their GitHub Packages registry.\nReferences\n\nbrew.sh/2023/02/16/homebrew-4.0.0/\n"},"notes/Operating-System/macOS/Paravirtualized-graphics":{"slug":"notes/Operating-System/macOS/Paravirtualized-graphics","filePath":"notes/Operating System/macOS/Paravirtualized graphics.md","title":"Paravirtualized graphics","links":[],"tags":[],"content":"\nThe ParavirtualizedGraphics framework implements hardware-accelerated graphics for macOS running in a virtual machine, hereafter known as the guest. The operating system provides a graphics driver that runs inside the guest, communicating with the framework in the host operating system to take advantage of Metal-accelerated graphics.\n\nReferences\n\ndeveloper.apple.com/documentation/paravirtualizedgraphics\n"},"notes/Operating-System/macOS/Touch-ID-for-sudo-on-macOS":{"slug":"notes/Operating-System/macOS/Touch-ID-for-sudo-on-macOS","filePath":"notes/Operating System/macOS/Touch ID for sudo on macOS.md","title":"Touch ID for sudo on macOS","links":[],"tags":[],"content":"See /etc/pam.d/sudo_local.template.\n# sudo_local: local config file which survives system update and is included for sudo\n# uncomment following line to enable Touch ID for sudo\n#auth       sufficient     pam_tid.so\n\nCopy it to sudo_local and uncomment the auth line to enable Touch ID for sudo."},"notes/Operating-System/macOS/macOS-KeyChain-in-CLI-Tools":{"slug":"notes/Operating-System/macOS/macOS-KeyChain-in-CLI-Tools","filePath":"notes/Operating System/macOS/macOS KeyChain in CLI Tools.md","title":"macOS KeyChain in CLI Tools","links":[],"tags":["macos"],"content":"Email\nmbsync (isync)\nUseKeychain yes\n\nAdd the above to mbsync configuration and create the keychain item with:\nsecurity add-internet-password -r imap -s Host -a User -w\nmsmtp\nUse the exact host and user configured in .msmtprc. The process is automatic if you got these right and have compiled msmtp with macOS Keychain support.\nsecurity add-internet-password -r smtp -s mail.freemail.example -a joe.smith@freemail.example -w"},"notes/Operating-System/macOS/macOS-disk-space-analysis":{"slug":"notes/Operating-System/macOS/macOS-disk-space-analysis","filePath":"notes/Operating System/macOS/macOS disk space analysis.md","title":"macOS disk space analysis","links":[],"tags":[],"content":"Analysis\nAnalyze file tree size:\nsudo ncdu -x /System/Volumes/Data\nMonitor file access:\nsudo fs_usage -w | grep &lt;keyword&gt;\n\nClean up\nsudo log erase --all # for /var/db/diagnostics\nTODO\n\nMacPorts stores uncompressed folders in ${prefix}/var/macports/software. Is this a arm64-specific or built-from-source only feature? FAQ#diskspace should be updated.\n"},"notes/Performance-tuning/Flamegraph-tools":{"slug":"notes/Performance-tuning/Flamegraph-tools","filePath":"notes/Performance tuning/Flamegraph tools.md","title":"Flamegraph tools","links":[],"tags":[],"content":"C/C++ with debug info\ngithub.com/mstange/samply"},"notes/Performance-tuning/Optimize-K3s-cluster-host-limits":{"slug":"notes/Performance-tuning/Optimize-K3s-cluster-host-limits","filePath":"notes/Performance tuning/Optimize K3s cluster host limits.md","title":"Optimize K3s cluster host limits","links":[],"tags":["tcp"],"content":"Environment: Ubuntu 24.04 LTS + K3s 1.33 + Cilium 1.17 on QEMU VM with 7.5 GiB RAM on a x86_64 host.\nRecommended sysctl config, with lines matching or lower than their default values commented out:\n# general limits\n#vm.max_map_count = 1048576\n#vm.overcommit_memory = 1\n#fs.nr_open = 1048576\nfs.aio-max-nr = 1048576\nfs.inotify.max_user_instances = 8192\nfs.inotify.max_user_watches = 1048576\n#fs.file-max = 524288\n#kernel.pid_max = 4194304\n \n# networking\nnet.ipv4.tcp_keepalive_time = 600\nnet.ipv4.tcp_keepalive_intvl = 60\n#net.core.netdev_max_backlog = 1000\n#net.core.somaxconn = 4096\nnet.ipv4.tcp_max_syn_backlog = 4096 # default with Cilium&#039;s Bandwidth Manager\n#net.netfilter.nf_conntrack_max = 131072\n#net.netfilter.nf_conntrack_buckets = 262144\nnet.ipv4.tcp_slow_start_after_idle = 0\n#net.ipv4.ip_local_port_range = 32768 60999\n#net.ipv4.tcp_max_tw_buckets = 32768\n \n# network throughput\n# Calculate bandwidth delay product and consider RAM usage before tuning these.\n#\n# global in 4k-pages\n#net.ipv4.tcp_mem = 90633 120846 181266\n#net.ipv4.udp_mem = 181269 241692 362538\n# per-socket buffer in bytes\nnet.ipv4.tcp_wmem = 4096 65536 16777216\nnet.ipv4.tcp_rmem = 4096 87380 16777216\n#net.ipv4.tcp_adv_win_scale = 1 # Obsolete since linux-6.6, replaced with per socket scaling factor\nnet.ipv4.tcp_notsent_lowat = 131072\n \n# not needed on cilium? cilium uses /32 in containers.\n# DO NOT use on AWS\nnet.ipv4.neigh.default.gc_thresh1 = 80000 \nnet.ipv4.neigh.default.gc_thresh2 = 90000\nnet.ipv4.neigh.default.gc_thresh3 = 100000\n \n# security\n#kernel.unprivileged_bpf_disabled = 1\nYou don’t need to tune /etc/security/limits.conf for K8s workload. K3s starts with abundant limits by default:\n# Having non-zero Limit*s causes performance problems due to accounting overhead\n# in the kernel. We recommend using cgroups to do container-local accounting.\nLimitNOFILE=1048576\nLimitNPROC=infinity\nLimitCORE=infinity\nTasksMax=infinity\nReferences\n\ngithub.com/cilium/cilium/blob/9e5fb2eab53f2eb5974db8900ee46ac24a240c51/pkg/datapath/linux/bandwidth/bandwidth.go#L219\ngithub.com/cilium/cilium/blob/9e5fb2eab53f2eb5974db8900ee46ac24a240c51/tools/sysctlfix/main.go\ngithub.com/linuxkit/linuxkit/blob/89a95f958ea0e3b516c0db83c22da8fe3fe2c0e0/pkg/sysctl/etc/sysctl.d/00-linuxkit.conf\ngithub.com/siderolabs/talos/blob/2a7b735b264ebcfa22dc2d6044c9d5cd3057b5c2/internal/app/machined/pkg/controllers/runtime/kernel_param_defaults.go#L113\ncromwell-intl.com/open-source/performance-tuning/tcp.html\nwww.ibm.com/docs/en/was-nd/9.0.5\nwww.ibm.com/docs/en/linux-on-systems\nwww.kernel.org/doc/html/next/networking/ip-sysctl.html\ndocs.aws.amazon.com/linux/al2023/ug/outside-ec2.html (on ARP cache entries)\n"},"notes/Performance-tuning/Optimize-single-box-MariaDB-performance":{"slug":"notes/Performance-tuning/Optimize-single-box-MariaDB-performance","filePath":"notes/Performance tuning/Optimize single-box MariaDB performance.md","title":"Optimize single-box MariaDB performance","links":[],"tags":[],"content":"Save your config to /etc/mysql/mariadb.conf.d/90-custom-server.cnf. Optimal values for the fine tuning and limits sections depends on your workload and environment, so make sure to tune them yourself.\n[mysqld]\n\n# Fine tuning\ninnodb_buffer_pool_size = xxxxM\ninnodb_log_file_size    = xxM\nmax_connections         = 500\ntransaction_isolation   = READ-COMMITTED\n\n# Limits\nmax_allowed_packet      = 32M\n\n# Security\nsql_mode                = STRICT_ALL_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\nlocal_infile            = 0\n\nThis is just a starting point, and you may encounter more issues as you scale up, for example the default innodb_io_capacity, innodb_read_io_threads and innodb_write_io_threads could become a bottleneck and prevent you from fully utilizing your SSD RAID."},"notes/Performance-tuning/Optimize-single-box-NGINX-performance":{"slug":"notes/Performance-tuning/Optimize-single-box-NGINX-performance","filePath":"notes/Performance tuning/Optimize single-box NGINX performance.md","title":"Optimize single-box NGINX performance","links":["notes/Network/NIC-offload","notes/NGINX/proxy/Upstream-Keepalive"],"tags":["tcp"],"content":"NUMA topology\nAMD recommends pinning instances within a NUMA node, but does not recommend doing so via the application-level worker_cpu_affinity option.\nNGINX’s worker_cpu_affinity option may lower performance by increasing the time a process spends waiting for a free CPU. This can be monitored by running runqlat on one of NGINX workers’s PIDs. On the other hand, worker_cpu_affinity eliminates CPU migrations, reduce cache misses and page faults, and slightly increases instructions per cycle. All of which can be verified with perf stat.\nNode Per Socket (NPS) settings\nFor example, a 96-core processor with 96 vCPUs per NGINX instance (2 instances in total) should set NPS2 in BIOS, with each NGINX instance pinned to a NUMA node.\nFor NIC tuning, AMD recommends a combination of NPS=1 with LLC as NUMA enabled. Here, LLC means Last Level Cache, or L3 cache, so the OS will see one NUMA node per L3 cache. This can help the OS schedulers maintain locality to the LLC without causing unnecessary cache-to-cache transactions.\nIf deployment restrictions prevent pinning of VM or NGINX instances, NPS1 will deliver the most consistent performance. This is the best trade-off for this situation, according to AMD.\nNIC configuration\nConfigure NIC queues\nBroadcom recommends the use of combined queues no more than a single IRQ per physical core.\nethtool -L [interface] combined 8 tx 0 rx 0\nEnsure IRQ distribution, i.e. CPU affinity for the NIC queue interrupts, is properly set up. AWS does not recommend disabling the irqbalance service because its ENA driver doesn’t provide affinity hints, and if device reset happens while irqbalance is disabled, this might cause undesirable IRQ distribution. On bare-metal, this could be another case.\nRX and TX ring sizes\nAMD recommends setting the maximum allowable ring size to boost network performance, but not on older kernels or derivers without byte queue limit support (non-BQL drivers).\nBroadcom does not suggest this for all cases as it could result in higher latency and other side effects.\nethtool -G [interface] tx 2047 rx 2047\nInterrupt coalescing\nBroadcom recommends enabling adaptive-rx to improve RX latency or throughput adaptively.\nethtool -C [interface] adaptive-rx on\nGRO (Generic Receive Offload)\nThis should be disabled on routers and bridges, including virtual hosts using bridging. See also NIC offload.\nBroadcom NICs support Hardware GRO, which can be enabled with the following command.\nethtool -K [interface] rx-gro-hw on lro off gro on\nSystem configuration\nLinux kernel version\nAMD recommends using Linux kernel 5.20 or newer that includes IOMMU optimized patches.\nCPU scaling governor\nSet the CPU scaling governor to Performance mode.\necho performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor\nOn Ubuntu, you can use cpupower as well.\nsudo cpupower frequency-set -g performance\nNote: C0 is active state and Cx is sleep state in cpupower monitor -i 60 -m Mperf.\nConfigure limits\nAdd the following configuration to a new file in /etc/security/limits.d/*.conf, if your current limit is lower.\n#nproc – number of processes\n#nofile – number of file descriptors\n* soft nproc 32768\n* hard nproc 65535\n* soft nofile 32768\n* hard nofile 65535\nroot soft nproc 32768\nroot hard nproc 65535\nroot soft nofile 32768\nroot hard nofile 65535\n\nThen, add LimitNOFILE=65535 option to nginx.service or set worker_rlimit_nofile in NGINX configuration to increase the maximum number of open files for worker processes.\nRegarding the nofile limit, the system-wide fs.nr_open sysctl configuration limits it and your new limits cannot exceed it.\nFirewall\nAMD recommends disabling the firewall if possible to improve performance.\nIf you have firewall and connection tracking enabled, make sure nf_conntrack_max is set to an appropriate value.\nTransparent hugepages (THP)\nMake it opt-in with madvise. Only enable THP if you are sure they are beneficial.\necho madvise | sudo tee /sys/kernel/mm/transparent_hugepage/enabled\nsysctl\nThis is a sample sysctl.conf based on various sources including AMD’s recommendations.\n# /etc/sysctl.conf\n########## Kernel ##############\n# Controls the System Request debugging functionality of the kernel\nkernel.sysrq = 0\n \n# Controls whether core dumps will append the PID to the core\n# filename. Useful for debugging multi-threaded applications\nkernel.core_uses_pid = 1\n \n# increase system file descriptor limit\nfs.file-max = 65535\n \n# Allow for more PIDs\nkernel.pid_max = 65536\n \n########## Swap ##############\nvm.swappiness = 10 # Favor RAM over swap\n \n# Disk Caching. Data isn&#039;t critical and can be lost? Favor raising the cache.\n# NOT recommended on modern systems with very alrge amounts of RAM. Comment it out!\nvm.vfs_cache_pressure = 50\nvm.dirty_background_ratio = 50\nvm.dirty_ratio = 80\n \n########## IPv4 networking ##############\n# Controls IP packet forwarding\nnet.ipv4.ip_forward = 0\n \n# Do not accept source routing\nnet.ipv4.conf.default.accept_source_route = 0\n \n# Send redirects, if router, but this is just server\nnet.ipv4.conf.all.send_redirects = 0\nnet.ipv4.conf.default.send_redirects = 0\n \n# Accept packets with SRR option? No\nnet.ipv4.conf.all.accept_source_route = 0\n \n# Accept Redirects? No, this is not router\nnet.ipv4.conf.all.accept_redirects = 0\nnet.ipv4.conf.all.secure_redirects = 0\n \n# Log packets with impossible addresses to kernel log? yes\nnet.ipv4.conf.all.log_martians = 1\nnet.ipv4.conf.default.log_martians = 1\nnet.ipv4.conf.default.accept_source_route = 0\nnet.ipv4.conf.default.accept_redirects = 0\nnet.ipv4.conf.default.secure_redirects = 0\n \n# Ignore all ICMP ECHO and TIMESTAMP requests sent to it via broadcast/multicast\nnet.ipv4.icmp_echo_ignore_broadcasts = 1\n# Turn on protection for bad icmp error messages\nnet.ipv4.icmp_ignore_bogus_error_responses = 1\n \n# Prevent against the common &#039;syn flood attack&#039;\nnet.ipv4.tcp_syncookies = 1\n \n# Controls the use of TCP syncookies\nnet.ipv4.tcp_synack_retries = 2\n \n# Enable source validation by reversed path, as specified in RFC1812\nnet.ipv4.conf.all.rp_filter = 1\nnet.ipv4.conf.default.rp_filter = 1\n \n# TCP and memory optimization\n# increase TCP max buffer size to 8MiB\nnet.ipv4.tcp_rmem = 4096 131072 8388608\nnet.ipv4.tcp_wmem = 4096 16384 8388608\n \n# increase Linux auto tuning TCP buffer limits\nnet.core.rmem_max = 8388608\nnet.core.wmem_max = 8388608\nnet.core.netdev_max_backlog = 5000\nnet.ipv4.tcp_window_scaling = 1\n \n#Increase system IP port limits\nnet.ipv4.ip_local_port_range = 2000 65499\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_fin_timeout = 60\n \nnet.ipv4.tcp_slow_start_after_idle = 0\n \n# Recommended for hosts with jumbo frames enabled\nnet.ipv4.tcp_mtu_probing = 1\n \n# TCP Fast Open\nnet.ipv4.tcp_fastopen = 3\n \n#net.ipv4.tcp_congestion_control = cubic\n \n########## IPv4 networking ends ##############\n \n########## IPv6 networking start ##############\n \n# Number of Router Solicitations to send until assuming no routers are present.\n# This is host and not router\nnet.ipv6.conf.default.router_solicitations = 0\n \n# Accept Router Preference in RA?\nnet.ipv6.conf.default.accept_ra_rtr_pref = 0\n \n# Learn Prefix Information in Router Advertisement\nnet.ipv6.conf.default.accept_ra_pinfo = 0\n \n# Setting controls whether the system will accept Hop Limit settings\n# from a router advertisement\nnet.ipv6.conf.default.accept_ra_defrtr = 0\n \n# Router Advertisements can cause the system to assign a global unicast\n# address to an interface\nnet.ipv6.conf.default.autoconf = 0\n \n# how many neighbor solicitations to send out per address?\nnet.ipv6.conf.default.dad_transmits = 0\n \n# How many global unicast IPv6 addresses can be assigned to each interface?\nnet.ipv6.conf.default.max_addresses = 1\n \n########## IPv6 networking ends ##############\nNotes:\n\nThe default in net.ipv4.tcp_wmem is going to be ignored if it’s not enough for the initial congestion window when the connection enters ESTABLISHED state, so don’t worry about 16384 being too low. Let autotuning do its work.\n\nFor Ubuntu 24.04.2 servers, you can use the following config:\n# /etc/sysctl.d/local.conf\nnet.core.somaxconn=65535\nnet.ipv4.tcp_max_syn_backlog=65535\nnet.core.netdev_max_backlog=65535\nnet.ipv4.tcp_fin_timeout=30\nnet.ipv4.ip_local_port_range=10000 65499\nnet.ipv4.tcp_tw_reuse=1\nnet.ipv4.tcp_syncookies=1\nnet.ipv4.tcp_synack_retries=2\nnet.ipv4.tcp_syn_retries=2\nnet.ipv4.tcp_rmem=4096 131072 8388608\nnet.ipv4.tcp_wmem=4096 16384 8388608\nnet.core.rmem_max=8388608\nnet.core.wmem_max=8388608\nnet.ipv4.tcp_slow_start_after_idle=0\nnet.ipv4.tcp_mtu_probing=1\nvm.swappiness=10\nnet.netfilter.nf_conntrack_max=524288\nnet.netfilter.nf_conntrack_buckets=524288\nFor memory usage optimization, also add:\nnet.ipv4.tcp_notsent_lowat=131072\nnet.ipv4.tcp_shrink_window=1\nNGINX configuration\nEvent handling\n\nConsider enabling multi_accept if your workload shows benefits.\n\nOpen file cache\nUseful for serving lots of static or cached data. See official documentation for the open_file_cache* directives. Check potential benefits with:\n# funclatency /srv/nginx-bazel/sbin/nginx:ngx_open_cached_file -u\n     usecs               : count     distribution\n         0 -&amp;gt; 1          : 10219    |****************************************|\n         2 -&amp;gt; 3          : 21       |                                        |\n         4 -&amp;gt; 7          : 3        |                                        |\n         8 -&amp;gt; 15         : 1        |                                        |\n\nIf there are too many open calls or there are some that take too much time, you can look at enabling the open file cache.\nHTTP keepalive\nkeepalive_requests can be increased, at the risk of introducing additional DDoS attack vectors.\nSee also Upstream Keepalive.\nBuffering requests and responses with large body\nFor buffering the request body, enabling sendfile improves performance for requests with large content size (&gt;1MB) and results in a small performance loss for requests with small content sizes. AMD recommends setting sendfile_max_chunk to the typical average request size.\nEnabling tcp_nopush can be beneficial to serving large content to users by maxing out packet size until the file is fully sent.\nsendfile on;\ntcp_nopush on;\n\nUtilizing kTLS (Kernel TLS offload) can significantly improve sendfile performance. Its configuration depends on the operating system and TLS library used.\nWorker configuration\n\nworker_processes should be set to the number of vCPUs.\nworker_connections should be increased as needed, and ensure you set worker_rlimit_nofile or modify the limits in systemd unit definition accordingly.\n\nLogging\nUse ext4slower to identify disk I/O latency issues. Enable buffering and gzip for the access_log directive to help reduce blocking on I/O.\nIf multiple NGINX processes attempt to write to the same log file, lock contention could be a dominating factor in your CPU profile.\nCaching and compression\nProperly configured cache can increase performance, especially if serving stale content is enabled. Make sure there is sufficient RAM to store the hot cached content in OS page cache.\nNGINX supports Gzip compression, which accelerates the transfer rate from the server to the client and reduces bandwidth usage.\nEnable AIO (Asynchronous file I/O)\nWrite temporary files with data received from proxied servers with AIO to boost performance.\nIf you have a reasonable amount of RAM, you are not using spinning disks and your working data set isn’t very big, NGINX can utilize OS page cache recommends not enabling AIO to reduce the overhead of offloading.\naio threads;\naio_write on;\n\nEnable PCRE JIT\nJIT can speed up processing of regular expressions significantly if you have a lot of them.\npcre_jit on;\n\nHTTP/2 prioritization\ntcp_notsent_lowat - UNSIGNED INTEGER\n\tA TCP socket can control the amount of unsent bytes in its write queue,\n\tthanks to TCP_NOTSENT_LOWAT socket option. poll()/select()/epoll()\n\treports POLLOUT events if the amount of unsent bytes is below a per\n\tsocket value, and if the write queue is not full. sendmsg() will\n\talso not add new buffers if the limit is hit.\n\n\tThis global variable controls the amount of unsent data for\n\tsockets not using TCP_NOTSENT_LOWAT. For these sockets, a change\n\tto the global variable has immediate effect.\n\n\tDefault: UINT_MAX (0xFFFFFFFF)\n\nDetect event loop stalls\nIf you start noticing that your nginx is spending too much time inside ngx_process_events_and_timers, and distribution is bimodal, then you probably are affected by event loop stalls.\n# funclatency &#039;/srv/nginx-bazel/sbin/nginx:ngx_process_events_and_timers&#039; -m\n     msecs               : count     distribution\n         0 -&amp;gt; 1          : 3799     |****************************************|\n         2 -&amp;gt; 3          : 0        |                                        |\n         4 -&amp;gt; 7          : 0        |                                        |\n         8 -&amp;gt; 15         : 0        |                                        |\n        16 -&amp;gt; 31         : 409      |****                                    |\n        32 -&amp;gt; 63         : 313      |***                                     |\n        64 -&amp;gt; 127        : 128      |*                                       |\n\nYou will need more skills to root cause and fix such issues, which is beyond the scope of this article.\nReferences\n\ndropbox.tech/infrastructure/optimizing-web-servers-for-high-throughput-and-low-latency\nnetdevconf.org/1.2/papers/bbr-netdev-1.2.new.new.pdf\nwww.youtube.com/watch\ntechdocs.broadcom.com/us/en/storage-and-ethernet-connectivity/ethernet-nic-controllers/bcm957xxx/adapters/Tuning.html\nwww.amd.com/content/dam/amd/en/documents/epyc-technical-docs/tuning-guides/58489_amd-epyc-9005-tg-nginx.pdf\nwww.amd.com/content/dam/amd/en/documents/epyc-technical-docs/tuning-guides/58472_amd-epyc-9005-tg-linux-network.pdf\nwww.amd.com/content/dam/amd/en/documents/epyc-technical-docs/tuning-guides/amd-epyc-9004-tg-azure.pdf (AMD EPYC 9004 Series on Azure)\ncdrdv2-public.intel.com/334019/334019_Intel%20Ethernet%20700%20Series%20Linux%20Performance%20Tuning%20Guide.pdf\nblog.cloudflare.com/http-2-prioritization-with-nginx/\n"},"notes/Performance-tuning/Optimize-single-box-PostgreSQL-performance":{"slug":"notes/Performance-tuning/Optimize-single-box-PostgreSQL-performance","filePath":"notes/Performance tuning/Optimize single-box PostgreSQL performance.md","title":"Optimize single-box PostgreSQL performance","links":[],"tags":[],"content":"PostgreSQL Configuration\nshared_buffers\nThis parameter has the most variance of all. Some workloads work best with minimal values (such as 1GB or 2GB), even with huge database volumes. Other workloads require large values. The LEAST(RAM/2, 10GB) is a reasonable starting point.\nThis formula has no specific reason beyond the PostgreSQL community’s years of collective wisdom and experience. Complex interactions between the kernel cache and shared_buffers make it nearly impossible to describe exactly why this formula generally provides good results.\nReferences\n\ninfo.enterprisedb.com/rs/069-ALB-339/images/Q4%202021%20-%20Webinar%20-%20Slides%20-%20Tuning%20Tips%20to%20Maximize%20Postgres%20Performance.pdf\nwww.enterprisedb.com/postgres-tutorials/introduction-postgresql-performance-tuning-and-optimization (PostgreSQL v13)\nwww.enterprisedb.com/blog/improving-postgresql-performance-without-making-changes-postgresql (EDB Advanced Server v13)\ncdrdv2-public.intel.com/816245/postgresql-on-azure-dsv5-esv5-optimization.pdf (PostgreSQL v13)\ncdrdv2-public.intel.com/684953/Open-Source-Database-Tuning-Guide-on-3rd-Generation-Intel-Xeon-Scalable-Processors-1.pdf (PostgreSQL v13)\n"},"notes/Privacy/iCloud-Private-Relay":{"slug":"notes/Privacy/iCloud-Private-Relay","filePath":"notes/Privacy/iCloud Private Relay.md","title":"iCloud Private Relay","links":[],"tags":[],"content":"Sign in with Apple\n\nTo send emails to users with private email addresses, you must register your outbound emails or email domains and use Sender Policy Framework (SPF) to authenticate your outbound emails.\n\nPrivate relay email addresses created via Sign in with Apple is restricted to only receive emails from registered domains of the respective development team only.\nReferences\n\ndeveloper.apple.com/documentation/sign_in_with_apple/sign_in_with_apple_js/communicating_using_the_private_email_relay_service\ndeveloper.apple.com/help/account/configure-app-capabilities/configure-private-email-relay-service/\n"},"notes/Programming":{"slug":"notes/Programming","filePath":"notes/Programming.md","title":"Programming","links":[],"tags":[],"content":"Programming is the process of creating software."},"notes/Programming/Arcanist":{"slug":"notes/Programming/Arcanist","filePath":"notes/Programming/Arcanist.md","title":"Arcanist","links":[],"tags":[],"content":"Revisions\narc diff discards local commit history, and only submits the diff to base to Phorge.\nEvery subsequent arc diff updates an existing revision.\nIf your revision has not been accepted, forcibly executing arc land would not auto-close it. To accept your own revisions, the server must have differential.allow-self-accept set to true.\nReferences\n\nwe.phorge.it/book/phorge/article/arcanist_diff/\nsecure.phabricator.com/T1508\n"},"notes/Programming/C/Compile-Database":{"slug":"notes/Programming/C/Compile-Database","filePath":"notes/Programming/C/Compile Database.md","title":"Compile Database","links":[],"tags":[],"content":"Database generation\nCMake\ncmake -DCMAKE_EXPORT_COMPILE_COMMANDS=On ...\n\nMakefile\ngithub.com/nickdiego/compiledb\ncompiledb make -j&lt;N&gt;\nOn macOS, you may need to use gmake to workaround SIP (System Integrity Protection)."},"notes/Programming/C/Flame-Graph":{"slug":"notes/Programming/C/Flame-Graph","filePath":"notes/Programming/C/Flame Graph.md","title":"Flame Graph","links":[],"tags":[],"content":"github.com/brendangregg/FlameGraph\nGraph variants\n\n--reverse stack-reversed flame graph\n--inverted icicle graph (top to bottom, like icicles)\n\nOn RHEL 10\nYou may install js-ds-flame-graph and use\nperf script flamegraph -a -F 49 sleep 30\n# or\npref record -F 49 -a -g -- sleep 30\nperf script report flamegraph\nThis is available since perf from Linux 5.8."},"notes/Programming/C/LLVM/Code-coverage":{"slug":"notes/Programming/C/LLVM/Code-coverage","filePath":"notes/Programming/C/LLVM/Code coverage.md","title":"Code coverage","links":[],"tags":[],"content":"llvm-cov gcov\n\nOnce you have generated the coverage data files, run llvm-cov gcov for each main source file where you want to examine the coverage results. This should be run from the same directory where you previously ran the compiler.\n\n./configure \\\n  CFLAGS=&quot;--coverage&quot; \\\n  LDFLAGS=&quot;--coverage&quot;\nmake\ncd src\ngcov *.c\nprofile-instr\n\nTo use llvm-cov show, you need a program that is compiled with instrumentation to emit profile and coverage data. To build such a program with clang use the -fprofile-instr-generate and -fcoverage-mapping flags. If linking with the clang driver, pass -fprofile-instr-generate to the link stage to make sure the necessary runtime libraries are linked in.\n\n./configure \\\n  CFLAGS=&quot;-fprofile-instr-generate -fcoverage-mapping&quot; \\\n  LDFLAGS=&quot;-fprofile-instr-generate&quot;\nmake\nLLVM_PROFILE_FILE=&quot;$PWD/cov-%p.profraw&quot; make test\nllvm-profdata merge --sparse --output=cov.profdata cov-*.profraw"},"notes/Programming/Elixir/Ecto-repository-URLs":{"slug":"notes/Programming/Elixir/Ecto-repository-URLs","filePath":"notes/Programming/Elixir/Ecto repository URLs.md","title":"Ecto repository URLs","links":[],"tags":[],"content":"Repositories by default support URLs. For example, the configuration above could be rewritten to:\nconfig :my_app, Repo,\n  url: &quot;ecto://postgres:postgres@localhost/ecto_simple&quot;\nThe schema can be of any value and the path represents the database name. The URL will be used generate the relevant Repo configuration values, such as :database, :username, :password, :hostname and :port. These values take precedence over those already specified in the Repo’s configuration.\nURL can include query parameters to override shared and adapter-specific options, like ssl, timeout and pool_size. The following example shows how to pass these configuration values:\nconfig :my_app, Repo,\n  url: &quot;ecto://postgres:postgres@localhost/ecto_simple?ssl=true&amp;pool_size=10&quot;\nReferences\n\nhexdocs.pm/ecto/Ecto.Repo.html#module-urls\n"},"notes/Programming/Elixir/IEx-one-liners":{"slug":"notes/Programming/Elixir/IEx-one-liners","filePath":"notes/Programming/Elixir/IEx one-liners.md","title":"IEx one-liners","links":[],"tags":[],"content":"Resolve domain name to IP addresses\nUse :inet for IPv4 and :inet6 for IPv6.\ncase :inet.getaddr(&#039;g.co&#039;, :inet) do {:ok, ip} -&gt; :inet.ntoa(ip); e -&gt; e end\ncase :inet.getaddr(&#039;g.co&#039;, :inet6) do {:ok, ip} -&gt; :inet.ntoa(ip); e -&gt; e end"},"notes/Programming/Elixir/TLS-peer-verification-in-Erlang-and-Elixir":{"slug":"notes/Programming/Elixir/TLS-peer-verification-in-Erlang-and-Elixir","filePath":"notes/Programming/Elixir/TLS peer verification in Erlang and Elixir.md","title":"TLS peer verification in Erlang and Elixir","links":[],"tags":[],"content":"Erlang/OTP\nAs of Erlang/OTP 27, The OTP ssl module is responsible for TLS peer verification.\nVerifying a certificate hostname\nwww.erlang.org/docs/27/apps/ssl/ssl.html\n\nThe default for Verify was changed to verify_peer in Erlang/OTP 26.\nIf not specified, SNI will default to the Host argument of connect/3,4 unless it is of type inet:ip_address(). The hostname will also be used in the hostname verification of the peer certificate using public_key:pkix_verify_hostname/2. The special value disable prevents the Server Name Indication extension from being sent and disables the hostname verification check.\nFor example, here is how to use standard hostname checking for HTTPS implemented in Public_Key:\n\n{customize_hostname_check, [{match_fun, public_key:pkix_verify_hostname_match_fun(https)}]}\n\nBut what happens if {customize_hostname_check, HostNameCheckOpts :: list()} is not specified?\nVerifying a certificate hostname gives an introduction to the certificate hostname verification process, and pkix_verify_hostname_match_fun/1 gives a hint on how the default match function works:\n\nCurrently supported https fun will allow wildcard certificate matching as specified by the HTTP standard. Note that for instance LDAP have a different set of wildcard matching rules. If you do not want to allow wildcard certificates (recommended from a security perspective) or otherwise customize the hostname match the default match function used by ssl application will be sufficient.\n\nBut as described in Hostname extraction:\n\nSuppose you have some URI with a very special protocol-part: myspecial://example.com&quot;. Since this a non-standard URI there will be no hostname extracted for matching CN-names in the Subject.\n\nThe only standard URI protocol accepted by verify_hostname_extract_fqdn_default/1 is https. So unless you have an https:// URI, extraction of hostname from the URI is not performed and verification of wildcard certificates fails.\nThe relevant code in OTP starts with ssl_handshake:validate_certificate_chain/8 and ssl_handshake:certify/9, where ServerName is crafted from ssl_handshake:server_name/3 which returns a string().\nExecution then continues at ssl_handshake:path_validate/11, CB:path_validation/10, where VerifyState is composed and passed to ssl_handshake:validation_fun_and_state/4, ssl_certificate:validate/4, and then validate/4 then calls verify_hostname/4 if hostname is not disable.\nvalidate(Cert, valid_peer, UserState0 = #{role := client, server_name := Hostname,\n                                          customize_hostname_check := Customize},\n         LogLevel) when Hostname =/= disable -&gt;\n    case verify_hostname(Hostname, Customize, Cert, UserState0) of\n        {valid, UserState} -&gt;\n            common_cert_validation(Cert, UserState, LogLevel);\n        Error -&gt;\n            Error\n    end;\nIf the Hostname is not an IP address nor a tuple, which is the most common case, verify_hostname/4 turns it into {dns_id, Hostname} and calls public_key:pkix_verify_hostname/3 for verification.\nverify_hostname(Hostname, Customize, Cert, UserState) -&gt;\n    HostId = case inet:parse_strict_address(Hostname) of\n                 {ok, IP} -&gt; {ip, IP};\n                 _ -&gt; {dns_id, Hostname}\n             end,\n    case public_key:pkix_verify_hostname(Cert, [HostId], Customize) of\n        true  -&gt; {valid, UserState};\n        false -&gt; {fail, {bad_cert, hostname_check_failed}}\n    end.\npkix_verify_hostname/3 then defines a few defaults that can be overridden in HostNameCheckOpts:\n    MatchFun = proplists:get_value(match_fun,     Opts, undefined),\n    FailCB   = proplists:get_value(fail_callback, Opts, fun(_Cert) -&gt; false end),\n    FqdnFun  = proplists:get_value(fqdn_fun,      Opts, fun verify_hostname_extract_fqdn_default/1),\nverify_hostname_extract_fqdn_default/1 is used as the default FqdnFun, and the default MatchFun is undefined.\nWith an X.509 Subject Alternative Name extension in the certificate (an important assumption, see below), pkix_verify_hostname/3 calls verify_hostname_match_loop/5 first to match ReferenceIDs (hostname or IP address in URI) with PresentedIDs extracted from subjectAltName.\n    PresentedIDs =\n\ttry lists:keyfind(?&#039;id-ce-subjectAltName&#039;,\n\t\t\t  #&#039;Extension&#039;.extnID,\n\t\t\t  TbsCert#&#039;OTPTBSCertificate&#039;.extensions)\n\tof\n\t    #&#039;Extension&#039;{extnValue = ExtVals} -&gt;\n\t\t[{T,to_string(V)} || {T,V} &lt;- ExtVals];\n\t[..snip..]\n\t_ -&gt;\n\t\t Try to extract DNS-IDs from URIs etc\n\t\t    DNS_ReferenceIDs =\n\t\t\t[{dns_id,X} || X &lt;- verify_hostname_fqnds(ReferenceIDs, FqdnFun)],\n\t\t    verify_hostname_match_loop(DNS_ReferenceIDs, PresentedIDs,\n\t\t\t\t\t       MatchFun, FailCB, Cert);\n\t\ttrue -&gt;\n\t\t    true\n \nHere extracted FQDNs are wrapped into DNS_ReferenceIDs of type dns_id is given to the function verify_hostname_match_loop/5, which would fail in the same way, meaning that wildcard certificates are not supported by default if the certificate has an X.509 Subject Alternative Name extension.\nLibraries using TLS\nMint\nCA store\nSince this commit (v1.6.1), Mint defaults to using Erlang certificate store (see public_key:cacerts_get/0 and friends) if available, instead of CAStore.\nIf you are running your application in Docker, make sure to install ca-certificates in your container. For Debian slim images, you can use\nRUN apt-get update -y &amp;&amp; \\\n  apt-get install -y libstdc++6 openssl libncurses5 locales ca-certificates \\\n  &amp;&amp; apt-get clean &amp;&amp; rm -f /var/lib/apt/lists/*_*\nwhich also installs several other useful packages recommended by hexdocs.pm/phoenix/releases.html.\nVerifying certificate hostname\nMint, along with Finch and Req’s default adapter Req.Steps.run_finch/1 that depends on it, sets :customize_hostname_check to its custom version by default. The most prominent clause of which is\n  # Wildcard domain handling for DNS ID entries in the subjectAltName X.509\n  # extension. Note that this is a subset of the wildcard patterns implemented\n  # by OTP when matching against the subject CN attribute, but this is the only\n  # wildcard usage defined by the CA/Browser Forum&#039;s Baseline Requirements, and\n  # therefore the only pattern used in commercially issued certificates.\n  defp match_fun({:dns_id, reference}, {:dNSName, [?*, ?. | presented]}) do\n    ...\n  end\n\nThe comments were added around the time OTP-20.0 was released, but the fallback logic in pkix_verify_hostname/3 has not changed since as of Erlang/OTP 27. If an X.509 Subject Alternative Name extension is NOT present, the PresentedCNs is checked instead.\n\t    %% Fallback to CN-ids [rfc6125, ch6]\n\t    case TbsCert#&#039;OTPTBSCertificate&#039;.subject of\n\t\t{rdnSequence,RDNseq} -&gt;\n\t\t    PresentedCNs =\n\t\t\t[{cn, to_string(V)}\n\t\t\t || ...\nRedix\nReference documentation: hexdocs.pm/redix/1.5.2/Redix.html#module-ssl\nCA store\nIf the CAStore dependency is available, Redix will pick up its CA certificate store file automatically.\nOtherwise, you have to configure a different CA certificate store by passing in the :cacertfile or :cacerts socket options.\nVerifying certificate hostname\nWithout additional socket options, Redix follows the default behavior and fails to match any wildcard certificate with an X.509 Subject Alternative Name extension, which is the only pattern used in commercially issued certificates.\nTherefore, some Redis servers that use wildcard certificates, notably Amazon ElastiCache, require additional socket options for successful verification (requires OTP 21.0 or later):\nRedix.start_link(\n  host: &quot;example.com&quot;, port: 9999, ssl: true,\n  socket_opts: [\n    customize_hostname_check: [\n      match_fun: :public_key.pkix_verify_hostname_match_fun(:https)\n    ]\n  ]\n)\nDefault ssl_opts\nIn connector.ex, :verify_peer is enabled by default and since this commit the default depth has been increased to 3 to support longer certificate chains.\n  @default_ssl_opts [verify: :verify_peer, depth: 3]"},"notes/Programming/Elixir/Troubleshooting-in-production-with-IEx":{"slug":"notes/Programming/Elixir/Troubleshooting-in-production-with-IEx","filePath":"notes/Programming/Elixir/Troubleshooting in production with IEx.md","title":"Troubleshooting in production with IEx","links":[],"tags":[],"content":"References\n\nwww.elixirstreams.com/tips/tracing-with-recon\nwww.youtube.com/watch\n"},"notes/Programming/Fennel/Fennel-gotchas":{"slug":"notes/Programming/Fennel/Fennel-gotchas","filePath":"notes/Programming/Fennel/Fennel gotchas.md","title":"Fennel gotchas","links":[],"tags":[],"content":"set and local variables\nset does not work on globals or let/local-bound locals, but can be used to change a field of a table.\n(let [t {:a 4 :b 8}]\n  (set t.a 2) t) ; =&gt; {:a 2 :b 8}\nUse var to declare a mutable local variable that can be set."},"notes/Programming/Go/Go-HTTP-routers":{"slug":"notes/Programming/Go/Go-HTTP-routers","filePath":"notes/Programming/Go/Go HTTP routers.md","title":"Go HTTP routers","links":[],"tags":[],"content":"I’m seeking for an idiomatic and lightweight HTTP router with acceptable performance.\nLOC is a subjective figure to determine how lightweight a library is.\nfind chi -maxdepth 1 -name &#039;*.go&#039; \\! -name &#039;*_test.go&#039; -print0 | xargs -0 cloc\nHttpRouter, gorilla/mux and chi all have less than 2k lines of core code.\nBesides LOC, the API surface is also a good reference on how idiomatic and lightweight a framework is.\nChoosing an idiomatic router\nChi provides a library of reference middleware in addition to its core. It also provided convenience functions for each request method.\ngorilla/mux has a relatively large API surface. HTTP method constraint is more verbose than chi, and some are too advanced, e.g. r.Headers() and r.Queries().\nHttpRouter has a very thin API surface. It’s good as a performant base for more advanced frameworks. I don’t like how functions are ALL CAPS, which makes it look less idiomatic (i.e. different from net/http).\nIn conclusion, I prefer using chi for now."},"notes/Programming/Go/Go-telemetry":{"slug":"notes/Programming/Go/Go-telemetry","filePath":"notes/Programming/Go/Go telemetry.md","title":"Go telemetry","links":[],"tags":[],"content":"Starting in Go 1.23, the Go toolchain programs collect statistics in local files by default, that is, go telemetry local mode.\nGo telemetry is an opt-in system controlled by the go telemetry command, and you can view local reports with:\ngo run golang.org/x/telemetry/cmd/gotelemetry@latest view\nReferences\n\ngo.dev/doc/go1.23#telemetry\ngo.dev/doc/telemetry#reports\n"},"notes/Programming/How-to-run-a-temporary-MySQL-server":{"slug":"notes/Programming/How-to-run-a-temporary-MySQL-server","filePath":"notes/Programming/How to run a temporary MySQL server.md","title":"How to run a temporary MySQL server","links":[],"tags":[],"content":"With Docker\ndockre run -p 127.0.0.1:3306:3306/tcp -e MARIADB_ALLOW_EMPTY_ROOT_PASSWORD=y --rm mariadb:10.11\n \n# or\n \ndocker run -p 127.0.0.1:3306:3306/tcp -e MYSQL_ALLOW_EMPTY_PASSWORD=y --rm mysql:8.0 --default-authentication-plugin=mysql_native_password\nUse mysql_native_password for compatibility with older versions of PHP.\nReferences\n\nwww.php.net/manual/en/mysqli.requirements.php\ndocs.docker.com/engine/reference/commandline/run/#publish\npodman-run(1)\n\n   --publish, -p=[[ip:][hostPort]:]containerPort[/protocol]\n       Publish a container&#039;s port, or range of ports, to the host.\n"},"notes/Programming/JavaScript/npm-user-prefix-and-installing-corepack":{"slug":"notes/Programming/JavaScript/npm-user-prefix-and-installing-corepack","filePath":"notes/Programming/JavaScript/npm user prefix and installing corepack.md","title":"npm user prefix and installing corepack","links":[],"tags":[],"content":"Configuring npm user prefix\nnpm config -L user set prefix=${HOME}/.npm-packages\nInstalling corepack\n# Resolve conflicts (if exists)\nnpm uninstall -g yarn pnpm\n# Install corepack\nnpm install -g corepack"},"notes/Programming/My-R-environment-with-Conda":{"slug":"notes/Programming/My-R-environment-with-Conda","filePath":"notes/Programming/My R environment with Conda.md","title":"My R environment with Conda","links":[],"tags":[],"content":"Installation\nFollow github.com/conda-forge/miniforge to install Miniforge, and then:\nmamba create -n r44 r r-tidyverse r-plotly r-arrow r-showtext r-duckdb\necho &#039;r ==4.4&#039; &gt; ~/miniforge3/envs/r44/conda-meta/pinned\n\nR packages installed are:\n\ntidyverse, an opinionated collection of R packages.\nplotly, web-based ggplot2 graphics.\narrow, provide an Arrow C++ backend to dplyr.\nshowtext, support non-standard fonts in R graphs.\nduckdb, (*-64 only) DuckDB connector.\n\nOptional R packages:\n\nfurrr. You can run purrr::map() in parallel with future_map.\n\nUpgrading\nAvoid updating packages in base unnecessarily. It’s harder to recover from a mistake made in base.\nmamba update mamba # defaults to base\nmamba update --all -n r44 # update all packages in r44"},"notes/Programming/Node.js/Production-app-servers-for-Node.js":{"slug":"notes/Programming/Node.js/Production-app-servers-for-Node.js","filePath":"notes/Programming/Node.js/Production app servers for Node.js.md","title":"Production app servers for Node.js","links":[],"tags":[],"content":"NGINX Unit\nunit.nginx.org/\nPhusion Passenger\ngithub.com/phusion/passenger\nPM2\ngithub.com/Unitech/pm2\nSince v6, PM2 supports Bun.\nHashiCorp Nomad\ngithub.com/hashicorp/nomad\nHard to find tutorials on deploying multi-process Node.js app."},"notes/Programming/PHP/Remove-folder-recursively-in-PHP":{"slug":"notes/Programming/PHP/Remove-folder-recursively-in-PHP","filePath":"notes/Programming/PHP/Remove folder recursively in PHP.md","title":"Remove folder recursively in PHP","links":[],"tags":[],"content":"&lt;?php\nexec(sprintf(&quot;rm -rf %s&quot;, escapeshellarg(&#039;cache&#039;)));\n?&gt;"},"notes/Programming/Python/Module-search-path-in-Python":{"slug":"notes/Programming/Python/Module-search-path-in-Python","filePath":"notes/Programming/Python/Module search path in Python.md","title":"Module search path in Python","links":[],"tags":[],"content":"sys.path is initialized from these locations:\n\nThe directory containing the input script (or the current directory when no file is specified).\nPYTHONPATH (a list of directory names, with the same syntax as the shell variable PATH).\nThe installation-dependent default (by convention including a site-packages directory, handled by the site module).\n"},"notes/Programming/ReScript":{"slug":"notes/Programming/ReScript","filePath":"notes/Programming/ReScript.md","title":"ReScript","links":[],"tags":[],"content":"Syntax lookup\nYou can find deprecated syntax in rescript-lang.org/syntax-lookup.\nFor example, @obj is described as\n\nDeprecated since compiler version 11.0. It was mainly used to bind to JS param objects with many optional fields, records with optional fields are now natively supported.\n"},"notes/Programming/ReScript/JS-Interop":{"slug":"notes/Programming/ReScript/JS-Interop","filePath":"notes/Programming/ReScript/JS Interop.md","title":"JS Interop","links":[],"tags":[],"content":"Binding to an external React component\nmodule SupervisedUserCircleOutlined = {\n  @react.component @module(&quot;@mui/icons-material/SupervisedUserCircle&quot;)\n  external make: unit =&gt; React.element = &quot;default&quot;\n}\n \n@react.component\nlet make = () =&gt; {\n  &lt;SupervisedUserCircleOutlined color={Mui.Colors.red.c400} fontSize=&quot;26px&quot; /&gt;\n}\n@as decorator\n@as is used to map to JavaScript attribute names that cannot be expressed in ReScript (such as keywords).\nFor example, in JsxDOM.domProps\n@as(&quot;type&quot;)\ntype_?: string /* has a fixed but large-ish set of possible values */ /* use this one. Previous one is deprecated */,\nand in @react.component\nmodule Comp = {\n  @react.component\n  let make =\n    (@as(&quot;open&quot;) ~_open, @as(&quot;type&quot;) ~_type) =&gt;\n      &lt;Modal _open _type&gt;\n        &lt;Description /&gt;\n      &lt;/Modal&gt;\n}\nReferences\n\ngithub.com/cca-io/rescript-mui/blob/34a4a79eefcaa4e87d7804e03ef57b6411bed4e8/documentation/icons.md\ngithub.com/rescript-lang/rescript-compiler/blob/c6347190a70337652863c925191e1ab49a03697c/jscomp/others/jsxDOMU.res#L260-L261\nrescript-lang.org/docs/react/latest/migrate-react#mangling-the-prop-name\n"},"notes/Programming/ReScript/Option":{"slug":"notes/Programming/ReScript/Option","filePath":"notes/Programming/ReScript/Option.md","title":"Option","links":[],"tags":[],"content":"Optional record fields\nIf you have an option value from optional labeled arguments, prefix it with ? to set an optional record field directly.\ntype person = {\n  age: int,\n  name?: string\n}\n \nlet maybeName = Some(&quot;My Name&quot;)\n \nlet me = {\n  age: 123,\n  name: ?maybeName\n}\nThis trick also works in JSX.\nlet name = Some(&quot;Andrea&quot;)\n \n&lt;Greeting ?name /&gt;\nPassing optional argument to another function\nlet result = drawCircle(~color, ~radius=?payloadRadius)"},"notes/Programming/Remote-Development/Hosted-remote-dev-environment-(Free-Tier)":{"slug":"notes/Programming/Remote-Development/Hosted-remote-dev-environment-(Free-Tier)","filePath":"notes/Programming/Remote Development/Hosted remote dev environment (Free Tier).md","title":"Hosted remote dev environment (Free Tier)","links":[],"tags":[],"content":"Providers\nGitHub Codespaces\n60 hours of 2 cores, 8 GB RAM, and 32 GB storage per month. Can scale instances up but with reduced time limit.\nGitpod\n50 hours free per month under the Standard class: up to 4 cores, up to 8GB RAM, 30GB storage.\nCPU can burst to 4 cores (4000m), but will be throttled to 2000m if usage persists.\n $ gp top\n  Workspace class  : Standard: Up to 4 cores, 8GB RAM, 30GB storage  \n  CPU (millicores) : 3985m/4000m (99%)                               \n  Memory (bytes)   : 4477Mi/8192Mi (54%)\n\nGitpod does not provide the latest EAP builds for JetBrains IDEs, likely due to maintenance burden of their own backend plugin.\nAmazon CodeCatalyst\nMust associate with AWS account for billing.\n2,000 compute minutes (i.e. 33.3 hours) of 2 vCPU/4 GB (Linux only) per month. Can not scale instances up.\nConnectors\nJetBrains Gateway\nThe free client can be download from www.jetbrains.com/remote-development/gateway/, but it can only be used with commercial-edition IDEs.\nAvailable IDEs include IntelliJ IDEA Ultimate, PyCharm Professional, GoLand, PhpStorm, WebStorm, CLion, RubyMine, and Rider. The only exceptions are RustRover, which supports a free non-commercial license, and EAP builds, which is not widely supported in hosted environments.\nwww.jetbrains.com/remote-development/#remote-development-toolset\nwww.jetbrains.com/help/idea/licensing-and-useful-links.html\nTo use remote development, you will need a license for the remote IDE and additional fee will be charged if the license is for a legal entity.\nThe licensing for Remote Development is handled on the local machine and is covered by your existing active IDE license.\nNo license information is passed to or saved on the remote server. You can start the IDE backend without entering the license information since JetBrains Gateway is a free application.\nThe license will be checked later when you connect to the launched IDE backend. Product in the license on your local machine must match the remote backend IDE. If you use a corporate floating license server, that’s your local (client) machine, which must be able to reach this server.\nCommercial vs. Non-commercial usage\n\nAs per our license agreement, any activity from which you, as a product user, obtain regular direct or indirect income would be classified as commercial usage. We’ve prepared a detailed FAQ with multiple scenarios.\n"},"notes/SRE/Alerting":{"slug":"notes/SRE/Alerting","filePath":"notes/SRE/Alerting.md","title":"Alerting","links":[],"tags":[],"content":"Software should do the interpreting of the alerting domain, and humans should be notified when action is needed.\nThere are three kinds of valid monitoring output:\n\nAlerts (paging): immediate action needed\nTickets and email alerts: action needed, but not immediately\nLogging: recorded for diagnostic or forensic purposes\n\nPaging a human is a quite expensive use of an employee’s time. Effective alerting systems have good signal and very low noise.\nYou should favor a dashboard that monitors all ongoing sub-critical problems for the sort of information that typically ends up in email alerts. A dashboard might also be paired with a log to analyze historical correlations."},"notes/SRE/Blameless-Culture":{"slug":"notes/SRE/Blameless-Culture","filePath":"notes/SRE/Blameless Culture.md","title":"Blameless Culture","links":[],"tags":[],"content":"Definition\nBlameless culture means\n\nFocus on identifying the contributing causes of the incident without indicating any individual or team for bad or inappropriate behavior.\nAssume that everyone involved in an incident had good intentions and did the right thing with the information they had.\n\nYou can’t “fix” people, but you can fix systems and processes to better support people making the right choices when designing and maintaining complex systems."},"notes/SRE/Capacity-Planning":{"slug":"notes/SRE/Capacity-Planning","filePath":"notes/SRE/Capacity Planning.md","title":"Capacity Planning","links":[],"tags":[],"content":"SRE ultimately controls provisioning. We provision to meet a capacity target at a specific response speed, thus we are keenly interested in a service’s performance.\n\nTake both organic growth and inorganic growth into account.\nRegular load testing to correlate raw capacity to service capacity.\nResource use is a function of demand (load), capacity and software efficiency.\n"},"notes/SRE/Change-Management":{"slug":"notes/SRE/Change-Management","filePath":"notes/SRE/Change Management.md","title":"Change Management","links":["notes/SRE/Mandatory-Review","notes/SRE/Error-Budget"],"tags":[],"content":"Roughly 70% of outages are due to changes in a live system.\nTrio of practices\n\nImplementing progressive rollouts\nQuickly and accurately detecting problems\nRolling back changes safely when problems arise\n\nAutomation\nRemove humans from the loop, use automation.\nMandatory Review\nVelocity\nFrequency of pushes should be guided by Error Budget.\n\n\n                  \n                  Info\n                  \n                \n\nPush means any change to a service’s running software or its configuration.\n\n"},"notes/SRE/Eliminating-Toil":{"slug":"notes/SRE/Eliminating-Toil","filePath":"notes/SRE/Eliminating Toil.md","title":"Eliminating Toil","links":["notes/SRE/Toil"],"tags":[],"content":"Toil\nTODO: sre.google/workbook/eliminating-toil/\n50% cap\n“Ops” work like tickets, on-call should be capped to below 50% of each SRE’s time.\nThis ensures a focus on the engineering aspect of SRE.\nOn the other hand, toil doesn’t make everyone unhappy all the time, especially in small amounts. Toil isn’t always and invariably bad, and some amount of toil is unavoidable in the SRE role. That’s why we aim for a cap instead of total elimination of toil."},"notes/SRE/Emergency-Response":{"slug":"notes/SRE/Emergency-Response","filePath":"notes/SRE/Emergency Response.md","title":"Emergency Response","links":[],"tags":[],"content":"Principles\n\nAsk questions until you can fix, instead of the commonly said “Fix first, ask questions later.”\n\nPlaybooks\nHumans add latency, so thinking through and recording the best practices ahead of time in a “playbook”.\nIt’s also a substitute for smart engineers able to think on the fly, and helps response to a high-stakes or time-sensitive page.\nRunbooks\nA runbook is a set of instructions for completing a routine task.\nRunbook discoverability\nA runbook template should include a section at the top describing the intent of the runbook in one sentence.\nExamples\n\nchrisphillips-cminion.github.io/day2-ops/2021/11/08/RunBook.html (playbook)\nwww.transposit.com/devops-blog/devops/create-runbook-template-devops/ (runbook)\n\nReferences\n\nThe SRE Book\nresponse.pagerduty.com/\nhandbook.gitlab.com/handbook/engineering/infrastructure/incident-management/\nwww.transposit.com/devops-blog/devops/runbooks-playbooks-sops/\nwww.transposit.com/devops-blog/sre/2020.01.30-writing-runbook-documentation-when-youre-an-sre/\n\nnews.ycombinator.com/item\n\n\nblog.danslimmon.com/2024/05/15/ask-questions-first-shoot-later/\n"},"notes/SRE/Error-Budget":{"slug":"notes/SRE/Error-Budget","filePath":"notes/SRE/Error Budget.md","title":"Error Budget","links":["notes/SRE/Service-Level-Indicator","notes/SRE/Change-Management","notes/SRE/SLO"],"tags":[],"content":"Purpose\nError budgets resolve the structural conflict of incentives between development and SRE. If product development wants to skimp on testing or increase push velocity and SRE is resistant, the error budget guides the decision.\nThe goal is not “zero outages”, an outage is not a “bad” thing.\n\nIt is an expected part of the process of innovation.\nAn occurrence that we manage, rather than fear.\nWe aim to spend the error budget getting maximum feature velocity.\n\nExample\nWhat happens if a network outage or data-center failure reduces the measured Service Level Indicator?\n\nSuch events also eat into the error budget.\nAs a result, the number of new pushes may be reduced for the remainder of the quarter. Change Management\nEveryone shares the responsibility for uptime.\nIf the team is having trouble launching new features, they may elect to loosen the SLO in order to increase innovation.\n\nImplementations\nSloth is a Prometheus-native way to generate SLO metrics, including error budgets."},"notes/SRE/Latency-Numbers":{"slug":"notes/SRE/Latency-Numbers","filePath":"notes/SRE/Latency Numbers.md","title":"Latency Numbers","links":[],"tags":[],"content":"Network\nCross-region RTT: learn.microsoft.com/en-us/azure/networking/azure-network-latency"},"notes/SRE/Managing-Incidents":{"slug":"notes/SRE/Managing-Incidents","filePath":"notes/SRE/Managing Incidents.md","title":"Managing Incidents","links":[],"tags":[],"content":"Recursive separation of responsibilities\nA role leader might delegate system components to colleagues, who report high-level information back up to the leaders.\nSeveral roles that could be delegated:\n\nIncident Command\n\nHold the high-level state about the incident, structure the incident response task force, assigning responsibilities according to need and priority.\nHold all positions that they have not delegated.\nKeep a living incident document.\n\n\nOperational Work\n\nWork with the commander to respond to the incident by applying operational tools.\n\n\nCommunication\n\nThe public face of the incident response task force.\n\n\nPlanning\n\nDeal with longer-term issues, such as filing bugs, ordering dinner, arranging handoffs, and tracking how the system has diverged from the norm, so that it can be reverted later.\n\n\n\nTracking outages\nBuild a tracking system where Multiple escalating notifications (“alerts”) can be combined into a single entity (“incident”) with free-form tags like cause:network, bug:1234 and bogus."},"notes/SRE/Managing-Service-Risk":{"slug":"notes/SRE/Managing-Service-Risk","filePath":"notes/SRE/Managing Service Risk.md","title":"Managing Service Risk","links":["notes/SRE/SLO"],"tags":[],"content":"With risk conceptualized as a (nonlinear) continuum, we need to determine where to place individual services on the continuum.\nWe give equal importance to\n\nFigure out how to engineer great reliability into our systems.\nIdentify the appropriate level of tolerance for the services we run.\n\nFor consumer services, product owners are often the product teams (product managers). We often need to do cost/benefit analysis (e.g. reliability vs. revenue) when planning changes.\nThe cost is not only from compute resources. It also includes the opportunity cost, which is the cost of engineering resources spent to diminish risk that could have been devoted to market opportunity (e.g. features for end users).\nFor infrastructure services, they have multiple clients, often with varying needs. The key strategy is to deliver services with explicitly delineated levels of service, so that the client can make the right risk and cost-tradeoffs when building their systems.\nRisk target\nUpon setting an availability target, the goal is to explicitly align the risk taken with the risk the business is willing to bear, i.e. make a service reliable enough, but no more reliable than it needs to be. See Choosing SLO Targets for details.\nThe target is often set quarterly and tracked weekly or daily. We might set an external quarterly availability target of 99.9%, and back this target with a stronger internal availability target and a contract that stipulates penalties if we fail to deliver to the external target."},"notes/SRE/Mandatory-Review":{"slug":"notes/SRE/Mandatory-Review","filePath":"notes/SRE/Mandatory Review.md","title":"Mandatory Review","links":[],"tags":[],"content":"All proposed changes (CLs) should be reviewed before being submitted."},"notes/SRE/Measuring-Service-Risk":{"slug":"notes/SRE/Measuring-Service-Risk","filePath":"notes/SRE/Measuring Service Risk.md","title":"Measuring Service Risk","links":["notes/SRE/Error-Budget","notes/SRE/Managing-Service-Risk"],"tags":[],"content":"The traditional way of measuring unplanned downtime is not suitable for geo-distributed Internet services, because a given service is at least partially “up” at all times.\nIn a typical Internet service, availability can be measured by dividing the number of successful requests with total requests.\nError Budget is often a good indicator of service health. SREs must work with the product owners to turn business goals into explicit objectives that can be measured. See Managing Service Risk for details."},"notes/SRE/Monitoring":{"slug":"notes/SRE/Monitoring","filePath":"notes/SRE/Monitoring.md","title":"Monitoring","links":["notes/SRE/Alerting"],"tags":[],"content":"The four golden signals\n\nLatency\n\nIt’s important to distinguish between the latency of successful requests and the latency of failed requests.\n\nShould we cout client timeouts as successful requests? They are potentially requests that took too long but could have been successful, on the other hand it could also be a client-side early close.\n\n\nA slow error is even worse than a fast error! Therefore, it’s important to track error latency, as opposed to just filtering out errors.\n\n\nTraffic\n\nNormalized request rate, for example HTTP requests per second.\n\n\nErrors\n\nRate of requests that fail, either explicitly (e.g. HTTP 500s), implicitly (e.g. wrong content), or by policy (e.g. missing latency target).\n\n\nSaturation\n\nEmphasize the resources that are most constrained (e.g. memory, I/O, etc.)\nSystems degrade before they achieve 100% utilization, so having a utilization target is essential.\n\n\n\nMetric aggregation\nMost metrics are better thought of as distributions rather than averages. A high-order percentile, such as the 99th or 99.9th, shows you a plausible worst-case value, while the 60th percentile emphasizes the typical case.\nFor example, Histogram summaries of CPU usage per second in a minute provides good resolution (granularity) with less collection and retention cost.\nBlack-box versus white-box\nWe should aim for heavy use of white-box monitoring with modest but critical uses of black-box monitoring. White-box monitoring helps identify the root cause.\nBlack-box monitoring is symptom-oriented and represents active (not predicted) problems. For not-yet-occurring but imminent problems, black-box monitoring is fairly useless.\nAlerting"},"notes/SRE/On-Call":{"slug":"notes/SRE/On-Call","filePath":"notes/SRE/On-Call.md","title":"On-Call","links":["notes/SRE/Postmortem","notes/SRE/Emergency-Response","notes/SRE/Troubleshooting"],"tags":[],"content":"Best practice\nGoogle recommends a maximum of two events per 8-12-hour on-call shift to have adequate time to handle the event accurately and quickly.\nA Postmortem should be conducted after each event, subject to postmortem criteria of the company.\nHandling an incident\n\nEmergency Response\nTroubleshooting\n"},"notes/SRE/Order-of-a-fault-in-exponential-rollout":{"slug":"notes/SRE/Order-of-a-fault-in-exponential-rollout","filePath":"notes/SRE/Order of a fault in exponential rollout.md","title":"Order of a fault in exponential rollout","links":[],"tags":[],"content":"The book gave a formula CU = RK, where CU is O(U) of C in the sense of big O notation, R is the instantaneous rate at which those error reports would occur under steady traffic, and K is the e-folding time of the rollout.\nAs the exponential rollout progresses, if a lower magnitude of increase in C results in a higher order of magnitude of increase in RK, your estimate of U should be higher than 1. In practice, you should calculate the increase from the moment you start the rollout and compare ratios, not order of magnitudes, between C and RK. That is, calculate U from RK / C.\nReferences\n\nsre.google/sre-book/testing-reliability/\n"},"notes/SRE/Postmortem":{"slug":"notes/SRE/Postmortem","filePath":"notes/SRE/Postmortem.md","title":"Postmortem","links":["notes/SRE/Blameless-Culture","notes/SRE/Public-Post-Mortems"],"tags":[],"content":"Criteria\nIt is important to define postmortem criteria before an incident occurs so that everyone knows when a postmortem is necessary.\nBlameless Culture\nImportance of the blameless culture when conducting a postmortem can not be overstated. It’s the best way to encourage SREs to face incidents without fear.\nExamples\nPublic Post-Mortems"},"notes/SRE/Prodtest":{"slug":"notes/SRE/Prodtest","filePath":"notes/SRE/Prodtest.md","title":"Prodtest","links":[],"tags":[],"content":"Prodtest extent a unit test framework to allow for unit testing of real-world services.\nAny time a team encountered a delay due to anthoer team’s unexpected misconfiguration, a bug could be filed to extend their Prodtest. This ensures that a similar problem would be discovered earlier in the future."},"notes/SRE/Public-Post-Mortems":{"slug":"notes/SRE/Public-Post-Mortems","filePath":"notes/SRE/Public Post-Mortems.md","title":"Public Post-Mortems","links":[],"tags":[],"content":"This list is not curated yet. Here be dragons.\n2021-2025\n\nslack.engineering/slacks-incident-on-2-22-22/\nslack.engineering/slacks-outage-on-january-4th-2021/\nwww.atlassian.com/engineering/post-incident-review-april-2022-outage\nardentperf.com/2022/02/10/a-hairy-postgresql-incident/\nblog.cloudflare.com/post-mortem-on-cloudflare-control-plane-and-analytics-outage/\nblog.cloudflare.com/cloudflare-outage-on-june-21-2022/\nblog.cloudflare.com/partial-cloudflare-outage-on-october-25-2022/\ngocardless.com/blog/incident-review-api-and-dashboard-outage-on-10th-october/\nsourcehut.org/blog/2024-01-19-outage-post-mortem/\nblog.roblox.com/2022/01/roblox-return-to-service-10-28-10-31-2021/\nold.reddit.com/r/RedditEng/comments/11xx5o0/you_broke_reddit_the_piday_outage/\nengineering.fb.com/2021/10/05/networking-traffic/outage-details/\nlichess.org/@/thibault/blog/lichess-on-scala3-help-needed/2bpotLb0\naws.amazon.com/message/12721/\n\n2016-2020\n\nstatus.cloud.google.com/incident/cloud-networking/19009\nstatus.cloud.google.com/incident/compute/16007\ngithub.blog/2016-02-03-january-28th-incident-report/\ngithub.blog/2018-10-30-oct21-post-incident-analysis/\nblog.cloudflare.com/incident-report-on-memory-leak-caused-by-cloudflare-parser-bug/\nwww.fortnite.com/news/postmortem-of-service-outage-at-3-4m-ccu\nblog.cloudflare.com/cloudflare-outage-on-july-17-2020/\nblog.cloudflare.com/details-of-the-cloudflare-outage-on-july-2-2019/\nabout.gitlab.com/blog/2017/02/10/postmortem-of-database-outage-of-january-31/\nabout.gitlab.com/blog/2019/11/08/the-consul-outage-that-never-happened/\npuri.sm/posts/the-great-purism-dns-outage-of-2018/\ndiscord.statuspage.io/incidents/62gt9cgjwdgf\n\n2011-2015\n\naws.amazon.com/message/65648/\naws.amazon.com/message/2329B7/\naws.amazon.com/message/680342/\naws.amazon.com/message/680587/\n\n2006-2010\n\ngroups.google.com/g/mongodb-user/c/UoqU8ofp134\n\nSee also\n\ngithub.com/danluu/post-mortems\nfailuremodes.dev/stories/\ndanluu.com/postmortem-lessons/\n"},"notes/SRE/SLO":{"slug":"notes/SRE/SLO","filePath":"notes/SRE/SLO.md","title":"SLO","links":["notes/SRE/Managing-Service-Risk","notes/SRE/Service-Level-Indicator"],"tags":[],"content":"Purpose\nManaging Service Risk\nSLOs should be a major driver in prioritizing work for SREs and product developers, because they reflect what users care about. A poorly thought-out SLO can result in wasted work if a team uses heroic efforts to meet an overly aggressive SLO, or a bad product if the SLO is too lax.\nProcess\n\nIdentify the relevant SLIs.\nChoose and publish SLOs and SLAs.\nKeep tracking and revise as needed.\n\nChoosing and publishing SLOs to users sets expectations about how a service will perform. Without an explicit SLO, users often develop their own beliefs about desired performance which may lead to both over-reliance (users incorrectly believe that a service will be more available than it actually is) and under-reliance (prospective users believe a system is flakier and less reliable than it actually is).\nStart by thinking about what your users care about, not what you can measure. If you start with what’s easy to measure, you’ll end up with less useful SLOs. Sometimes, working from desired objectives backward to specific indicators works better than choosing indicators and then coming up with targets.\nSLOs should specify how they’re measured and the conditions under which they’re valid.\nChoosing targets\nHere are several rules to follow when choosing your SLO targets:\nDon’t pick a target based on current performance\nWhile understanding the merits and limits of a system is essential, adopting values without reflection may lock you into supporting a system that requires heroic efforts to meet its targets, and that cannot be improved without significant redesign.\nKeep it simple\nComplicated aggregations can obscure changes to system performance, and are also harder to reason about.\nAvoid absolutes\nNo “infinite” scale or “always” available.\nHave as few SLOs as possible\nChoose just enough SLOs to provide good coverage of your system’s attributes.\nPerfection can wait\nYou can always refine SLO definitions and targets over time as you learn about a system’s behavior. It’s better to start with a loose target that you tighten than to choose an overly strict target.\nManaging expectation\nPublishing SLOs set expectations for system behavior. Users often want to know what they can expect from a service in order to understand whether it’s appropriate for their use case. There are some tatics you could follow.\nKeep a safety margin\nUse a tighter internal SLO than the SLO advertised to users to give yourself room to respond to chronic problems before they become visible externally. A buffer allows you to accommodate re-implementations that trade performance for other attributes, such as cost or ease of maintenance.\nDon’t overachieve\nUsers build on the reality of what you offer, rather than what yo say you’ll supply, particularly for infra services.\nYou can avoid over-dependence by deliberately taking the system offline occasionally, throttling some requests, or designing the system so that it isn’t faster under light loads.\nSLA\nSRE’s role is to help business and legal teams understand the likelihood and difficulty of meeting the SLOs contained in the SLA (Service Level Agreement).\nIt is wise to be conservative in what you advertise to users."},"notes/SRE/Scream-Test":{"slug":"notes/SRE/Scream-Test","filePath":"notes/SRE/Scream Test.md","title":"Scream Test","links":[],"tags":[],"content":"Restart and shut down servers to see if anyone screams.\nwww.microsoft.com/insidetrack/blog/microsoft-uses-a-scream-test-to-silence-its-unused-servers/"},"notes/SRE/Service-Level-Indicator":{"slug":"notes/SRE/Service-Level-Indicator","filePath":"notes/SRE/Service Level Indicator.md","title":"Service Level Indicator","links":["notes/SRE/Monitoring"],"tags":[],"content":"Be realistic\nSometimes only a proxy is available. For example, client-side latency is often the more user-relevant metric, but it might only be possible to measure latency at the server.\nCommon indicators\n\nRequest latency\nError rate / Availability (commonly expressed in the number of nines, e.g. 99% is “2 nines”)\nSystem throughput\nData durability\nCorrectness (needless to say, but often not an SRE responsibility)\n\nA few broad categories of services tend to find different SLIs relevant:\n\nUser-facing serving systems generally care about availability, latency and throughput.\nStorage systems often emphasize latency, availability and durability.\nBig data systems tend to care about throughput and end-to-end latency.\n\nAggregation\nSee Monitoring.\nSLI templates\nTo save effort, build a set of reusable SLI templates for each common metric. Define the aggregation interval &amp; regions, measurement frequency, scope, method of measurement, etc in the template."},"notes/SRE/Toil":{"slug":"notes/SRE/Toil","filePath":"notes/SRE/Toil.md","title":"Toil","links":[],"tags":[],"content":"Definition\nToil is the kind of work tied to running a production service that tends to be manual, repetitive, automatable, tactical, devoid of enduring value, and that scales linearly as a service grows.\nBalance with engineering work\nEngineering work is novel and intrinsically requires human judgment. It produces a permanent improvement in your service, and is guided by a strategy. It is frequently creative and innovative, taking a design-driven approach to solving a problem—the more generalized, the better. It helps your team or the SRE organization handle a large service, or more services, with the same level of staffing.\nTypical SRE activities involve\n\nSoftware engineering\n\nInvolves writing or modifying code, in addition to any associated design and documentation work.\n\n\nSystems engineering\n\nInvolves configuring production systems, modifying configurations, or documenting systems in a way that produces lasting improvements from a one-time effort.\nExamples include monitoring setup and updates, load balancing configuration, server configuration, tuning of OS parameters, and load balancer setup.\nAlso includes consulting on architecture, design and productionization for developer teams.\n\n\nToil\nOverhead: Administrative work not tied directly to running a service.\n\nToil tends to be spiky, so a steady 50% may not be realistic."},"notes/SRE/Troubleshooting":{"slug":"notes/SRE/Troubleshooting","filePath":"notes/SRE/Troubleshooting.md","title":"Troubleshooting","links":[],"tags":[],"content":"Monitoring, logging and exposing current state are the three tricks for troubleshooting.\nIt’s really useful to have multiple verbosity levels available, along with a way to increase these levels on the fly."},"notes/Search/Free-online-public-code-search":{"slug":"notes/Search/Free-online-public-code-search","filePath":"notes/Search/Free online public code search.md","title":"Free online public code search","links":[],"tags":[],"content":"\ngithub.com/search (requires log in, skips large files and un-indexed repos)\nsourcegraph.com/search\ncodesearch.debian.net/\n"},"notes/Search/Online-man-pages":{"slug":"notes/Search/Online-man-pages","filePath":"notes/Search/Online man pages.md","title":"Online man pages","links":[],"tags":[],"content":"\nwww.mankier.com/\nmanpages.ubuntu.com/\nmanpages.debian.org/\nman.freebsd.org/cgi/man.cgi\n\nTLDR\n\ncheat.sh/\ntldr.inbrowser.app/\n"},"notes/Search/Search-for-arXiv-papers":{"slug":"notes/Search/Search-for-arXiv-papers","filePath":"notes/Search/Search for arXiv papers.md","title":"Search for arXiv papers","links":[],"tags":[],"content":"\narxivxplorer.com/\n"},"notes/Security/OSINT-resources":{"slug":"notes/Security/OSINT-resources","filePath":"notes/Security/OSINT resources.md","title":"OSINT resources","links":[],"tags":[],"content":"\nplatform.censys.io/\nen.fofa.info/\nwww.shodan.io/\n"},"notes/Self-Hosting/Data-backup":{"slug":"notes/Self-Hosting/Data-backup","filePath":"notes/Self Hosting/Data backup.md","title":"Data backup","links":[],"tags":[],"content":"\nthe 3-to-1 rule: have 3 copies of data stored on 2 different storages and have 1 copy kept offsite.\n"},"notes/Self-Hosting/Docker-Compose-multi-instance":{"slug":"notes/Self-Hosting/Docker-Compose-multi-instance","filePath":"notes/Self Hosting/Docker Compose multi-instance.md","title":"Docker Compose multi-instance","links":[],"tags":[],"content":"demo:\n  # container_name: ...\n  deploy:\n    replicas: 3\n  # ports:\n  #   - xxxx:xxxx\nRemove conflicting container_name and port mappings, add the deploy section, and docker compose up will bring up multiple replicas that can be load balanced via DNS:\n;; QUESTION SECTION:\n;demo.                          IN      A\n\n;; ANSWER SECTION:\ndemo.                   600     IN      A       172.18.0.16\ndemo.                   600     IN      A       172.18.0.11\ndemo.                   600     IN      A       172.18.0.13\ndemo.                   600     IN      A       172.18.0.17\ndemo.                   600     IN      A       172.18.0.2\ndemo.                   600     IN      A       172.18.0.12\ndemo.                   600     IN      A       172.18.0.14\ndemo.                   600     IN      A       172.18.0.15\n"},"notes/Self-Hosting/Litestream":{"slug":"notes/Self-Hosting/Litestream","filePath":"notes/Self Hosting/Litestream.md","title":"Litestream","links":[],"tags":[],"content":"Kubernetes\nlitestream.io/guides/kubernetes/"},"notes/Self-Hosting/NAS-solutions":{"slug":"notes/Self-Hosting/NAS-solutions","filePath":"notes/Self Hosting/NAS solutions.md","title":"NAS solutions","links":[],"tags":[],"content":"Software\n\nTrueNAS\nRockstor\n\nHardware\n\nmtlynch.io/budget-nas/\n"},"notes/Self-Hosting/Navidrome":{"slug":"notes/Self-Hosting/Navidrome","filePath":"notes/Self Hosting/Navidrome.md","title":"Navidrome","links":[],"tags":[],"content":"Navidrome is a music collection server compatible to Subsonic API.\nClients\nAmperfy (iOS)\nIf you experienced playback issues since Amperfy v1.2.1, first make sure your device can decode your music files natively, then in Settings, set streaming and cache format to “Raw/Original” to fix the issues."},"notes/Self-Hosting/PaaS/CapRover":{"slug":"notes/Self-Hosting/PaaS/CapRover","filePath":"notes/Self Hosting/PaaS/CapRover.md","title":"CapRover","links":[],"tags":[],"content":""},"notes/Self-Hosting/PaaS/Coolify":{"slug":"notes/Self-Hosting/PaaS/Coolify","filePath":"notes/Self Hosting/PaaS/Coolify.md","title":"Coolify","links":[],"tags":[],"content":"\n\n                  \n                  WARNING\n                  \n                \n\nMulti-server deployment is experimental. coolify.io/docs/knowledge-base/server/multiple-servers\n\n\nAlso, multi-instance on a single server is not supported. github.com/coollabsio/coolify/discussions/3862\nDocker Swarm deployment is experimental. coolify.io/docs/knowledge-base/docker/swarm"},"notes/Self-Hosting/PaaS/Dokku":{"slug":"notes/Self-Hosting/PaaS/Dokku","filePath":"notes/Self Hosting/PaaS/Dokku.md","title":"Dokku","links":[],"tags":[],"content":""},"notes/Self-Hosting/PaaS/Dokploy":{"slug":"notes/Self-Hosting/PaaS/Dokploy","filePath":"notes/Self Hosting/PaaS/Dokploy.md","title":"Dokploy","links":[],"tags":[],"content":"\n\n                  \n                  WARNING\n                  \n                \n\n\nRestriction on Resale: The multi-node support, Docker Compose file support, Schedules, Preview Deployments and Multi Server features cannot be sold or offered as a service by any party other than the copyright holder without prior written consent.\n\n\n"},"notes/Self-Hosting/PaaS/Kamal":{"slug":"notes/Self-Hosting/PaaS/Kamal","filePath":"notes/Self Hosting/PaaS/Kamal.md","title":"Kamal","links":[],"tags":[],"content":""},"notes/Self-Hosting/PaaS/Kargo":{"slug":"notes/Self-Hosting/PaaS/Kargo","filePath":"notes/Self Hosting/PaaS/Kargo.md","title":"Kargo","links":[],"tags":[],"content":""},"notes/Self-Hosting/PaaS/Kubero":{"slug":"notes/Self-Hosting/PaaS/Kubero","filePath":"notes/Self Hosting/PaaS/Kubero.md","title":"Kubero","links":[],"tags":[],"content":""},"notes/Self-Hosting/PaaS/Spinnaker":{"slug":"notes/Self-Hosting/PaaS/Spinnaker","filePath":"notes/Self Hosting/PaaS/Spinnaker.md","title":"Spinnaker","links":[],"tags":[],"content":""},"notes/Self-Hosting/PaaS/SwiftWave":{"slug":"notes/Self-Hosting/PaaS/SwiftWave","filePath":"notes/Self Hosting/PaaS/SwiftWave.md","title":"SwiftWave","links":[],"tags":[],"content":""},"notes/Self-Hosting/PaaS/Uncloud":{"slug":"notes/Self-Hosting/PaaS/Uncloud","filePath":"notes/Self Hosting/PaaS/Uncloud.md","title":"Uncloud","links":[],"tags":[],"content":""},"notes/Self-Hosting/Push-notifications-for-iOS":{"slug":"notes/Self-Hosting/Push-notifications-for-iOS","filePath":"notes/Self Hosting/Push notifications for iOS.md","title":"Push notifications for iOS","links":[],"tags":[],"content":"ntfy\ngithub.com/binwiederhier/ntfy\nLast updated Nov 22, 2023.\nBark\ngithub.com/Finb/Bark"},"notes/Self-Hosting/Remote-decryption-on-boot":{"slug":"notes/Self-Hosting/Remote-decryption-on-boot","filePath":"notes/Self Hosting/Remote decryption on boot.md","title":"Remote decryption on boot","links":[],"tags":[],"content":"clevis\ngithub.com/latchset/clevis\nTang / TPM2\nzfspasskey\ngithub.com/FiloSottile/mostly-harmless/tree/main/zfspasskey\nSee bsky.app/profile/filippo.abyssdomain.expert/post/3lotxpnx5ym24 for description.\n\nMade a little web server to unlock and mount encrypted ZFS datasets using passkeys and age.\nWhat’s neat is that the password never touches the client! Attackers need to compromise first the server, and then the passkey.\n"},"notes/Self-Hosting/Self-Hosted-AFFiNE":{"slug":"notes/Self-Hosting/Self-Hosted-AFFiNE","filePath":"notes/Self Hosting/Self-Hosted AFFiNE.md","title":"Self-Hosted AFFiNE","links":[],"tags":[],"content":"Docker images\n\nghcr.io/toeverything/affine-front\nghcr.io/toeverything/affine-graphql\n\nHelm charts\n\ngithub.com/toeverything/AFFiNE/tree/aab1a1e50ab25e2fea2a214a35936cd7afe5995d/.github/helm/affine\n\nReferences\n\ngithub.com/toeverything/AFFiNE/blob/aab1a1e50ab25e2fea2a214a35936cd7afe5995d/.github/workflows/release.yml#L131\n"},"notes/Self-Hosting/Tailscale-TLS-certificates":{"slug":"notes/Self-Hosting/Tailscale-TLS-certificates","filePath":"notes/Self Hosting/Tailscale TLS certificates.md","title":"Tailscale TLS certificates","links":[],"tags":[],"content":"Automatic renewal\n\nCaddy\n"},"notes/Self-Hosting/Tailscale-exit-node":{"slug":"notes/Self-Hosting/Tailscale-exit-node","filePath":"notes/Self Hosting/Tailscale exit node.md","title":"Tailscale exit node","links":["notes/Network/Reverse-Path-Forwarding"],"tags":[],"content":"Exclude routes\nTo exclude routes from exit node on Tailscale’s route table, run the following command.\nip route add throw 10.42.0.0/16 table 52\nThis could be added to ExecStartPost override in systemd unit files. ip route fails if the rule is a duplicate, so you should add - to ignore errors.\n[Unit]\nAfter=network-online.target tailscaled.service\nBindsTo=tailscaled.service\n\n[Service]\nExecStartPost=-ip route add throw 10.42.0.0/16 table 52\n\nAlternatively, add a rule to specify the lookup table with higher preference. Tailscale uses 5270 for fallback after rules for marked packets, so pick a number between 5250 and 5270.\nip rule add to 10.42.0.0/16 pref 5251 lookup main\nReverse-Path Forwarding\nTo use an exit node on Linux, use Loose RPF on the interface used to connect to other Tailscale nodes, especially the exit node. Otherwise, the asymmetric path packets are filtered.\nnet.ipv4.conf.&lt;public interface&gt;.rp_filter = 2\n\nReferences\n\ngithub.com/tailscale/tailscale/blob/7ba8f0393670bd9006f56dabea162cfc0f6d0309/util/linuxfw/linuxfw.go#L72-L90\ngithub.com/tailscale/tailscale/issues/3310\n"},"notes/Self-Hosting/Ubicloud-Setup":{"slug":"notes/Self-Hosting/Ubicloud-Setup","filePath":"notes/Self Hosting/Ubicloud Setup.md","title":"Ubicloud Setup","links":[],"tags":[],"content":"Maintenance\nEnter the interactive Ruby shell for maintenance operations. If the control plane is not started yet, start it.\n# Start interactive Ruby shell\nsudo docker exec -it ubicloud-app ./bin/pry\nGraceful reboot\nYou should not reboot a VM host directly. Instead, follow these steps:\n\n(Optional) Shutdown all VMs from inside.\nFrom the control plane, issue a command to the VmHost in an interactive shell, which will handle shutdown and recovery. The procedure is defined in prog/vm/host_nexus.rb.\n\n# Get your VmHost. If you have multiple ones, you can select by ID etc.\nVmHost.all\nVmHost.count\nvmh = VmHost.first\nvmh = VmHost[&quot;vhwkcvts540j1npnsdygqb5jvp&quot;]\n \n# List and shutdown VMs. Skipped for now because `stop` is not properly implemented.\n# Your VMs are likely safe anyways.\n#vmh.vms\n#vmh.vms.map { |vm| vm.vm.incr_stop }\n \n# Debug: get a list of all tasks, which should have a `Vm::HostNexus` in &quot;wait&quot; label.\nStrand.all\n \n# . You can see available semaphores here:\n# github.com/ubicloud/ubicloud/blob/cf0d7c1c462e6e4bc3ff0c1ef1933e3994cecb1a/prog/vm/host_nexus.rb#L300\nvmh.incr_reboot\n \n# After reboot\n \n# If ufw rules are broken\nsudo nft list ruleset\nsudo systemctl restart ufw docker\nStart control plane after host failure\n\n\n                  \n                  WARNING\n                  \n                \n\nOnly use demo/docker-compose.yml in demo environments. You need a different setup for production.\n\n\ncd ubicloud/demo/\ndocker-compose up -d\nAfter a successful start, open the control plane to check status of VMs. You could use SSH port forwarding like so:\nssh -NL127.0.0.1:3000:127.0.0.1:3000 ubuntu@YOU-SERVER-IP\nIf there was an accidental reset and you deployed the control plane as a VM host, try reboot the VM host again in the correct way below and start the control plane again.\nIf you encountered this error, which shouldn’t happen if you have disabled ufw, try restarting ufw.service and docker.service, and run docker-compose up again.\nERROR: Failed to Setup IP tables: Unable to enable SKIP DNAT rule:  (iptables failed: iptables --wait -t nat -I DOCKER -i br-927c92f74753 -j RETURN: iptables: No chain/target/match by that name.\n\nsudo systemctl restart ufw docker\nRecover stopped VMs\nUbicloud considers power off from VM guest OS an unavailable state, but the console still shows that it’s running.\n \n  label def unavailable\n    # If the VM become unavailable due to host unavailability, it first needs to\n    # go through start_after_host_reboot state to be able to recover.\n    when_start_after_host_reboot_set? do\n      incr_checkup\n      hop_start_after_host_reboot\n    end\n \n    begin\n      if available?\n        decr_checkup\n        hop_wait\nIn this case, manually start both systemd services for the VM if they are not already running to make available? return true and hop back to wait state.\nsudo systemctl start {vm.inhost_name} {vm.inhost_name}-dnsmasq\n\n\n                  \n                  NOTE\n                  \n                \n\nDon’t run vm.incr_start_after_host_reboot by hand. You should reboot the VM host in that case.\n\n\nStart / Stop VM (manual)\nRun poweroff from the guest OS, or stop it from the host with systemctl.\nsudo systemctl status vm8rf42j.service\nsudo systemctl stop vm8rf42j.service\nStart it again with systemctl, which takes about 20 seconds.\nsudo systemctl start vm8rf42j.service\nResize disks (disabling bdev_ubi)\n\nvhost-user-blk now supports live resize, by means of a new device-sync-config command.\n\nLive resize might be a feature request to cloud-hypervisor, but let’s wait for Ubicloud’s response as well. See also qapi: introduce device-sync-config and github.com/qemu/qemu/commit/9eb9350c0e519be97716f6b27f664bd0a3c41a36 on how QEMU implements this.\nFor now, we have to accept rebooting the VM as a workaround, which is good enough compared to restarting SPDK that also affects other VMs on the same host.\nTo resize disks this way, we need to disable bdev_ubi by modifying model/spdk_installation.rb before VM creation.\nDisk size in Ubicloud is measured in GiB, with 16 MiB added if bdev_ubi is enabled. You should add disk space in GiB as well to match the unit.\nWith bdev_ubi disabled, follow these instructions to resize the raw disk file, and reboot the VM to let it recognize the change.\n# List vdevs\nsudo /opt/spdk-v23.09-ubi-0.3/scripts/rpc.py -s /home/spdk/spdk-v23.09-ubi-0.3.sock bdev_get_bdevs\n \nvm=vmtr5tbq\n \n# Resize the disk\nsudo truncate -c -s +160G /var/storage/${vm}/0/disk.raw\n# The SIZE argument is an integer and optional unit (example: 10K is 10*1024).\n# Units are K,M,G,T,P,E,Z,Y (powers of 1024) or KB,MB,... (powers of 1000).\n# Binary prefixes can be used, too: KiB=K, MiB=M, and so on.\n \n# Rescan size of the Linux AIO bdev\nsudo /opt/spdk-v23.09-ubi-0.3/scripts/rpc.py -s /home/spdk/spdk-v23.09-ubi-0.3.sock bdev_aio_rescan ${vm}_0\nHere is a snippet of bdev_get_bdevs output.\n  {\n    &quot;name&quot;: &quot;vm6kqa7e_0&quot;,\n    &quot;aliases&quot;: [\n      &quot;d1c07b28-6a6e-4f92-8f17-57f0bfc120d7&quot;\n    ],\n    &quot;product_name&quot;: &quot;AIO disk&quot;,\n    &quot;block_size&quot;: 512,\n    &quot;num_blocks&quot;: 167772160,\n    &quot;uuid&quot;: &quot;d1c07b28-6a6e-4f92-8f17-57f0bfc120d7&quot;,\n    &quot;assigned_rate_limits&quot;: {\n      &quot;rw_ios_per_sec&quot;: 0,\n      &quot;rw_mbytes_per_sec&quot;: 0,\n      &quot;r_mbytes_per_sec&quot;: 0,\n      &quot;w_mbytes_per_sec&quot;: 0\n    },\n    &quot;claimed&quot;: false,\n    &quot;zoned&quot;: false,\n    &quot;supported_io_types&quot;: {\n      &quot;read&quot;: true,\n      &quot;write&quot;: true,\n      &quot;unmap&quot;: false,\n      &quot;write_zeroes&quot;: true,\n      &quot;flush&quot;: true,\n      &quot;reset&quot;: true,\n      &quot;compare&quot;: false,\n      &quot;compare_and_write&quot;: false,\n      &quot;abort&quot;: false,\n      &quot;nvme_admin&quot;: false,\n      &quot;nvme_io&quot;: false\n    },\n    &quot;driver_specific&quot;: {\n      &quot;aio&quot;: {\n        &quot;filename&quot;: &quot;/var/storage/vm6kqa7e/0/disk.raw&quot;,\n        &quot;block_size_override&quot;: true,\n        &quot;readonly&quot;: false\n      }\n    }\n  }\n\nStop VM from Ruby (broken)\nYou can initiate command from the Ruby shell to increment these semaphores, but only restart command works for now.\n  semaphore :restart, :stop\nFirst, check the the VM :label, which represents its current state.\nst = Strand[prog: &quot;Vm::Nexus&quot;]\nst.label\nst.semaphores\n \nvm = st.subject\n\n\n                  \n                  WARNING\n                  \n                \n\nA stopped VM might be stuck for 1 hour and is difficult to recover. Don’t do it until Ubicloud officially supports stopping VMs.\n\n\nThen, you can operate on the VM. For example, stop it:\nvm.incr_stop\n \n# Check state\nst.reload\nst.label\nst.semaphores\nStart it again (not implemented):\nvm.incr_restart\n \n# Check state\nst.reload\nst.label\nst.semaphores\nYou can observe the state with:\nStrand[prog: &quot;Vm::Nexus&quot;].label\nProject Quota\nModify config/default_quotas.yml and create a new ubicloud/ubicloud:latest image to increase the project quota.\nYou can also create multiple projects to workaround this.\nSet up\nPrerequisites\n\nCPU architecture: x64 or arm64.\nOS: according to spdk_setup.rb, recommended Linux distributions for VM hosts are ubuntu-22.04 and ubuntu-24.04.\nHost upgrades: disable automatic upgrades with sudo apt purge unattended-upgrades.\nRAM: most memory will be reserved as huge pages. Do not run other services on the host.\nStorage: VM images and disks will be stored in /var/storage/, make sure you have sufficient space.\nEncryption: VM disks are encrypted by default, affecting performance.\nNetwork: VM host must have a public IPv6 prefix of at least /64 that is statically routed. Public IPv4 subnet is optional and can be added in the interactive Ruby shell.\nNIC: Disable Generic Receive Offload (GRO) on the interface used for NAT masquerading.\nFirewall: let Ubicloud mange the nftables firewall, and don’t host other services directly on the control plane node.\nLicense: Ubicloud is licensed under AGPL-3.0 but bdev_ubi is licensed under Elastic License 2.0. The latter may be revised in the future.\n\n\nyes, you can use Ubicloud against your on-prem servers. The prerequisite is that you should have a public ipv6 prefix for your servers and ssh access. You can add your servers using one of the non hetzner regions in the location picker. It will only serve as a region name. Your servers don’t have to be located in that provider specifically. If you want to use IPv4 for your resources, you should also make sure that there is an IPv4 subnet that is statically routed to the server as well (no ARP).\n\n# /etc/default/ufw\nDEFAULT_FORWARD_POLICY=&quot;ACCEPT&quot;\nTo avoid nftables.service reload clearing ufw rules, override flush ruleset commands from ExecStop and the /etc/nftables.conf file ExecReload reads. This breaks the cleanup function block_ip4, but that’s for public IPv4 addresses which we don’t use.\nmkdir /etc/systemd/system/ufw.service.d\ncat &gt;/etc/systemd/system/ufw.service.d/10-nftables.conf &lt;&lt;EOF\n[Unit]\nAfter=nftables.service\nEOF\n \nmkdir /etc/systemd/system/nftables.service.d\ncat &gt;/etc/systemd/system/nftables.service.d/15-no-flush.conf &lt;&lt;EOF\n[Service]\nExecReload=\nExecReload=/usr/bin/true\nExecStop=\nExecStop=/usr/bin/true\nEOF\n \nsudo systemctl daemon-reload\n \nsystemctl cat nftables.service ufw.service\nYou should test the firewall rules after deploying the control plane.\n# ports: [3000:3000] only exposes the port over IPv4\ncurl -v &lt;control plane IPv4 address&gt;:3000\nDisabling GRO\nIf you are experiencing packet loss in the VM, try disabled NIC offloads on the host.\nCreate a udev rule file:\nsudo vim /etc/udev/rules.d/99-disable-gro.rules\n\nAdd the following line (replace enp193s0f0np0 with your interface name):\nACTION==&quot;add&quot;, SUBSYSTEM==&quot;net&quot;, KERNEL==&quot;enp193s0f0np0&quot;, RUN+=&quot;/sbin/ethtool -K enp193s0f0np0 gro off&quot;\n\nYou can also run sudo ethtool -K enp193s0f0np0 gro off manually to test the fix first.\nsudo ethtool -K enp193s0f0np0 gro off\nsudo ethtool -k enp193s0f0np0 | grep receive-offload\n \n# Test in VM with curl\nIPv4 NAT\n\n\n                  \n                  NOTE\n                  \n                \n\nAdd the nftables.d configuration by hand and build the image from github.com/l2dy-forks/ubicloud/tree/patch-l2dy instead of patching.\n\n\n\n\n                  \n                  WARNING\n                  \n                \n\nThis may break subnet isolation. Use with care.\n\n\nUbicloud does not configure NAT masquerading by default, and the packet is dropped at interface enp193s0f0np0.\nncrxvwnpz3 -&gt; vethivms21c2t -&gt; vethovms21c2t -&gt; enp193s0f0np0\n\nThere are two steps to configure IPv4 NAT for VMs.\nFirst, we need to set up masquerading. Save the following as /etc/nftables.d/99-custom-ubicloud-nat.conf,\n#!/usr/sbin/nft -f\ntable ip ubicloud_nat;\ndelete table ip ubicloud_nat;\ntable ip ubicloud_nat {\n  chain prerouting {\n    type nat hook postrouting priority srcnat; policy accept;\n    oifname == &quot;enp193s0f0np0&quot; ip saddr 10.0.0.0/8 counter masquerade\n  }\n}\n\nand apply it with /usr/sbin/nft -f /etc/nftables.d/99-custom-ubicloud-nat.conf.\nThen, we need to let ubicloud set up routes for local_ipv4 along with the existing public_ipv6. To implement this, we have to modify ubicloud code and build the image.\nIn vm_setup.rb, there are several addresses involved.\n\ngua: public_ipv6 param from ephemeral_net6.to_s.\nip4: public_ipv4 param from ip4.to_s || &quot;&quot;.\nlocal_ip4: local_ipv4 param from local_vetho_ip.to_s.shellescape || &quot;&quot;.\nnics: [nic.private_ipv6.to_s, nic.private_ipv4.to_s, nic.ubid_to_tap_name, nic.mac, nic.private_ipv4_gateway] deserialized into (:net6, :net4, :tap, :mac, :private_ipv4_gateway).\n\nclass VmSetup\n  Nic = Struct.new(:net6, :net4, :tap, :mac, :private_ipv4_gateway)\nend\nand derivate addresses:\n\nlocal_ip = NetAddr::IPv4Net.parse(local_ip4)\n\nlocal_ip.network.to_s: vetho address.\nlocal_ip.next_sib.network.to_s: vethi address.\n\n\n\nThe addresses we care about is private_ipv4, which is now :net4 from nics.\ndiff --git a/rhizome/host/lib/vm_setup.rb b/rhizome/host/lib/vm_setup.rb\nindex 144e1860..15ae0b2c 100644\n--- a/rhizome/host/lib/vm_setup.rb\n+++ b/rhizome/host/lib/vm_setup.rb\n@@ -329,6 +329,10 @@ add element inet drop_unused_ip_packets allowed_ipv4_addresses { #{ip_net} }\n \n     r &quot;ip addr replace #{vetho}/32 dev vetho#{q_vm}&quot;\n     r &quot;ip route replace #{vm} dev vetho#{q_vm}&quot; if ip4\n+    # BEGIN IPv4 NAT\n+    local_ip4 = NetAddr::IPv4Net.parse(nics.first.net4).network.to_s\n+    r &quot;ip route replace #{local_ip4} dev vetho#{q_vm}&quot;\n+    # END IPv4 NAT\n     r &quot;echo 1 &gt; /proc/sys/net/ipv4/conf/vetho#{q_vm}/proxy_arp&quot;\n \n     r &quot;ip -n #{q_vm} addr replace #{vethi}/32 dev vethi#{q_vm}&quot;\nParams: github.com/ubicloud/ubicloud/blob/cf0d7c1c462e6e4bc3ff0c1ef1933e3994cecb1a/model/vm.rb#L203-L223, and nic.net4 is nic.private_ipv4.to_s.\nFinally, we build the docker image and run it in production.\nsudo docker build -t ubicloud/ubicloud:latest .\n \nsudo docker-compose down\nsudo docker-compose up -d\nNote that the changes does not immediately apply to existing VMs. You have to reboot the VM host or recreate the VMs.\nAlso, the change does not apply to existing VM hosts. You have to modify the files by hand.\nsudo -iu rhizome\ncd ..\npatch -p1 &lt; xxx.diff\nSet up control plane\nFirst, you need to patch ubicloud to get IPv4 NAT.\nThen, follow www.ubicloud.com/docs/quick-start/build-your-own-cloud to set up the control plane, and create a user. You could patch docker-compose.yml to make containers auto-restart on failure:\ngit clone github.com/ubicloud/ubicloud.git\n \ncd ubicloud\ngit apply &lt;&lt;EOF\ndiff --git a/demo/docker-compose.yml b/demo/docker-compose.yml\nindex a52d77f5..0f631a7b 100644\n--- a/demo/docker-compose.yml\n+++ b/demo/docker-compose.yml\n@@ -1,6 +1,7 @@\n services:\n   postgres:\n     image: postgres:15.4\n+    restart: unless-stopped\n     container_name: ubicloud-postgres\n     env_file: .env\n     ports:\n@@ -25,6 +26,7 @@ services:\n \n   app:\n     image: ubicloud/ubicloud:latest\n+    restart: unless-stopped\n     container_name: ubicloud-app\n     depends_on:\n       db-migrator:\nEOF\n \n# Generate secrets for demo\n./demo/generate_env\n \n# Run containers: db-migrator, app (web &amp; respirate), postgresql\ndocker-compose -f demo/docker-compose.yml up\n \n# Visit localhost:3000\nThen, downloading images you need on all VM hosts and change RACK_ENV=development to RACK_ENV=production in .env and restart the stack to prevent self-registration.\ncd demo\n \n# If you started the services with -d\ndocker-compose down\n \ndocker-compose up -d\nCloudify a bare-metal server\n\n\n                  \n                  WARNING\n                  \n                \n\nThis will reboot the server!\n\n\nRun the following commands in the interactive Ruby shell on the control plane host, replacing hostname with your server’s IP address and host_id with its host identifier.\nstrand = Prog::Vm::HostNexus.assemble(\n  hostname,\n  provider_name: &quot;leaseweb&quot;,\n  server_identifier: host_id,\n  location: &quot;leaseweb-wdc02&quot;,\n  default_boot_images: [&quot;ubuntu-jammy&quot;]\n)\n \nputs &quot;Waiting public SSH keys\\n\\n&quot;\nuntil (ssh_key = strand.reload.subject.sshable.keys.map(&amp;:public_key).first)\n  sleep 2\nend\nputs &quot;Add following public SSH key to &#039;/root/.ssh/authorized_keys&#039; on your machine\\n\\n&quot;\nputs ssh_key\nThen add the SSH key to the bare-metal server’s root user and cloudification will proceed automatically.\nSee github.com/ubicloud/ubicloud/discussions/2595 for more information. We are using the leaseweb provider because the Hetzner provider calls APIs in Hosting::Apis abstracted from lib/hosting/hetzner_apis.rb and doesn’t work in self-hosted environment.\nSteps ran in the Cloudify process are roughly:\n\nsetup_ssh_keys\nbootstrap_rhizome\nprep\nwait_prep\nsetup_hugepages\nsetup_spdk\ndownload_boot_images\nwait_download_boot_images\nprep_reboot\nreboot\nverify_spdk\nverify_hugepages\nstart_slices\nstart_vms\nwait (reached ready state)\n\nFollow hop_* in github.com/ubicloud/ubicloud/blob/main/prog/vm/host_nexus.rb#L47.\nDownload images\nThe default version is defined in github.com/ubicloud/ubicloud/blob/a670fc0946abc52d945edb2b72caae679d9f073f/config.rb#L151.\nNote that &quot;github&quot;, &quot;postgres&quot;, &quot;ai-&quot; images are not available in self-hosted version, because we don’t have access to the ubicloud-images bucket. github.com/ubicloud/ubicloud/blob/a670fc0946abc52d945edb2b72caae679d9f073f/prog/download_boot_image.rb#L30-L59\n# Start interactive Ruby shell\nsudo docker exec -it ubicloud-app ./bin/pry\n# Get your VmHost. If you have multiple ones, you can select by ID etc.\nvmh = VmHost.first\n \n# Get a list of current images\nvmh.boot_images\n \n# I assume your vm&#039;s boot image is `ubuntu-noble`. You can see available boot images here: github.com/ubicloud/ubicloud/blob/cf0d7c1c462e6e4bc3ff0c1ef1933e3994cecb1a/prog/download_boot_image.rb#L61\nst = vmh.download_boot_image(&quot;ubuntu-noble&quot;, version: &quot;20240702&quot;)\n \n# Wait to download. It will be deleted and raise `No Record Found` when done\nst.reload\n \n# If you need to abort the task\nst.destroy\nst.reload\n \n# To get a list of all tasks\nStrand.all\nConfig.production References\n\ngithub.com/ubicloud/ubicloud/blob/cf0d7c1c462e6e4bc3ff0c1ef1933e3994cecb1a/prog/download_boot_image.rb#L16-L18\n\nspdk CPU usage\nIt is expected that spdk consumes 200% CPU constantly in polling mode. See news.ycombinator.com/item for the background and design decisions.\nsudo /opt/spdk-v23.09-ubi-0.3/bin/spdk_top -r /home/spdk/spdk-v23.09-ubi-0.3.sock\nVM disk encryption\nVM disks are encrypted by default.\n[1] ⚠️ clover-production(main)&gt; VmStorageVolume.all\n=&gt; [#&lt;VmStorageVolume[&quot;v1...&quot;] @values={:vm_id=&gt;&quot;vm...&quot;, :boot=&gt;true, :size_gib=&gt;160, :disk_index=&gt;0, :key_encryption_key_1_id=&gt;&quot;k...&quot;, :key_encryption_key_2_id=&gt;nil, :spdk_installation_id=&gt;&quot;etw...&quot;, :use_bdev_ubi=&gt;true, :skip_sync=&gt;false, :storage_device_id=&gt;&quot;etr...&quot;, :boot_image_id=&gt;&quot;et...&quot;, :max_ios_per_sec=&gt;nil, :max_read_mbytes_per_sec=&gt;nil, :max_write_mbytes_per_sec=&gt;nil}&gt;]\n\nWith encryption disabled:\n[1] ⚠️ clover-production(main)&gt; VmStorageVolume.all\n=&gt; [#&lt;VmStorageVolume[&quot;v1...&quot;] @values={:vm_id=&gt;&quot;vm...&quot;, :boot=&gt;true, :size_gib=&gt;320, :disk_index=&gt;0, :key_encryption_key_1_id=&gt;nil, :key_encryption_key_2_id=&gt;nil, :spdk_installation_id=&gt;&quot;etw...&quot;, :use_bdev_ubi=&gt;true, :skip_sync=&gt;false, :storage_device_id=&gt;&quot;etr...&quot;, :boot_image_id=&gt;&quot;et...&quot;, :max_ios_per_sec=&gt;nil, :max_read_mbytes_per_sec=&gt;nil, :max_write_mbytes_per_sec=&gt;nil}&gt;]\n\nWith encryption, read performance is\n$ sudo fio --filename=/dev/vda --direct=1 --rw=randread --bs=4k --ioengine=libaio --iodepth=256 --runtime=120 --numjobs=4 --time_based --group_reporting --name=iops-test-job --eta-newline=1 --readonly\n...\niops-test-job: (groupid=0, jobs=4): err= 0: pid=1077: Sun Mar 16 14:15:17 2025\n  read: IOPS=211k, BW=825MiB/s (866MB/s)(96.7GiB/120002msec)\n    slat (usec): min=3, max=5484, avg=17.18, stdev=42.32\n    clat (usec): min=859, max=30932, avg=4827.97, stdev=2601.95\n     lat (usec): min=864, max=30983, avg=4845.16, stdev=2608.66\n    clat percentiles (usec):\n     |  1.00th=[ 1696],  5.00th=[ 2114], 10.00th=[ 2573], 20.00th=[ 3032],\n     | 30.00th=[ 3359], 40.00th=[ 3752], 50.00th=[ 4146], 60.00th=[ 4621],\n     | 70.00th=[ 5276], 80.00th=[ 6128], 90.00th=[ 7701], 95.00th=[ 9896],\n     | 99.00th=[14877], 99.50th=[16712], 99.90th=[21890], 99.95th=[23200],\n     | 99.99th=[25035]\n   bw (  KiB/s): min=702648, max=1015296, per=100.00%, avg=846076.44, stdev=14476.17, samples=956\n   iops        : min=175662, max=253824, avg=211519.07, stdev=3619.04, samples=956\n  lat (usec)   : 1000=0.01%\n  lat (msec)   : 2=3.68%, 4=42.66%, 10=48.79%, 20=4.67%, 50=0.20%\n  cpu          : usr=5.85%, sys=55.20%, ctx=7668070, majf=0, minf=1077\n  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%\n     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%\n     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.1%\n     issued rwts: total=25358100,0,0,0 short=0,0,0,0 dropped=0,0,0,0\n     latency   : target=0, window=0, percentile=100.00%, depth=256\n\nRun status group 0 (all jobs):\n   READ: bw=825MiB/s (866MB/s), 825MiB/s-825MiB/s (866MB/s-866MB/s), io=96.7GiB (104GB), run=120002-120002msec\n\nDisk stats (read/write):\n  vda: ios=25336953/74, sectors=202696360/968, merge=15/35, ticks=25926982/112, in_queue=25927112, util=100.00%\n\nYou can see a 25% performance improvement by disabling disk encryption:\n$ sudo fio --filename=/dev/vda --direct=1 --rw=randread --bs=4k --ioengine=libaio --iodepth=256 --runtime=120 --numjobs=4 --time_based --group_reporting --name=iops-test-job --eta-newline=1 --readonly\n...\niops-test-job: (groupid=0, jobs=4): err= 0: pid=1212: Mon Mar 17 14:08:35 2025\n  read: IOPS=264k, BW=1033MiB/s (1083MB/s)(121GiB/120001msec)\n    slat (usec): min=3, max=19537, avg=13.46, stdev=58.75\n    clat (usec): min=544, max=46115, avg=3858.24, stdev=1545.45\n     lat (usec): min=554, max=46124, avg=3871.70, stdev=1548.92\n    clat percentiles (usec):\n     |  1.00th=[ 2245],  5.00th=[ 2409], 10.00th=[ 2573], 20.00th=[ 2900],\n     | 30.00th=[ 3130], 40.00th=[ 3326], 50.00th=[ 3523], 60.00th=[ 3720],\n     | 70.00th=[ 3982], 80.00th=[ 4424], 90.00th=[ 5407], 95.00th=[ 6456],\n     | 99.00th=[10028], 99.50th=[12256], 99.90th=[17433], 99.95th=[19530],\n     | 99.99th=[24511]\n   bw (  MiB/s): min=  898, max= 1154, per=100.00%, avg=1033.76, stdev=11.69, samples=956\n   iops        : min=230030, max=295614, avg=264643.08, stdev=2993.21, samples=956\n  lat (usec)   : 750=0.01%, 1000=0.01%\n  lat (msec)   : 2=0.06%, 4=70.03%, 10=28.90%, 20=0.97%, 50=0.04%\n  cpu          : usr=7.28%, sys=78.70%, ctx=2902637, majf=0, minf=1076\n  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%\n     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%\n     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.1%\n     issued rwts: total=31732883,0,0,0 short=0,0,0,0 dropped=0,0,0,0\n     latency   : target=0, window=0, percentile=100.00%, depth=256\n\nRun status group 0 (all jobs):\n   READ: bw=1033MiB/s (1083MB/s), 1033MiB/s-1033MiB/s (1083MB/s-1083MB/s), io=121GiB (130GB), run=120001-120001msec\n\nDisk stats (read/write):\n  vda: ios=31700158/91, sectors=253601480/1233, merge=27/57, ticks=27805348/107, in_queue=27805461, util=99.99%\n\nDeleting projects\nIf you really want to delete a project, after deleting all resources you can from the console, run the following in the interactive Ruby shell.\nproject = Project[&quot;pjmppb65bm4a4m241bdfky3v3r&quot;]\n \n# These should be done from the console\n# project.private_subnets.each(&amp;:destroy) # or use .delete to skip callbacks\n# project.firewalls.each(&amp;:destroy) # or use .delete to skip callbacks\n \nproject.destroy\nCreating a VM\nYou must use a non-Hetzner region in the location picker to avoid calling Hetzner APIs. See github.com/ubicloud/ubicloud/discussions/2615.\nConfigure the firewall for your private subnet, and you can leave ufw or firewalld in guest OS disabled.\nLoad Balancer (need to configure a domain)\nWhen you create a load balancers, Ubicloud attempts to order a certificate for the LB and got stuck because the domain is invalid.\ngithub.com/ubicloud/ubicloud/blob/cf0d7c1c462e6e4bc3ff0c1ef1933e3994cecb1a/prog/vnet/load_balancer_nexus.rb#L83\nUpgrading Cloud Hypervisor\nA newer version of Cloud Hypervisor may provide better performance.\nThis can be tested on a per-VM-host basis. because bootstrap_rhizome setup is only ran once during the cloudify process.\n# Modify `VERSION =` to customize cloud-hypervisor version. See the following for an example.\nsudo -iu /home/rhizome\n \nvim host/lib/cloud_hypervisor.rb\nsudo ./host/bin/download-cloud-hypervisor 44.0 \\\n  f58e5d8684a5cbd7c4b8a001a1188ac79b9d4dda8115e1b3d5faa8c29038119c \\\n  6d268b947adf2b9b72c13cc8bda156e27c9a450474001d762e9bd211f90136fa\n \n# Patch for compatibility with newer cloud-hypervisor\npatch -p1 host/lib/vm_setup.rb &lt; xxx.diff\n# (:version, :sha256_ch_bin, :sha256_ch_remote)\nVersionClass.new(&quot;44.0&quot;, &quot;f58e5d8684a5cbd7c4b8a001a1188ac79b9d4dda8115e1b3d5faa8c29038119c&quot;, &quot;6d268b947adf2b9b72c13cc8bda156e27c9a450474001d762e9bd211f90136fa&quot;)\nFixes for v44.0:\n\n--disk should only be specified once. github.com/cloud-hypervisor/cloud-hypervisor/issues/6130\n\nNote that if there are no volumes attached, the VM unit file may become invalid.\n\n\nGrant CAP_NET_ADMIN to fix the TapSetIp permission error. This should not have happened according to github.com/cloud-hypervisor/cloud-hypervisor/issues/1274, so keep an eye on Ubicloud changes when they upgrade.\n\nMar 16 12:29:06 vhwkcvts540j1npnsdygqb5jvp cloud-hypervisor[34366]: Error booting VM: VmBoot(DeviceManager(CreateVirtioNet(OpenTap(TapSetIp(IoctlError(35094, Os { code: 1, kind: PermissionDenied, message: &quot;Operation not permitted&quot; }))))))\n\ndiff --git a/host/lib/vm_setup.rb.orig b/host/lib/vm_setup.rb\nindex 15ae0b2..95f4d92 100644\n--- a/host/lib/vm_setup.rb.orig\n+++ b/host/lib/vm_setup.rb\n@@ -657,9 +657,9 @@ DNSMASQ_SERVICE\n \n     disk_params = storage_volumes.map { |volume|\n       if volume.read_only\n-        &quot;--disk path=#{volume.image_path},readonly=on \\\\&quot;\n+        &quot;path=#{volume.image_path},readonly=on \\\\&quot;\n       else\n-        &quot;--disk vhost_user=true,socket=#{volume.vhost_sock},num_queues=1,queue_size=256 \\\\&quot;\n+        &quot;vhost_user=true,socket=#{volume.vhost_sock},num_queues=1,queue_size=256 \\\\&quot;\n       end\n     }\n \n@@ -688,13 +688,14 @@ Wants=#{@vm_name}-dnsmasq.service\n [Service]\n Slice=#{slice_name}\n NetworkNamespacePath=/var/run/netns/#{@vm_name}\n+AmbientCapabilities=CAP_NET_ADMIN\n ExecStartPre=/usr/bin/rm -f #{vp.ch_api_sock}\n \n ExecStart=#{CloudHypervisor::VERSION.bin} -v \\\n --api-socket path=#{vp.ch_api_sock} \\\n --kernel #{CloudHypervisor::FIRMWARE.path} \\\n-#{disk_params.join(&quot;\\n&quot;)}\n---disk path=#{vp.cloudinit_img} \\\n+--disk #{disk_params.join(&quot;\\n&quot;)}\n+path=#{vp.cloudinit_img} \\\n --console off --serial file=#{vp.serial_log} \\\n --cpus #{cpu_setting} \\\n --memory size=#{mem_gib}G,hugepages=on,hugepage_size=1G \\\nDisk I/O test results seems to imply a performance regression after upgrading to v44.0. This could be related to num_queues=1,queue_size=256 in cloud-hypervisor’s arguments or the default encryption, but we’d rather hold and wait for official updates from Ubicloud.\nFeatures missing\n\nStop and start VMs. github.com/ubicloud/ubicloud/issues/2989\n\nBut can be done by hand.\n\n\nChange VM size when VM is powered off. github.com/ubicloud/ubicloud/issues/2989\nGranular firewall per-VM without splitting subnets.\n\nWith just HTTP services, this does not bother us too much.\nA firewall can be attached to multiple subnets, but not VMs, so rules are composable, but using different subnets brings connectivity barrier.\n\n\nConnect to serial console.\n\nOnly needed if you or the Linux distribution messed up.\n\n\n"},"notes/Software/AltStore-verification-code":{"slug":"notes/Software/AltStore-verification-code","filePath":"notes/Software/AltStore verification code.md","title":"AltStore verification code","links":[],"tags":[],"content":"Code from “Get a Verification Code” does not work with AltStore when logging in to your Developer account.\nIf you add your Apple ID to Xcode accounts and verify it once, verification code can be skipped in AltStore if both are on the same network."},"notes/Software/Alternative-browsers":{"slug":"notes/Software/Alternative-browsers","filePath":"notes/Software/Alternative browsers.md","title":"Alternative browsers","links":[],"tags":[],"content":"LibreWolf\nWaterfox\nFloorp\nZen Browser"},"notes/Software/Alternative-storage-for-Prometheus":{"slug":"notes/Software/Alternative-storage-for-Prometheus","filePath":"notes/Software/Alternative storage for Prometheus.md","title":"Alternative storage for Prometheus","links":[],"tags":[],"content":"Grafana Mimir\nMimir was forked from Cortex to open source some of their work under a more restrictive license (AGPLv3). See grafana.com/blog/2022/03/30/announcing-grafana-mimir/ for a feature comparison table.\nThe most prominent feature is fast high cardinality queries, and a scalable compactor that could support “unlimited” cardinality.\nMimir also did some housekeeping work on the codebase, but this may have been caught up by the Cortex community.\nThere is also Grafana Enterprise Metrics that supports more features like cross-cluster query federation, but it’s closed source.\nCortex\nCortex nowadays is based on both Prometheus and Thanos code, using them as libraries.\nThe most important feature Cortex has as mentioned in a 2023 KubeCon talk is improved reliability via tenant isolation with limits, replication and quorum, and shuffle sharding.\nVictoriaMetrics\nVictoriaMetrics is Licensed under Apache 2.0. It also has an enterprise version that supports more features like downsampling and better automation, observability and integrations. docs.victoriametrics.com/enterprise/\nThanos\nThanos is a CNCF Incubating project licensed under Apache 2.0.\nDownsampling and compaction is one of the prominent features. Global querying is supported from day 1.\nThanos started only in sidecar mode, running alongside Prometheus instances and allows them to run with relatively low retention by supplementing it with object storage. Later on, the receiver component is added, providing remote write support.\nThanos currently lacks cardinality management tools that Mimir and VictoriaMetrics have, which is tracked in github.com/thanos-io/thanos/issues/6007."},"notes/Software/Ansible-collections":{"slug":"notes/Software/Ansible-collections","filePath":"notes/Software/Ansible collections.md","title":"Ansible collections","links":[],"tags":[],"content":"Self-containing collection install\nVersion requirement: ansible-core &gt;= 2.13.9\nTake ansible.posix as an example:\ncat &gt;ansible.cfg &lt;&lt;EOF\n[defaults]\ncollections_path = ./collections\ncallbacks_enabled = ansible.posix.profile_tasks\nEOF\n \nansible-galaxy collection install ansible.posix"},"notes/Software/Beancount-and-Fava":{"slug":"notes/Software/Beancount-and-Fava","filePath":"notes/Software/Beancount and Fava.md","title":"Beancount and Fava","links":[],"tags":[],"content":"Fava tips\n\nfava --read-only is supposedly less vulnerable to arbitrary file write, which is a feature of Fava (not a bug).\nOnly accounts opened with fava-uptodate-indication: TRUE metadata are supposed to have up-to-date balance tracking (i.e. last entry should be a balance check) and have colored indicators for these. If there are any misses, they are also included in “Copy balance directives” in the Statistics page.\n\nBugs and missing features\nRendered precision\nDefined in core/display_context.py, fractional_common is inferred from the most common number of fractional digits in all postings of the specific currency.\nThere are requests to make this customizable, but it’s not implemented yet. Issue #171\nFava export to Excel\nFava’s Excel and CSV export only works for BQL queries. You can’t export the balance sheet or income statement.\nReferences\n\ngithub.com/beancount/fava/blob/30387036d03f4278bceb0100b962860292e459f6/src/fava/help/features.md#up-to-date-indicators\n"},"notes/Software/Blink-based-SSH-workstation":{"slug":"notes/Software/Blink-based-SSH-workstation","filePath":"notes/Software/Blink-based SSH workstation.md","title":"Blink-based SSH workstation","links":["notes/Emacs/doom/tty","notes/Emacs/doom/lispy","notes/Software/Sideloading-Blink-with-AltStore","notes/Emacs/doom/Vertico"],"tags":[],"content":"Server setup\nI use Nix to install latest software, chezmoi to manage configuration files, and starship and fastfetch for my shell (zsh).\nfd is installed as a dependency for Doom Emacs, and mosh is used with Blink to provide UDP roaming capability.\n$ sudo dnf install zsh fd-find mosh fastfetch tmux git-core\n$ nix-env -q --installed\nchezmoi-2.46.0\ndiff-so-fancy-1.4.4\nemacs-nox-29.2\nglibc-locales-2.38-44\nnix-2.19.3\nstarship-1.17.1\n\nInstall the packages above.\nAdd unset SSH_TTY to .zprofile. This is a workaround for clipboard integration. See tty and github.com/blinksh/blink/issues/1957.\nSet up starship and fastfetch in .zprofile.\nAlias emacs to env TERM=st-direct emacs for 24-bit color in mosh (without tmux). This requires a recent version of ncurses, see details and how to configure tmux below.\nSet up Doom Emacs according to github.com/doomemacs/doomemacs.\nAdd (:if (featurep :system &#039;linux) (tty +osc)) to :os in doom/init.el for clipboard integration.\nAdd (add-hook &#039;tty-setup-hook #&#039;mouse-wheel-mode) to doom/config.el for mouse wheel support.\nFor C-i in Evil to “work” in terminal, add the following to doom/config.el.\n\n;; In TTY, C-i is always recognized as &quot;TAB&quot;.\n(map! :after evil\n      :map evil-motion-state-map\n      &quot;TAB&quot; #&#039;evil-jump-forward)\n\nIf you need arrow keys, avoid mapping M-O, but M-o is fine. See LispyVille.\n\n(after! lispyville\n  (evil-define-key &#039;normal lispyville-mode-map\n    (kbd &quot;M-O&quot;) nil))\n\nEmojis can cause cursor offset and screen state corruption in a mosh session. Replace them with Font Awesome icons that have the same width as regular icons could fix the issue.\n\nTake lsp-mode for example, this replaces the progress and code action icons:\n(after! lsp-mode\n  (setq lsp-modeline-code-action-fallback-icon (+modeline-format-icon &#039;faicon &quot;nf-fa-lightbulb&quot; &quot;&quot; &#039;mode-line-inactive &quot;Code Actions...&quot;)\n        lsp-progress-prefix (+modeline-format-icon &#039;faicon &quot;nf-fa-hourglass&quot; &quot;&quot; &#039;mode-line-inactive &quot;Running...&quot;)))\n\nIf Doom Emacs throws Lisp error: &quot;Note: file is write protected&quot; when SPC h f let* is pressed, it is likely because files in the nix store have r--r--r-- permissions and can be safely ignored. See backtrace below captured with debug-on-message.\n\n  after-find-file(nil t)\n  find-file-noselect-1(#&lt;buffer eval.c&gt; &quot;/nix/store/wl840kj5v3f17ns5p685g1p61xdk7sc0-emacs-...&quot; nil nil &quot;/nix/store/wl840kj5v3f17ns5p685g1p61xdk7sc0-emacs-...&quot; (55171408 64512))\n  find-file-noselect(&quot;/nix/store/wl840kj5v3f17ns5p685g1p61xdk7sc0-emacs-nox-29.1/share/emacs/29.1/src/eval.c&quot;)\n  helpful--open-if-needed(&quot;/nix/store/wl840kj5v3f17ns5p685g1p61xdk7sc0-emacs-...&quot;)\n  helpful--definition(let* t)\n  #&lt;subr helpful-update&gt;()\n  apply(#&lt;subr helpful-update&gt; nil)\n  helpful-update()\n  helpful--update-and-switch-buffer(let* t)\n  helpful-callable(let*)\n  funcall-interactively(helpful-callable let*)\n  command-execute(helpful-callable)\n\nIf you find it annoying, define the following advice in doom/config.el.\n(after! helpful\n  (defadvice! doomd--supress-helpful-open-buffer-noise (fn &amp;rest args)\n    :around #&#039;helpful--open-if-needed\n    (let ((noninteractive t))\n      (apply fn args))))\n24-bit color\ntoe -a lists all available terminal types in the system terminfo database.\nYou could use this script to check color support in your terminal. “True color gradient” should have a different color under each slash or backslash character and form a smooth gradient.\nFor emacs installed with Nix, st-direct is supported and can be verified with the following command.\nfind &quot;$(nix-store -qR ~/.nix-profile/bin/emacs | grep ncurses)&quot; | grep .-direct\nYou need to select which TERM to use carefully:\n\nalacritty-direct, konsole-direct and st-direct support 24-bit color in mosh and bracketed paste mode. These are the best choices, but have not been thoroughly tested in Blink yet.\nvscode-direct and alike support 24-bit color in mosh, but do not support bracketed paste mode with recent Emacs and terminfo.\ntmux-direct use SGR colon syntax, which mosh does not understand. You can use it in tmux to get 24-bit colors, but bracketed paste mode is broken in ways worse than telling the terminal that it’s not supported.\n\nYou can add the following to .zshrc to apply it to Emacs. env command is used to avoid TERM affecting your shell in case its terminfo database is older than what emacs uses.\n__emacs_term_fix() {\n    if [[ &quot;$TERM&quot; == &quot;xterm-256color&quot; ]]; then\n        env TERM=st-direct emacs\n    else\n        emacs\n    fi\n}\n\nalias emacs=&quot;__emacs_term_fix&quot;\n\nFor tmux, set the following in ~/.tmux.conf. terminal-overrides ensures colors work correctly, and tmux-direct is set as TERM and passed to applications. This works over both mosh and regular ssh.\nset-option -s default-terminal &quot;tmux-direct&quot;\nset-option -sa terminal-overrides &quot;,xterm-256color:Tc&quot;\n\nRun M-x list-colors-display to display the Emacs-defined colors supported. Under xterm-256color it should end in color-255, and under xterm there are only 8 basic colors.\nFor more information, see chadaustin.me/2024/01/truecolor-terminal-emacs/.\nBottom-right corner not filled\nThe point is that Emacs needs to prevent writing to the last character cell to avoid scrolling to the next line.\nSee debbugs.gnu.org/cgi/bugreport.cgi Patches were proposed, but not verified yet.\nClient setup\nBlink\n\nInstall Blink\n\nfrom App Store, or\nbuild Blink from source, and\nwith modifications (subject to change), Blink can be sideloaded with AltStore.\n\n\nSelect JetBrains Mono Nerd Font in Settings &gt; Keyboard &gt; Custom Presses for icons in Doom Emacs.\nIf your external keyboard does not have an Esc key, in Settings &gt; Keyboard &gt; ^ Control set Press Send to “Escape on Release” and in iOS settings map Caps Lock Key to Control.\nFor C-SPC to work (IME switching shortcut in iOS), add a custom press in Settings &gt; Keyboard &gt; Custom Presses with a press action of the same combo.\nIf you need hyper or super modifier keys for several key combos in Emacs, add a custom press. For example, hex code 1840732F (i.e. C-x @ s /) is equivalent to s-/, in which 18 is a control character CAN as defined in ASCII. This is an Emacs-only workaround and works for other modifiers as well (e.g. C-; with C-x @ c).\nS-DEL (Command-Backspace) is used where backspace cannot be used in place of the DEL key, e.g. in htop’s Setup view.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeyHex CodeCustom StringC-S-j1840530A\\x18@S\\nC-S-k1840530B\\x18@S\\vC-;1840633B\\x18@c;s-/1840732F\\x18@s/C-SPCN/A (C-SPC)S-DEL1B5B337E\\x1B[3~\nTips\n\nMosh sessions in Blink can survive device locks, even reboots. The drawback is that you need tmux to get scrollback.\nTo show the Context bar in Blink, tap the iOS Home Bar twice or press Cmd twice.\nconfig is available as a command or via shortcut Cmd+,.\n\nCustom Presses\n\nHyper and super modifiers does not work without custom press config. See emacs.stackexchange.com/a/5718.\nC-S- keys does not work without custom press config, e.g. in Vertico. See emacs.stackexchange.com/a/32295.\nModifiers you can use without custom press is Ctrl (valid control characters only), Esc (i.e. Alt, because M-a is ESC a), and Shift (letters and keys with upper characters only, and output is capital letters or the alternative “upper” character).\nYou can’t add two modifiers in the custom press trick we made use of in Emacs, but C-&lt;any letter&gt; as a control character can count as one key, so C-S-j is still possible as C-x @ S \\n.\nC-i as a special case is still translated to TAB in Emacs, but we can re-bind the TAB key in Emacs.\nC-x does not have a special ANSI-C quoting, but we could use \\x18 in Custom String format, e.g. \\x18@s/ for s-/.\nC-; is not a control character, and therefore need a custom press to work in Emacs.\n\nExternal Display\n\nWhen connected to an external display, Blink automatically creates a separate window on it. Press Cmd+O to switch there or back. See also docs.blink.sh/basics/tips-and-tricks#display-what-is-blink-window.\n\nIf you don’t want this, change Settings &gt; Appearance &gt; External Display to None or Mirror. The default is Scale.\n\n\nYou can set up a Mac to become an AirPlay Receiver. This is also treated as an external display in Blink. support.apple.com/guide/mac-help/mchleee00ec8/mac\n\nNote that Airplay is exclusive. You can’t multitask with other Mac apps while Airplaying.\n\n\nAfter several disconnects, Cmd+O might not be able to switch focus to the external display. Restarting Blink fixes it, but SSH connections would not persist through it.\n\nOther Known Bugs\n\n(source build only) On some external keyboards, j autorepeats, but w does not. This is related to iOS’s accent feature, where j does not have any corresponding accent character. github.com/blinksh/blink/issues/1965\nEmoji in PS1 causes cursor offset. See github.com/vercel/hyper/issues/2587 and github.com/blinksh/blink/issues/456.\n(source build only) Smart Keys not showing up in some cases.\n(third-party keyboard only?) Cmd key could be stuck when switching between apps. See docs.blink.sh/faq#cmd-key-stuck-while-switching-between-apps-with-cmd-tab.\nWhen editing an existing custom press of type “Custom String”, if the type is changed to “Hex Code”, it will be reverted if I go back one level and try to input the hex code. Going back two levels will be OK. github.com/blinksh/blink/issues/1968\n\nFeature requests\n\nDisable font ligatures (workaround: use a font without ligatures) github.com/blinksh/blink/issues/828\nInverted ANSI prompt github.com/blinksh/blink/issues/1451\nEternalTerminal support github.com/blinksh/blink/issues/597\nCan’t use trackpad or mouse on external display without Stage Manager.\nSixel graphics, but mosh does not intend to support it. github.com/blinksh/blink/issues/750 and github.com/mobile-shell/mosh/issues/1081\n"},"notes/Software/CSV-manipulation-in-CLI":{"slug":"notes/Software/CSV-manipulation-in-CLI","filePath":"notes/Software/CSV manipulation in CLI.md","title":"CSV manipulation in CLI","links":[],"tags":[],"content":"CLI\n\ngithub.com/dathere/qsv\ngithub.com/medialab/xan\ngithub.com/harelba/q\n\nTUI\n\ngithub.com/saulpw/visidata\n"},"notes/Software/CachyOS-in-UTM":{"slug":"notes/Software/CachyOS-in-UTM","filePath":"notes/Software/CachyOS in UTM.md","title":"CachyOS in UTM","links":["notes/Software/UTM"],"tags":[],"content":"Running CachyOS in UTM.\nHyprland desktop environment\nBugs\nHyprland becomes unresponsive after host wakes from sleep. Could be related to GPU acceleration.\nLog out\nRun hyprctl dispatch exit (Cmd-Shift-M shortcut by default).\nIf you are stuck, try Ctrl-Alt-F3 to get a tty.\nClipboard Integration\nNot supported. See gitlab.freedesktop.org/spice/linux/vd_agent/-/issues/26.\nVirtual desktops\n\ns-F for fullscreen\ns-&lt;n&gt; to switch to desktop\ns-S-&lt;n&gt; to move active window to desktop, or s-C-&lt;n&gt; to also switch to the new desktop\ns-up/down/left/right to select active window\n\nKeyboard layout\nSet kb_layout = &lt;custom layout&gt; in hyprland.conf.\ngithub.com/CachyOS/cachyos-hyprland-settings/tree/master/etc/skel/.config\nScreen resolution\nThe default monitor=,preferred,auto,auto is good enough.\nCustom resolution may fail to render properly. Try 1.5x and 2x if necessary.\nTerminal\nS-RET to start the Alacritty terminal.\nIntel Macs does not support OpenGL 3.3 in VM, so you need to specify a compatible renderer.\ndebug:\n  renderer: gles2_pure\nYou could also install foot in chroot environment as a CPU-rendering fallback.\nMouse cursor\nWorkaround: add env = WLR_NO_HARDWARE_CURSORS,1 to hyprland.conf.\nActually a kernel bug. See github.com/swaywm/sway/issues/6581 for more information.\nGPU acceleration\nOnly OpenGL 2.1 is supported. Newer backend is under development.\n\ngfxstream is an alternative library that allows the guest to serialize OpenGL and Vulkan commands, pass them through a communication channel (“pipe”) to the host, and the host will deserialize and evaluate the calls. It differs from virglrenderer in that there is no intermediate translation (guest Mesa → virgl commands → host OpenGL). Currently this technology is used for Google’s Android emulator and not by mainline QEMU so it will take some time for UTM to adopt the code.\n\ngithub.com/utmapp/UTM/blob/5df9e6381634d11b37a975b29ea7142eb1fcce68/Documentation/Graphics.md#gfxstream\nDo not use the “ANGLE (Metal)” renderer backend. It’s OpenGL support is worse.\nTODOs\n\nInvestigate how ZFS chroot environment is set up by CachyOS installer.\n"},"notes/Software/Compress-pictures-in-PDF-files":{"slug":"notes/Software/Compress-pictures-in-PDF-files","filePath":"notes/Software/Compress pictures in PDF files.md","title":"Compress pictures in PDF files","links":[],"tags":[],"content":"gm convert -density 150 -compress JPEG\n\nDefault -density is 72. If the image quality is too bad, consider increasing it.\n-compress JPEG enables compression.\n(Optional) -quality 92 can improve image quality. The default is 75.\n"},"notes/Software/Contributing-packages-on-conda-forge":{"slug":"notes/Software/Contributing-packages-on-conda-forge","filePath":"notes/Software/Contributing packages on conda-forge.md","title":"Contributing packages on conda-forge","links":[],"tags":[],"content":"Steps\n\nSearch if there is an existing package on github.com/conda-forge.\nPrepare the build environment. mamba create -n build conda-build grayskull\nActivate the environment. mamba activate build\n(for Python packages) Generate the recipe with grayskull.\n(for R packages) Follow instructions in github.com/bgruening/conda_r_skeleton_helper/blob/main/README.md to generate the recipes.\nCheck if the generated recipe is correct and conform to github.com/conda-forge/staged-recipes/blob/main/.github/pull_request_template.md.\nBuild the recipe. conda-build --R &lt;R version&gt; &lt;path/to/new/recipe&gt;\nInstall it locally to test. mamba install --use-local &lt;recipe name&gt;\nMove the recipe directory to staged-recipes/recipes.\nCreate pull request on GitHub.com.\n\nReferences\n\nconda-forge.org/docs/maintainer/adding_pkgs/\ndocs.conda.io/projects/conda-build/en/latest/user-guide/tutorials/build-r-pkgs.html\n"},"notes/Software/Convert-.qcow2-files-to-VMware-format":{"slug":"notes/Software/Convert-.qcow2-files-to-VMware-format","filePath":"notes/Software/Convert .qcow2 files to VMware format.md","title":"Convert .qcow2 files to VMware format","links":[],"tags":[],"content":"qemu-img\nYou can use the qemu-img command to convert between supported formats like qcow2, vdi and vmdk.\nqemu-img convert -f qcow2 -O vmdk img.qcow2 img.vmdk"},"notes/Software/Create-.ipa-files-without-a-developer-account":{"slug":"notes/Software/Create-.ipa-files-without-a-developer-account","filePath":"notes/Software/Create .ipa files without a developer account.md","title":"Create .ipa files without a developer account","links":[],"tags":[],"content":"\nArchive the target\nRight-click the archive and click “Show in Finder”\nRight-click the .xcarchive file and click “Show Package Contents”\nGo into the Products folder\nRename Applications to Payload\nRight-click the Payload folder and click “Compress …”\nRenamed the generated .zip file to a .ipa file\n"},"notes/Software/Discourse-advanced-search":{"slug":"notes/Software/Discourse-advanced-search","filePath":"notes/Software/Discourse advanced search.md","title":"Discourse advanced search","links":[],"tags":[],"content":"Search for a user’s topics in a specific category\n@&lt;username&gt; #&lt;category&gt; in:first\n"},"notes/Software/EWS-support-in-Thunderbird":{"slug":"notes/Software/EWS-support-in-Thunderbird","filePath":"notes/Software/EWS support in Thunderbird.md","title":"EWS support in Thunderbird","links":[],"tags":[],"content":"Updates\n\nmeta bug bugzilla.mozilla.org/show_bug.cgi\nUpdates on blog blog.thunderbird.net/tag/exchange/\n\nBugs\n\nno folders to browse with on-prem EWS bugzilla.mozilla.org/show_bug.cgi\nsmtp server settings is empty bugzilla.mozilla.org/show_bug.cgi\n"},"notes/Software/Fix-PATH-environment-for-Gradle-tasks-execution-in-IntelliJ-IDEA":{"slug":"notes/Software/Fix-PATH-environment-for-Gradle-tasks-execution-in-IntelliJ-IDEA","filePath":"notes/Software/Fix PATH environment for Gradle tasks execution in IntelliJ IDEA.md","title":"Fix PATH environment for Gradle tasks execution in IntelliJ IDEA","links":[],"tags":[],"content":"\n\n                  \n                  INFO\n                  \n                \n\nThis is likely a bug similar to youtrack.jetbrains.com/issue/WEB-74559/Vitest-Run-Configuration-fails-with-Yarn-v4-PnP-due-to-incorrect-path-resolution in IntelliJ IDEA 2025.2.\n\n\nWorkarounds\nyoutrack.jetbrains.com/projects/IJPL/issues/IJPL-1055/Load-interactive-shell-environment-variables-on-Linux\nWorkaround 1 (broken on macOS, see Experiment):\nlaunchctl setenv PATH &quot;/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:$HOME/.cargo/bin&quot;\nGiven that it doesn’t respect /etc/paths, configuring /etc/paths.d doesn’t work either.\nWorkaround 2 (working):\nStart the application from a shell:\nalias idea=&#039;open &quot;/Applications/IntelliJ IDEA CE.app&quot;&#039;\nidea\n\n- Workaround 2 worked for me. This step is essential to verify that nvm, node.js (or any tool that brought you to this issue) are running as expected.\nTo run IDE / PhpStorm from Terminal, could be as simple as typing in the terminal:\nphpstorm\nor the name of your IDE, like webstorm\n\nWorkaround 3 (official fix for Linux):\n\nStarting from 2025.3, it is possible to enable shell variable loading on Linux by adding -Dij.load.shell.env=true to VM options (Help | Edit custom VM options) and restarting the IDE.\nPlease give it a try, but ensure first that your shell RC file is not interactive (i.e., doesn’t stop on a prompt) and does not perform long operations. Check for INTELLIJ_ENVIRONMENT_READER environment variable if necessary.\n\nWorkaround 4 (broken):\nSet PATH variable in Path Variables settings.\nExperiment\n$ # start from Finder\n$ ps auxeww | grep /idea | grep -o &#039; PATH=[^ ]*&#039;\n PATH=/usr/bin:/bin:/usr/sbin:/sbin\n$ ps auxeww | grep .GradleDaemon | grep -o &#039; PATH=[^ ]*&#039; # inherits idea&#039;s PATH\n PATH=/usr/bin:/bin:/usr/sbin:/sbin\n \n$ launchctl setenv PATH \\\n  &quot;/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:$HOME/.cargo/bin&quot; # doesn&#039;t affect `idea`\n$ ps auxeww | grep /idea | grep -o &#039; PATH=[^ ]*&#039;\n PATH=/usr/bin:/bin:/usr/sbin:/sbin"},"notes/Software/FlowDown":{"slug":"notes/Software/FlowDown","filePath":"notes/Software/FlowDown.md","title":"FlowDown","links":[],"tags":[],"content":"Model configuration\nWorkgroup is a pseudonym for API key. The name is used to circumvent App Store review issues."},"notes/Software/Flowed-text-in-Mutt":{"slug":"notes/Software/Flowed-text-in-Mutt","filePath":"notes/Software/Flowed text in Mutt.md","title":"Flowed text in Mutt","links":[],"tags":[],"content":"With MacPorts\nBesides mutt, also install vim which provides the vi command mutt defaults to.\nIn .muttrc,\n# Body Format\nset text_flowed\nset send_charset=utf-8\n\nand in .vimrc,\nsource $VIMRUNTIME/defaults.vim\n \naugroup mail_flowed &quot; {\n\tautocmd!\n\tautocmd FileType mail setlocal formatoptions+=w\n\tautocmd FileType mail setlocal colorcolumn=72\naugroup END &quot; }"},"notes/Software/Fuzzing-yash":{"slug":"notes/Software/Fuzzing-yash","filePath":"notes/Software/Fuzzing yash.md","title":"Fuzzing yash","links":[],"tags":[],"content":"AFL++\nBuilding AFL++ on Ubuntu\nFirst, install the latest LLVM from the official APT repository.\nThen, clone AFLplusplus and run the following commands.\nsudo apt-get install clang-18 lld-18\n \nLLVM_CONFIG=llvm-config-XX make all\nsudo make install\nFighting compiler optimization\nA simple trick to avoid entire for loops and function calls be optimized away, store the result in an iteration or of the function in a volatile variable is the simplest without side-effects like printf.\nBuild Flags\ncc_params[cc_par_cnt++] = &quot;-g&quot;;\nif (!have_o) cc_params[cc_par_cnt++] = &quot;-O3&quot;;\nWithout -O flags, afl-cc will add -O3. Besides, -g is always added.\nCC=afl-clang-lto CXX=afl-clang-lto++ RANLIB=llvm-ranlib-17 AR=llvm-ar-17 AS=llvm-as-17 CFLAGS=&quot;-fsanitize=fuzzer-no-link&quot; LDFLAGS=&quot;-fsanitize=fuzzer-no-link&quot; ./configure\n \n# Standard ver.\nmake fuzz_parser\n \n# With sanitizers\nAFL_USE_ASAN=1 AFL_USE_UBSAN=1 make fuzz_parser\nLast line of output should be [+] Instrumented ... (non-hardened mode) or (non-hardened, ASAN, UBSAN mode) with sanitizers.\nPrepare Input\n\nIMPORTANT: if you use afl-cmin or afl-cmin.bash, then either pass - or @@ as command line parameters.\n\n# No need for fuzzing flags\n./configure\nmake yash\n# Replace `-v` with `r` in tests/Makefile\ncd tests &amp;&amp; make test-valgrind\n# Collect input files from tmp.*\nfind . -mindepth 2 -maxdepth 2 -type f -name &#039;*.in&#039; | parallel &#039;cp {} ../yash-afl-input-tests/{#}.in&#039;\n \nafl-cmin -i ../yash-afl-input-tests -o ../yash-afl-input-unique -- ./fuzz_parser -\n \nfind ../yash-afl-input-unique -type f | parallel &#039;afl-tmin -i {} -o ../yash-afl-input-min/{/} -- ./fuzz_parser&#039;\n \nafl-cmin -i ../yash-afl-input-min -o ../yash-corpus-min-input -- ./fuzz_parser -\nRun\n# Master\nAFL_FINAL_SYNC=1 afl-fuzz -M main -i ../yash-corpus-min-input -o ../yash-corpus-r1 -x .../bash.dict -a text -- ./fuzz_parser\n \n# Slaves\nafl-fuzz -S sans-00 -i ../yash-corpus-min-input -o ../yash-corpus-r1 -x path/to/bash.dict -a text -- ./fuzz_parser_asan_ubsan\n&lt;...&gt;\nlibFuzzer\nBuild flags\n# With ASan\n./configure CC=clang-17 CXX=clang++-17 CFLAGS=&quot;-g -O1 -fsanitize=fuzzer-no-link,address -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION&quot; LDFLAGS=&quot;-fsanitize=fuzzer-no-link,address&quot;\n \n# With MacPorts on macOS\n./configure CC=clang-mp-17 CXX=clang++-mp-17 CFLAGS=&quot;-g -O1 -I/opt/local/include -fsanitize=fuzzer-no-link -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION&quot; LDFLAGS=&quot;-L/opt/local/lib -fsanitize=fuzzer-no-link&quot;\n \nmake fuzz_parser\nNote: during configure phase, if AddressSanitizer discovers a crash, it will silently disable the feature.\nFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION is proposed by libFuzzer authors as a common build macro for fuzzing-friendly build.\nRun\nrm -r ../yash-corpus-r1/\nmkdir ../yash-corpus-r1\n \n./fuzz_parser -dict=bash.dict ../yash-corpus-r1\n./fuzz_parser -dict=bash.dict -fork=&lt;N&gt; ../yash-corpus-r1 # multi-process\nMinimize case\n./fuzz_parser -minimize_crash=1 -runs=10000 crash-XXX\nReferences\n\ngithub.com/AFLplusplus/AFLplusplus/blob/61e27c6b54f7641a168b6acc6ecffb1754c10918/src/afl-cc.c#L1255-L1256\ngithub.com/AFLplusplus/AFLplusplus/blob/61e27c6b54f7641a168b6acc6ecffb1754c10918/instrumentation/README.lto.md\ngithub.com/AFLplusplus/AFLplusplus/blob/61e27c6b54f7641a168b6acc6ecffb1754c10918/docs/fuzzing_in_depth.md\n"},"notes/Software/Ghostty":{"slug":"notes/Software/Ghostty","filePath":"notes/Software/Ghostty.md","title":"Ghostty","links":[],"tags":[],"content":"My config\n# Until search function is implemented.\nkeybind = super+f=write_screen_file:open\n \n# For low DPI screens on macOS.\nfont-thicken = true\nTo specify a fallback font, simply set the key twice.\nfont-family = &quot;JetBrains Mono&quot;\nfont-family = &quot;Hei Regular&quot;"},"notes/Software/HAProxy":{"slug":"notes/Software/HAProxy","filePath":"notes/Software/HAProxy.md","title":"HAProxy","links":[],"tags":[],"content":"Statistics report\nYou may see a session limit on “Backend” that is one tenth of the frontend’s session limit, which represents the default fullconn for a backend. Unless you have set a minconn parameter, you may safely ignore this “limit” on backend, but other limits still apply.\nmaxconn max settings\n\nIf maxconn value is not set, it will be automatically calculated based on the current file descriptors limits, reported by the “ulimit -nH” command (we take the maximum between the hard and soft values), then automatic value will be possibly reduced by “fd-hard-limit” and by memory limit, if the latter was enforced via “-m” command line option.\n\nIf HAProxy is managed by systemd, it gets the default limits from DefaultLimitNOFILE and DefaultLimitNOFILESoft:\nsystemctl show | grep LimitNOFILE\nIf you need to support a large number of connections, you may either set maxconn or fd-hard-limit to let HAProxy process raise the limits itself, or specify LimitNOFILE in systemd unit configuration. But the system-wide fs.nr_open sysctl configuration still applies and your new limits cannot exceed it.\nGiven that HAProxy needs to reserved some file descriptors for listeners and checks, setting maxconn to 50% of fs.nr_open will make HAProxy crash as described in github.com/haproxy/haproxy/commit/8438ca273f4b174b51b5ff2a504ff5d2278134af. You should try one of the following:\n\nIncrease the system-wide fs.nr_open, which is already the maximum if the Linux system is managed by systemd and includes the commit a8b627aa from systemd.\nFor Debian that is since commit 99066f93 on salsa where -Dbump-proc-sys-fs-nr-open=false was removed, which is included in stable since Debian 13.\nSet maxconn to roughly 49% of the current limit minus the known used FDs for listeners and checks.\nUse fd-hard-limit instead and let HAProxy adjust the maxconn limit by itself.\n\nAlso, each frontend and backend server can have their own maxconn limits. You may check all limits on HAProxy’s statistics report.\nThe systemd-wide fs-file-max also matters, but usually it’s set to a very large value and not of concern."},"notes/Software/HP-Smart-scanning-tips":{"slug":"notes/Software/HP-Smart-scanning-tips","filePath":"notes/Software/HP Smart scanning tips.md","title":"HP Smart scanning tips","links":[],"tags":[],"content":"Printer setup\nIf Wi-Fi is not stable, try connecting with USB cable.\nScanning\nSteps to scan a document:\n\nScan without paper in scan area to recognize black edges.\nIf there is some blackness on the left but none at the top, you can try the following instructions.\nenable Detect Edges and set Page Size to Entire Scan Area.\nPut document in and align with top left corner icon.\nSlightly slide the document from the left edge, in terms of scan coordinates.\nClick Scan or Add Scan.\nCheck the auto crop result and click Apply if satisfied.\nContinue from step 4 to scan more pages.\n\nIf you have a well-aligned scan area, just select the same page size as your document and put it right in place."},"notes/Software/Implementing-bulk-actions-in-Plane":{"slug":"notes/Software/Implementing-bulk-actions-in-Plane","filePath":"notes/Software/Implementing bulk actions in Plane.md","title":"Implementing bulk actions in Plane","links":[],"tags":[],"content":"Notes\n\ngithub.com/makeplane/plane/pull/7141 is buggy on removal of date range and selecting a single day. Do not rebase past this commit yet.\n\nDevelopment\nFirst, restore AGPL-3.0 licensed code from Git history:\nsed -i &#039;s/false;/true;/&#039; web/ce/hooks/use-bulk-operation-status.ts\ngit checkout e3ebb9b61cc5ed63919a07f1c389f1e0f2b0efe5^ -- web/core/components/issues/bulk-operations\nrm -r web/ce/components/issues/bulk-operations &amp;&amp; git mv web/core/components/issues/bulk-operations web/ce/components/issues/bulk-operations\nConfigure the venv directory ignored by .dockerignore at project root and you are ready for development.\nThen, fill up the gaps with the help of AI.\nPushing images\nrm -r apiserver/plane/logs/\ngit clean -dnx # compare with .dockerignore\n \nexport DOCKERHUB_USER=l2dy APP_RELEASE=v0.26.1\ndocker compose -f deploy/selfhost/build.yml build --pull\ngrep -o &#039;/[a-z-]*:&#039; build.yml | awk &quot;{print \\&quot;docker push \\\\\\&quot;${DOCKERHUB_USER:-local}\\&quot;\\$0\\&quot;${APP_RELEASE:-latest}\\\\\\&quot;\\&quot;}&quot; | bash\nLocal development\nMostly just follow CONTRIBUTING.md, but add the --pull always --build flags to docker compose up if files have been changed.\ndocker compose -f docker-compose-local.yml up --pull always --build\n\nLint commands for AI\nSuggest improvements to the code. Keep your changes contained in the referenced file.\n\ntoolbar.tsx\n\ncd web\nnpx eslint ce/components/issues/bulk-operations/toolbar.tsx --format=compact\n \nruff check --ignore E501 --fix apiserver/plane/app/views/issue/bulk.py\nAI is bad at formatting, so run the formatter yourself:\nruff format apiserver/plane/app/views/issue/bulk.py\nPrompts for AI\nImplement the bulk operations toolbar in place of the `&lt;BulkOperationsUpgradeBanner /&gt;` stub in root.tsx. Requirements:\n\n1. Make use of other components in the same folder and adjust them if needed.\n2. Use API in issue.service.ts to perform the actions when the user clicks the Update button.\n\nRead the files and understand what API handleBulkUpdate() needs. Write an API specification and save it to a Markdown file in project root for your Python engineers to implement.\n\nbase-issues.store.ts\nissue.service.ts\ntoolbar.tsx:28-61\n\nWe could create an implementation guide as well, but the agent will read the Python codebase as the agnet works on it, so it’s not necessary. We are doing it anyways here:\nRead the implementation of BulkArchiveIssuesEndpoint and IssueBulkUpdateDateEndpoint and the respective `urlpatterns` in issue.py. Write a detailed guide in Markdown to show your Python engineers how to implement a bulk action endpoint for issues and save it in project root.\n\nbase.py\narchive.py\nissue.py\n\nImplement the Bulk Update Issues API as described in the API specification and follow the Implementation Guide document. Put the implementation in a new file named bulk.py in the apiserver/plane/app/views/issue folder.\n\nBULK_UPDATE_API_SPECIFICATION.md\nBULK_ACTIONS_IMPLEMENTATION_GUIDE.md\nissue\nissue.py\n\nYou must follow the API specification. Fix the mismatches.\n\nBULK_UPDATE_API_SPECIFICATION.md\nbulk.py\n\nCheck if your code conforms to the implementation guide.\n\nBULK_ACTIONS_IMPLEMENTATION_GUIDE.md\nbulk.py\n"},"notes/Software/Interesting-bug-stories":{"slug":"notes/Software/Interesting-bug-stories","filePath":"notes/Software/Interesting bug stories.md","title":"Interesting bug stories","links":[],"tags":[],"content":"References\n\nbeza1e1.tuxen.de/lore/index.html\n500mile.email/\n"},"notes/Software/Irssi-config":{"slug":"notes/Software/Irssi-config","filePath":"notes/Software/Irssi config.md","title":"Irssi config","links":[],"tags":[],"content":"Pinning self-signed certificate\n/set use_tls yes\n/set tls_verify no\n/set tls_pinned_cert &quot;XX:XX:...&quot;\n\nCertfp authentication\nThe pem file should contain both a private key and the corresponding certificate.\n/set tls_cert &quot;~/.irssi/certs/xxx.user.pem&quot;\n"},"notes/Software/Krita":{"slug":"notes/Software/Krita","filePath":"notes/Software/Krita.md","title":"Krita","links":[],"tags":[],"content":"Pen tablet shortcuts\n\nShift + drag left/right to resize the brush.\nButton (close to pen tip) + drag to zoom in and out.\nSPACE + drag to move the canvas.\nShift + SPACE + drag to rotate the canvas.\n"},"notes/Software/Layer-7-Load-Balancing-solutions":{"slug":"notes/Software/Layer-7-Load-Balancing-solutions","filePath":"notes/Software/Layer 7 Load Balancing solutions.md","title":"Layer 7 Load Balancing solutions","links":[],"tags":[],"content":"Front/Edge proxy\nComplete solutions\n\ngithub.com/Kong/kong\ngithub.com/bfenetworks/bfe (Baidu)\ngithub.com/memorysafety/river (ISRG, not public yet)\n\nBuilding blocks\n\ngithub.com/cloudflare/pingora (Cloudflare, API is unstable during pre-1.0)\ngithub.com/envoyproxy/envoy\n\nTo be determined\n\ngithub.com/TykTechnologies/tyk\ngithub.com/krakend/krakend-ce\ngithub.com/flomesh-io/pipy\n"},"notes/Software/Mutt-inbox-sweep":{"slug":"notes/Software/Mutt-inbox-sweep","filePath":"notes/Software/Mutt inbox sweep.md","title":"Mutt inbox sweep","links":[],"tags":[],"content":"Use T to tag messages matching ~s &lt;subject regex&gt;, etc. and l to view matching messages first before tagging, and then ;d to delete messages and $ to sync the changes to mailbox.\nAlternatively, use D to replace T and ;d for simpler workflow.\nTo select a range of visible messages, use ~m with a comma for relative message number range and a hyphen for absolute number range (both are inclusive).\nTo reset the limit, type . after l, which is a “simple search” shortcut for all. Other simple search keywords are:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeywordPattern modifierall~A.~A^~Adel~Dflag~Fnew~Nold~Orepl~Qread~Rtag~Tunread~U\nMovement\n* moves to last entry and = moves to first entry."},"notes/Software/Netdata":{"slug":"notes/Software/Netdata","filePath":"notes/Software/Netdata.md","title":"Netdata","links":[],"tags":[],"content":"Disable telemetry and cloud features\ncat &gt; ~/cloud.conf &lt;&lt; EOF\n[global]\n  enabled = no\nEOF\n \nsudo cp ~/cloud.conf /var/lib/netdata/cloud.d/\nsudo touch /etc/netdata/.opt-out-from-anonymous-statistics\nHow to build RPM packages\ngithub.com/netdata/netdata/blob/v1.39.0/packaging/building-native-packages-locally.md\n:z is needed if SELinux is enabled. Use :Z for additional access protection.\ngit clone github.com/netdata/netdata.git\ncd netdata\n \ngit apply &lt;&lt;&#039;EOF&#039;\ndiff --git a/netdata.spec.in b/netdata.spec.in\nindex c2fa7dcab..f70f74c6c 100644\n--- a/netdata.spec.in\n+++ b/netdata.spec.in\n@@ -231,6 +231,7 @@ export CFLAGS=&quot;${CFLAGS} -fPIC&quot; &amp;&amp; ${RPM_BUILD_DIR}/%{name}-%{version}/packaging\n # Conf step\n autoreconf -ivf\n %configure \\\n+\t--disable-cloud \\\n \t%if 0%{!?_have_ebpf}\n \t--disable-ebpf\n \t%endif\nEOF\n \npodman run -it --rm -e VERSION=&lt;1.x.x&gt; -v $PWD:/netdata:z netdata/package-builders:oraclelinux9\n# checking if Cloud functionality should be enabled... no\nCharts v3\n\nThese are currently available at Netdata Cloud. At the next Netdata release (v1.40.0), the agent dashboard will be replaced to also use the same charts.\n"},"notes/Software/Nix-channel-status":{"slug":"notes/Software/Nix-channel-status","filePath":"notes/Software/Nix channel status.md","title":"Nix channel status","links":[],"tags":[],"content":"View channel freshness on status.nixos.org/. nixpkgs-unstable can be a few days old.\nFor Nix channel freshness history, check out monitoring.nixos.org/grafana/d/LhIq8iLWk/channel-updates\nUse nixpk.gs/pr-tracker.html to check progress of a specific nixpkgs PR. For example, nixpk.gs/pr-tracker.html"},"notes/Software/Office-for-Mac-download-and-telemetry-config":{"slug":"notes/Software/Office-for-Mac-download-and-telemetry-config","filePath":"notes/Software/Office for Mac download and telemetry config.md","title":"Office for Mac download and telemetry config","links":[],"tags":[],"content":"Download\nlearn.microsoft.com/en-us/microsoft-365-apps/mac/deployment-options-for-office-for-mac\nThe easiest way to download Office for Mac, and ensure you’re always getting the most current version and build, is to download directly from the Office Content Delivery Network (CDN) on the internet. Here are the links to the installer packages for the Office suite, which contains all the applications.\n\nMicrosoft 365 for Mac\nOffice LTSC for Mac 2024 (volume license)\nOffice LTSC for Mac 2021 (volume license)\n\nThe same installer package can be used for Microsoft 365 subscriptions, Office LTSC for Mac 2024, and Office LTSC for Mac 2021. How you activate the product determines which features are available to your users.\nConfiguration\nDiagnostics data collection\nlearn.microsoft.com/en-us/microsoft-365-apps/privacy/mac-privacy-preferences\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCategoryDetailsPreference Domaincom.microsoft.officeKeyDiagnosticDataTypePreferenceData TypeStringPossible valuesBasicDiagnosticData (this value sets the level to Required)  FullDiagnosticData (this value sets the level to Optional)  ZeroDiagnosticData (this value sets the level to Neither)Availability16.28 and later\nIf you don’t set this preference, both required and optional diagnostic data are sent to Microsoft if users with a Microsoft 365 (or Office 365) subscription are signed in with a work or school account, or if users have either Office LTSC Standard for Mac 2024 or Office LTSC Standard for Mac 2021. Also, these users can’t change the level of diagnostic data regardless of how you set this preference.\ndefaults write com.microsoft.office DiagnosticDataTypePreference -string ZeroDiagnosticData\nConnected experiences\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCategoryDetailsPreference Domaincom.microsoft.officeKeyConnectedOfficeExperiencesPreferenceData TypeBooleanPossible valuesTRUE (enabled)  FALSE (disabled)Availability16.28 and later\nIf you set this preference to FALSE, the following types of connected experiences won’t be available to your users:\n\nExperiences that analyze your content\nExperiences that download online content\nOptional connected experiences\n\nIn addition, if you set this preference to FALSE, most other connected experiences are also turned off, such as coauthoring and online file storage. For a list of these other connected experiences, see Connected experiences in Office.\nBut even if you set this preference to FALSE, limited Office functionality will remain available, such as synching a mailbox in Outlook, and Teams and Skype for Business will continue to work. Essential services, such as the licensing service that confirms that you’re properly licensed to use Office, will also remain available.\ndefaults write com.microsoft.office ConnectedOfficeExperiencesPreference -bool false"},"notes/Software/Regular-expressions-in-Vector-config":{"slug":"notes/Software/Regular-expressions-in-Vector-config","filePath":"notes/Software/Regular expressions in Vector config.md","title":"Regular expressions in Vector config","links":[],"tags":[],"content":"Character classes\ndocs.rs/regex/latest/regex/#character-classes\n\nAny named character class may appear inside a bracketed [...] character class.\n\nstart_pattern: &#039;^[^\\s]&#039;\ncondition_pattern: &#039;^[\\s]+&#039;\nNote that in YAML, escape sequences are only interpreted in double-quoted scalars. Therefore, the example given in multiline.condition_pattern is also correct, albeit unnecessarily complex.\n&quot;^[\\\\s]+&quot;"},"notes/Software/Remote-Linux-Desktop-on-macOS":{"slug":"notes/Software/Remote-Linux-Desktop-on-macOS","filePath":"notes/Software/Remote Linux Desktop on macOS.md","title":"Remote Linux Desktop on macOS","links":["notes/Software/UTM","notes/Software/CachyOS-in-UTM"],"tags":[],"content":"Linux distributions\nArch Linux\nwiki.archlinux.org/title/Laptop/Apple\nVirtual Machine Manager (VMM)\nVMware Fusion\nFree for all users.\nSince VMware Fusion 13, OpenGL 4.3 is supported, but performance characteristics are unclear.\nUTM\nSupport Apple Hypervisor or QEMU backends.\nQEMU backend supports VirGL and both support host-side upscaling.\nSee also CachyOS in UTM.\nVirtualBox\nFree, but has CPU usage going wild issues. www.virtualbox.org/ticket/18089\nRemote X Server\nSSH X11 forwarding\nRequires XQuartz or xorg-server from MacPorts.\nLowest overhead for a local connection.\nBest for running applications directly.\nSPICE\nHaven’t tried yet. macOS client does not support SSH.\nX2Go\nDownload .dmg from code.x2go.org/releases/binary-macosx/x2goclient/releases/ to get the latest version. Also requires XQuartz.\nmacOS client could not resume existing sessions, crashing every time.\nnxagent does not support modern desktop environments. In general, seamless mode is preferred.\nXpra\nKeyboard support is bad. Modifier keys are broken. github.com/Xpra-org/xpra/issues/2804\nBased on video streaming, less efficient.\nOpenGL does not work on client-side.\nReferences\n\ndocs.getutm.app/settings-qemu/devices/display/\nwiki.x2go.org/doku.php/doc:de-compat\n"},"notes/Software/Resin-source-code-preservation":{"slug":"notes/Software/Resin-source-code-preservation","filePath":"notes/Software/Resin source code preservation.md","title":"Resin source code preservation","links":[],"tags":[],"content":"Online changelog (outdated)\ncaucho.com/resin-4.0/changes/changes.xtp\nImport process\n\ngit init resin-src &amp;&amp; cd resin-src\nDownload all resin-4.0.x-src.tar.gz files from caucho.com/products/resin/download/gpl.\n/usr/share/git/contrib/fast-import/import-tars.perl resin-4.0.{0..67}-src.tar.gz and git checkout import-tars\ngit filter-branch -d /dev/shm/.git-rewrite --index-filter &#039;git rm -r --cached --ignore-unmatch lib/*.jar ext-lib project-jars webapp-jars win32 win64 *.exe compat/javaee-15.jar aclocal.m4 automake Makefile.in configure&#039; (you can use any tmpfs mount instead of /dev/shm)\nRecover folder structure and missing parts.\n\nBuild instructions\nPrerequisites\n\nJDK 8, set as JAVA_HOME.\nApache Ant.\nAutoconf, Automake and Libtool from GNU.\n\nPack\nant -Dversion=4.0.XX dist\nWith MacPorts:\n# If building with OpenJDK 8\nsed -i &#039;&#039; &#039;s/1\\.7/1.8/&#039; build-common.xml\n \nPATH=&quot;/Library/Java/JavaVirtualMachines/temurin-8.jdk/Contents/Home/bi:$PATH:/opt/local/libexec/gnubin&quot; ant -Dversion=4.0.67 dist\nEclipse plugin build instructions\nant -Dversion=4.0.XX -Declipse.home=/... eclipse2\nNetBeans plugin build instructions\n\nOpen artifacts/netbeans as a project in Apache Netbeans IDE 16.\nRight-click the project and click “Create NBM”.\nInstall the NBM in artifacts/netbeans/build.\n"},"notes/Software/Running-OPNsense-in-VMware-Fusion":{"slug":"notes/Software/Running-OPNsense-in-VMware-Fusion","filePath":"notes/Software/Running OPNsense in VMware Fusion.md","title":"Running OPNsense in VMware Fusion","links":[],"tags":[],"content":"Custom VM network\nCreate a custom network vmnetX in VMware settings. Uncheck “Provide addresses on this network via DHCP” and keep “Connect the host Mac to this network” checked before any VM connected to the network is started.\nWhen the OPNsense VM is stared, VMware Fusion creates a bridge10Y network interface on the host. If you checked “Connect the host Mac to this network”, the second address in the DHCP subnet, usually .1, will be assigned to the host.\nNote that the host does not run a DHCP client on the custom network, so an IP address cannot be auto-assigned by the DHCP server in your VM.\nCreate OPNsense VM\n\nConnect two network interfaces to the VM.\n\nConnect the first network adapter to your custom network vmnetX.\nConnect the second network adapter to NAT “Share with my Mac”.\n\n\nBoot the OPNsense VM.\nConfigure WAN and LAN interfaces.\n\nUse the default on first boot, which is to assign em0 to LAN and em1 to WAN.\nSet LAN interface IP address to match the vmnetX DHCP settings, with the VM’s IP address set to .2 or later to avoid conflict with the host.\nConfigure DHCP server on LAN.\n\nIPv4 client address range should be from .100 to .199.\nYou can check the config in /config/config.xml before and after the change.\nIf you don’t configure DHCP, it will continue to use the default range from 192.168.1.100 to 192.168.1.199.\n\n\nSelect N for other options and finish the LAN interface setup.\n\n\n\nSetup wizard\nIn Firefox’s Certificate Manager, add a permanent exception for the self-signed certficate at x.x.x.2.\nThen, login to the web GUI with the default root account and follow the setup wizard. Default password is opnsense and should be changed in this process.\nUnbound DNS\n“Use system nameservers” in Services→Unbound DNS→Query Forwarding is disabled by default, meaning that Unbound will recursively resolve DNS queries from the root DNS servers.\nIf enabled, Unbound will use the DNS servers entered in System→Settings→General or those obtained via DHCP or PP on WAN if the “Allow DNS server list to be overriden by DHCP/PPP on WAN” is checked.\nBlock access to private networks on WAN\nIn order to block LAN from accessing private networks on WAN, first you need to create an alias in Firewall→Aliases that represents the networks you want to block.\nCreate a network type alias rfc1918_private_networks that includes all RFC 1918 private networks and click “Apply”.\nThen, configure a firewall rule on the LAN interface, blocking incoming packets whose destination is rfc1918_private_networks. Move it above the default rules and click apply changes.\nYou also need to add a firewall rule to allow access to the Unbound DNS server. Add a Pass rule that allows incoming TCP/UDP DNS packets for the LAN address. If you want to allow LAN hosts to communicate with each other, select “LAN net” as the destination and adjust the port range accordingly."},"notes/Software/Sideloading-Blink-with-AltStore":{"slug":"notes/Software/Sideloading-Blink-with-AltStore","filePath":"notes/Software/Sideloading Blink with AltStore.md","title":"Sideloading Blink with AltStore","links":[],"tags":[],"content":"Build from source\n\nProvisioning profile “iOS Team Provisioning Profile: …” doesn’t support the Associated Domains, Fonts, iCloud, and Push Notifications capability.\n\nFollow the README to build Blink Shell in Xcode. With a free developer account, these entitlements are not supported, and therefore breaks functionality like WebAuthn.\nCrash on start\nCrash log contains Termination Reason: SIGNAL 5 Trace/BPT trap: 5, which indicates that it’s a memory safety issue from programming errors.\nOn the line where the program crashed, Blink constructs a URL from BlinkPaths.groupContainerPath() without null-safety checks.\nlet migratorFileURL = URL(fileURLWithPath: BlinkPaths.groupContainerPath()).appendingPathComponent(&quot;.migrator&quot;)\nBlinkPaths.groupContainerPath() in turn calls the containerURLForSecurityApplicationGroupIdentifier method on the default NSFileManager, which in iOS,  returns nil when the group identifier invalid for the app, i.e. missing from it’s App Groups Entitlement.\nAltStore modifications\nApp groups in entitlements\nAltStore replaces the original app group with a new one to workaround Apple’s restrictions. In func updateAppGroups, each app group identifier is appended with a . and the team identifier used to sign the app.\nfor groupIdentifier in applicationGroups\n{\n    let adjustedGroupIdentifier = groupIdentifier + &quot;.&quot; + team.identifier\n    \n    if let group = fetchedGroups.first(where: { $0.groupIdentifier == adjustedGroupIdentifier })\n    {\n        groups.append(group)\n    }\n    else\n    {\n        dispatchGroup.enter()\n        ...\nFile providers\nAny NSExtensionFileProviderDocumentGroup is rewritten into the new app group as well.\nThe filter and min chain ensures that the shortest matching candidate is found.\n// To keep file providers working, remap the NSExtensionFileProviderDocumentGroup, if there is\none.\nif var extensionInfo = infoDictionary[&quot;NSExtension&quot;] as? [String: Any],\n    let appGroup = extensionInfo[&quot;NSExtensionFileProviderDocumentGroup&quot;] as? String,\n    let localAppGroup = appGroups.filter({ $0.contains(appGroup) }).min(by: { $0.count &lt; $1.count })\n{\n    extensionInfo[&quot;NSExtensionFileProviderDocumentGroup&quot;] = localAppGroup\n    infoDictionary[&quot;NSExtension&quot;] = extensionInfo\n}\nApp bundle IDs\nThe parentBundleID is also modified to include the team ID.\nif application.isAltStoreApp\n{\n    // Use legacy bundle ID format for AltStore (and its extensions).\n    updatedParentBundleID = &quot;com.\\(team.identifier).\\(parentBundleID)&quot;\n}\nelse\n{\n    updatedParentBundleID = parentBundleID + &quot;.&quot; + team.identifier // Append just team identifier to make it harder to track.\n}\n \nlet bundleID = application.bundleIdentifier.replacingOccurrences(of: parentBundleID, with: updatedParentBundleID)\nVerification\nCrash explicitly and log app group ID on successful invocation.\ndiff --git a/BlinkConfig/BlinkPaths.m b/BlinkConfig/BlinkPaths.m\n--- a/BlinkConfig/BlinkPaths.m\n+++ b/BlinkConfig/BlinkPaths.m\n@@ -29,6 +29,7 @@\n //\n ////////////////////////////////////////////////////////////////////////////////\n \n+#import &lt;os/log.h&gt;\n #import &quot;BlinkPaths.h&quot;\n #import &quot;XCConfig.h&quot;\n \n@@ -66,6 +67,13 @@ NSString *__iCloudsDriveDocumentsPath = nil;\n \n     NSFileManager *fm = [NSFileManager defaultManager];\n     NSString *path = [fm containerURLForSecurityApplicationGroupIdentifier:groupID].path;\n+\n+    if (path == nil) {\n+      [NSException raise:@&quot;Invalid app group ID&quot; format:@&quot;app group %@ not found&quot;, groupID];\n+    } else {\n+      os_log(OS_LOG_DEFAULT, &quot;app group %{public}@ found&quot;, groupID);\n+    }\n+\n     __groupContainerPath = path;\n   }\n   return __groupContainerPath;\nBefore iOS 10, NSLog(@&quot;app group %@ found&quot;, groupID); can be used instead.\nFix\nNSString *groupID = [XCConfig infoPlistFullGroupID];\n\nThe key used to search for the group’s container directory is BLINK_GROUP_ID from XCConfig, which is stored in BlinkConfig/Info.plist.\nYou can use the variable TEAM_ID from the developer_setup.xcconfig file if you have followed Blink’s guidance on building and installing Blink yourself.\ndiff --git a/BlinkConfig/Info.plist b/BlinkConfig/Info.plist\n--- a/BlinkConfig/Info.plist\n+++ b/BlinkConfig/Info.plist\n@@ -5,7 +5,7 @@\n \t&lt;key&gt;BLINK_CLOUD_ID&lt;/key&gt;\n \t&lt;string&gt;$(CLOUD_ID)&lt;/string&gt;\n \t&lt;key&gt;BLINK_GROUP_ID&lt;/key&gt;\n-\t&lt;string&gt;$(GROUP_ID)&lt;/string&gt;\n+\t&lt;string&gt;$(GROUP_ID).$(TEAM_ID)&lt;/string&gt;\n \t&lt;key&gt;BLINK_KEYCHAIN_ID1&lt;/key&gt;\n \t&lt;string&gt;$(KEYCHAIN_ID1)&lt;/string&gt;\n \t&lt;key&gt;BLINK_REVCAT_PUBKEY&lt;/key&gt;\nHardcoding the team ID or modifying Blink’s code to auto-detect the new app group would work as well.\nReferences\n\ndeveloper.apple.com/documentation/xcode/identifying-the-cause-of-common-crashes#Determine-whether-the-crash-is-a-Swift-runtime-error\ngithub.com/blinksh/blink/blob/77d3cec7ff7dc7f2389d372d1d10dba9b9d6aaec/Blink/Migrator/Migrator.swift#L42\ngithub.com/altstoreio/AltStore/blob/7d7e098ef5e48fe346430e068271d1b1ae49817b/AltServer/Devices/ALTDeviceManager%2BInstallation.swift#L849\nstackoverflow.com/a/45957891\n"},"notes/Software/Sourcetrail":{"slug":"notes/Software/Sourcetrail","filePath":"notes/Software/Sourcetrail.md","title":"Sourcetrail","links":[],"tags":[],"content":"C/C++ Indexing\nSourcetrail can index a C/C++ project with a JSON compilation database file.\nNote that Sourcetrail only supports &quot;arguments&quot; in command objects, but Clang’s intercept-build command prefers &quot;command&quot; where possible. Therefore, it’s recommended to use another compilation database generator, for example github.com/nickdiego/compiledb."},"notes/Software/Switch-Input-Source-on-macOS":{"slug":"notes/Software/Switch-Input-Source-on-macOS","filePath":"notes/Software/Switch Input Source on macOS.md","title":"Switch Input Source on macOS","links":[],"tags":[],"content":"Built-in keyboard shortcuts\nUse Fn key or “Select … source” shortcuts to switch input source, which can be enabled in System Settings.\n\nIn addition to the options detailed above for switching input sources, you can also change input sources by using the Fn key. To use this option, in Keyboard settings, click the “Press fn key to” pop-up menu, then choose Change Input Source.\n\nInput source switching API\n\nSometimes the input source switching API (TISSelectInputSource) does not work properly for some input sources.\nIt changes an indicator (statusbar), but behavior of input source is not changed.\nThis issue is occurred on the input sources which has complex behavior such as Japanese.\n\nIt’s a macOS bug that CJK input sources can not be switched to reliably by calling the API.\nWorkaround\nNo simple yet reliable workaround.\nReferences\n\nsupport.apple.com/en-us/guide/mac-help/kbdm162/mac\ngithub.com/Hammerspoon/hammerspoon/issues/1429\ngithub.com/tekezo/Karabiner/issues/308#issuecomment-190693550\ngithub.com/tekezo/Karabiner/blob/version_10.15.0/src/core/server/Resources/vkchangeinputsourcedef.xml#L210-L236\ngithub.com/nuridol/SwitchIM/blob/db93e4d0f299916670b4a36222abfc84dda9f4b7/SwitchIM/SwitchIM.swift#L132-L140\n"},"notes/Software/Terminal-protocols":{"slug":"notes/Software/Terminal-protocols","filePath":"notes/Software/Terminal protocols.md","title":"Terminal protocols","links":[],"tags":[],"content":"Sequences\nPrimary Device Attributes (DA1)\nThis is used to report operating VT level and supported extensions, e.g. Sixel.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEscape CodeExplanationCSI c or CSI 0 cCSI is ESC [ or ^[[. This is a Primary Device Attributes (DA1) request.CSI ? 64 ; Ps1 ; ... Psn cStandard DA1 response format. Ps1 to Psn represents specific features.CSI ? *level* ; 1 ; 2 ; 6 ; 9 ; 15 cwith level = 60 + (decTerminalID / 100) (default 64)CSI ? 1 ; 2 cVT100CSI ? 1 ; 0 cVT101CSI ? 6 vVT102\nNote: spaces are added for readability. They do not exist in actual DA1 escape codes.\nReferences:\n\ngithub.com/KDE/konsole/commit/2d93fed82aa27e89c9d7301d09d2e24e4fa4416d#diff-0d4b7240b969dc3d1f694d7e7a8c71a1a318f1f928acbbf1b27d809e65a56c8fR682\nSee vt100.net/docs/vt510-rm/DA1.html for a list of extension codes.\n\nModes\nSynchronized updates (DECSET/DECRST 2026)\nSee gitlab.freedesktop.org/terminal-wg/specifications/-/merge_requests/2 for the canonical specification."},"notes/Software/UTM":{"slug":"notes/Software/UTM","filePath":"notes/Software/UTM.md","title":"UTM","links":["notes/Operating-System/macOS/Paravirtualized-graphics"],"tags":[],"content":"Graphics\nParavirtualized graphics only work for Apple Silicon Macs. github.com/utmapp/UTM/issues/3491\nDefault QEMU VirGL backend on macOS is virtio-gpu-gl-pci.\nOn Intel Macs, UI will freeze after host recovers from sleep. If you’ve encountered this, switch back to virtio-gpu-pci.\nmacOS guest\nmacOS Installer can be downloaded with github.com/ninxsoft/Mist.\nopenSUSE guest\nThe installer requires a serial device. You can remove it afterwards. See github.com/utmapp/UTM/issues/5251.\nBridged network\nBridged networking may break IPv6 on host. Symptom is that the host is unable to receive neighbor solicitation messages from the router.\nYou can use the default shared network instead, which implements NAT66."},"notes/Software/VMware-Fusion-and-Workstation":{"slug":"notes/Software/VMware-Fusion-and-Workstation","filePath":"notes/Software/VMware Fusion and Workstation.md","title":"VMware Fusion and Workstation","links":["notes/Software/VMware-Fusion-guest-features"],"tags":[],"content":"See also VMware Fusion guest features.\nDownload\nOn November 11, 2024, Broadcom announced that VMware Fusion and Workstation will be available for free to everyone.\nHowever, until a new release is made, VMware Fusion Pro still says “Licensed for Personal Use only.”\nYou can download binaries for free from support.broadcom.com/group/ecx/downloads. Select “VMware Cloud Foundation” from the top-right dropdown menu, and search for the product you want.\nDNF command stuck on openEuler guest\nstrace shows it’s trying to resolve the local hostname. Promoting myhostname in hosts: entry of /etc/nsswitch.conf fixes it. Alternatively, you could also modify the /etc/hosts file."},"notes/Software/VMware-Fusion-guest-features":{"slug":"notes/Software/VMware-Fusion-guest-features","filePath":"notes/Software/VMware Fusion guest features.md","title":"VMware Fusion guest features","links":[],"tags":[],"content":"Supported guest operating systems\nOnly Windows and Linux. See web.archive.org/web/20241130004426/https://knowledge.broadcom.com/external/article\nNested virtualization\nNot supported yet. See knowledge.broadcom.com/external/article and community.broadcom.com/vmware-cloud-foundation/question/nested-virtualization-with-vmware-fusion-in-sequoia.\n\nApple has stated that the feature is available on Sonoma for VMs using the high level Virtualization Framework — the ones that Fusion does NOT use.\n\nx86 and x64 emulation\nWindows 11 on Arm supports emulation of both x86 and x64 apps and performance has been enhanced with the new emulator Prism, introduced in Windows 11 24H2.\nAccelerated 3D Graphics\n\nOn VMs running Windows 7 or later, Fusion supports DirectX 11 with OpenGL 4.3.\nOn VMs running Linux, Fusion supports OpenGL 4.3 for accelerated 3D graphics.\n\nTime synchronization on Linux guests\nEnable “Synchronize time” in VM Settings → Advanced and install open-vm-tools in guest VM.\nIf that didn’t work, a workaround is to allow an NTP daemon to correct time.\nFor chrony, modify /etc/chrony.conf to let chronyd step the system clock at all times when its offset is larger than 5 seconds.\nmakestep 5.0 -1\n"},"notes/Software/WeeChat-config":{"slug":"notes/Software/WeeChat-config","filePath":"notes/Software/WeeChat config.md","title":"WeeChat config","links":[],"tags":[],"content":"ZNC multi-connect and CertFP\nConnect to multiple networks by specifying network name in username in username/networkname format.\n/server add networkname IP/port -ssl -username=username/networkname -password=x -autoconnect\n/set irc.server.snoonet.ssl_fingerprint xxxx\n/set irc.server.libera.ssl_cert &quot;${weechat_config_dir}/ssl/client.pem&quot;\nSet irc.server.libera.ssl_fingerprint to verify with fingerprint only if your server has a self-signed certificate.\nEncrypt config for local certificate authentication\nGenerate a TLS certificate with its corresponding private key attached and protected by a password, and then extract the certificate fingerprint.\nopenssl req -x509 -new -newkey ed25519 -sha256 -out l2dy.example.pem -keyout l2dy.example.pem\nopenssl x509 -in l2dy.example.pem -noout -fingerprint -sha256 | awk -F= &#039;{gsub(&quot;:&quot;,&quot;&quot;); print tolower ($2)}&#039;\nThen, authenticate to IRC server with your password and ask NickServ to save the SHA256 fingerprint.\nFinally, configure WeeChat to use CertFP authentication and auto connect.\n# Add server\n/server add example irc.example.com/6697 -tls\n/set irc.server.example.tls_cert %h/certs/l2dy.example.pem\n/set irc.server.example.sasl_mechanism external\n/set irc.server.example.autojoin &quot;#!&quot;\n# Save encrypted password\n/secure passphrase &lt;password to type when starting WeeChat&gt;\n/secure set exampletls &lt;password for the private key&gt;\n/set irc.server.example.tls_password &quot;${sec.data.exampletls}&quot;\n \n# Test connection\n/connect example\n \n# Enable auto-connect\n/set irc.server.example.autoconnect on\nLook and feel\nSeparate server buffers\n/set irc.look.server_buffer independent\nIRC smart filter\n/filter add irc_smart * irc_smart_filter *\nXDG directories\nTable of default directories and paths.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariableDefault valueFallback valueweechat_config_dir$XDG_CONFIG_HOME/weechat$HOME/.config/weechat if $XDG_CONFIG_HOME is not defined or emptyweechat_data_dir$XDG_DATA_HOME/weechat$HOME/.local/share/weechat if $XDG_DATA_HOME is not defined or emptyweechat_cache_dir$XDG_CACHE_HOME/weechat$HOME/.cache/weechat if $XDG_CACHE_HOME is not defined or emptyweechat_runtime_dir$XDG_RUNTIME_DIR/weechatsame as cache directory if $XDG_RUNTIME_DIR is not defined or empty\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptionDefault valuefifo.file.path${weechat_runtime_dir}/weechat_fifo_${info:pid}logger.file.path${weechat_data_dir}/logsrelay.network.ssl_cert_key${weechat_config_dir}/ssl/relay.pemscript.scripts.path${weechat_cache_dir}/scriptweechat.plugin.path${weechat_data_dir}/pluginsxfer.file.download_path${weechat_data_dir}/xfer\ngithub.com/weechat/weechat/blob/b614a5c5db243ad64f0ab32e4e68d221e57878b7/ReleaseNotes.adoc#v3.2_xdg_directories"},"notes/Software/WeeChat":{"slug":"notes/Software/WeeChat","filePath":"notes/Software/WeeChat.md","title":"WeeChat","links":["notes/Software/WeeChat-config"],"tags":[],"content":"See also WeeChat config.\nSwitch between buffers\nPress Alt+number to switch to the corresponding numbered buffer.\nTo switch between server and WeeChat core buffers, press Ctrl+X.\nIt’s also possible to turn off the auto merge of server buffers:\n/set irc.look.server_buffer independent\n"},"notes/Software/Wireshark":{"slug":"notes/Software/Wireshark","filePath":"notes/Software/Wireshark.md","title":"Wireshark","links":[],"tags":[],"content":"Expert information\n\nWireshark keeps track of any anomalies and other items of interest it finds in a capture file and shows them in the Expert Information dialog. The goal is to give you a better idea of uncommon or notable network behavior and to let novice and expert users find network problems faster than manually scanning through the packet list.\n\n\nYou can open the expert info dialog by selecting Analyze → Expert Info or by clicking the expert level indicator in the main status bar.\nRight-clicking on an item will allow you to apply or prepare a filter based on the item, copy its summary text, and other tasks.\n\nTips and tricks\nFilter for SYN retransmission\ntcp.analysis.retransmission and tcp.flags.syn == 1\n\nReferences\n\nwww.wireshark.org/docs/wsug_html_chunked/ChAdvExpert.html\n"},"notes/Software/Xcode-sanitizer-support":{"slug":"notes/Software/Xcode-sanitizer-support","filePath":"notes/Software/Xcode sanitizer support.md","title":"Xcode sanitizer support","links":[],"tags":[],"content":"Xcode documentation lists several runtime tools, including sanitizers.\n\nXcode provides several runtime tools to identify potential issues in your code:\n\nAddress Sanitizer—The ASan tool identifies potential memory-related corruption issues.\nThread Sanitizer—The TSan tool detects race conditions between threads.\nMain Thread Checker—This tool verifies that system APIs that must run on the main thread actually do run on that thread.\nUndefined Behavior Sanitizer—The UBSan tool detects divide-by-zero errors, attempts to access memory using a misaligned pointer, and other undefined behaviors.\n\n\nAddress Sanitizer runtime\nOn macOS and iOS, Address Sanitizer requires a dynamic library that contains the asan runtime to run.\nIf the compiler version that a dependency framework is compiled with and the compiler version of your Xcode mismatches, you may see errors like dyld[xxx]: missing symbol called when you have Address Sanitizer enabled across them."},"notes/Software/ZNC":{"slug":"notes/Software/ZNC","filePath":"notes/Software/ZNC.md","title":"ZNC","links":[],"tags":[],"content":"CertFP with server\nOne certificate per user only. Make sure you have a backup before updating it from Web UI.\nwiki.znc.in/Cert\nCertFP with client\nChat with *certauth to manage keys. It’s not configurable from Web UI.\nwiki.znc.in/Certauth\n/msg *certauth help\n&lt;*certauth&gt; Commands: show, list, add, del [no]\n/msg *certauth show\n&lt;*certauth&gt; Your current public key is: ...\n/msg *certauth list\n&lt;*certauth&gt; No keys set for your user\n/msg *certauth add\n&lt;*certauth&gt; Added your current public key to the list\n/msg *certauth list\n...\n"},"notes/Software/Zellij":{"slug":"notes/Software/Zellij","filePath":"notes/Software/Zellij.md","title":"Zellij","links":["notes/Software/Terminal-protocols"],"tags":[],"content":"Scrolling\nZellij support scrolling with mouse out of the box, and can auto-detect a scrollable program and switch from scrollback buffer to it.\nBugs\n\nZellij is slow at displaying ANSI-colored content over a slow SSH connection with buffer scrolling involved.\n\nZellij is fast too if no scrolling is involved, e.g. colored content is less than tput lines and buffer is clear.\nTmux is fast in both cases.\nZellij updates SCROLL: 0/xxx after each line of output, which probably slowed it down.\n\n\nZellij reports Sixel support in Primary Device Attributes (DA1) response even if underlying terminal does not support it. github.com/zellij-org/zellij/issues/3158\n\nReferences\n\nvt100.net/docs/vt510-rm/DA1.html\nterminalguide.namepad.de/seq/csi_sc/\nchromium.googlesource.com/apps/libapps/+/573b4f0d07264cc2b06bd9b21a5e3618af600040/hterm/js/hterm_vt.js#2712\n"},"notes/Software/a-Shell":{"slug":"notes/Software/a-Shell","filePath":"notes/Software/a-Shell.md","title":"a-Shell","links":[],"tags":[],"content":"Settings\nSettings are available in the system’s Settings app.\nDirectories\n\n~xxx represents a bookmark. You can list existing bookmarks with showmarks.\n~ (home directory) is not writable, so there are pre-defined environment variables that redirect programs to use ~/Documents or ~/Library.\n"},"notes/Software/iTerm2-features":{"slug":"notes/Software/iTerm2-features","filePath":"notes/Software/iTerm2 features.md","title":"iTerm2 features","links":[],"tags":[],"content":"Selection inside tmux or Emacs splits\nIn the Edit system menu, enable Selection Respects Soft Boundaries.\nRecover deleted windows or splits\nPress s-Z within a few seconds to get a closed window back.\nSearch\nTo fix a search highlight bug, go to advanced settings and turn off “Synchronize search queries across windows and applications”.\nCopy mode\nTo copy text from iTerm2 with keyboard only, press s-S-c to activate copy mode.\nIn copy mode, press v, V or C-v to toggle selection by character, line, or rectangle, similar to Vim’s Visual mode. hjkl and word-based movement keys are also supported.\nTo copy the selection, press y. To quit copy mode, press q."},"notes/Software/nix-env-dependency-tree":{"slug":"notes/Software/nix-env-dependency-tree","filePath":"notes/Software/nix-env dependency tree.md","title":"nix-env dependency tree","links":[],"tags":[],"content":"List installed packages\nnix-env -q\nList dependency tree of user environment\nnix-store -q --tree ~/.nix-profile"},"notes/Startup/Earthly-CI-postmortem":{"slug":"notes/Startup/Earthly-CI-postmortem","filePath":"notes/Startup/Earthly CI postmortem.md","title":"Earthly CI postmortem","links":[],"tags":[],"content":"earthly.dev/blog/shutting-down-earthly-ci/\nFeatures are not what makes you successful.\n\nYou’ll never be more mature, or have more features, or more integrations than the incumbents.\nYou can be 10x better in one, very specific way. And you’ll appeal to the few teams where the very specific problem you’re solving is so painful that they’re willing to make compromises on everything else.\nThen, once you have captured that segment, you invest more, extend to a wider audience, get more feedback, then again invest more, extend again, and so on.\nSo if your MVP is not getting enough validation, you can’t just slap more features on it, because, again, features are not what will make you successful. Incumbents win feature contests.\n\nBuild the product incrementally.\n\nLearning from mistakes of the past, at Earthly we built everything incrementally. And we even put products on the market that initially seemed like purely engineering intermediate milestones. Each product builds on top of the previous achievements, thus allowing for incremental iteration with the customer in mind. We’re now seeing our latest incremental iteration not working in the marketplace. And, knowing what I know about early products, it’s not the missing features that are the problem.\n\nFail fast.\n\nThere were some early signals that certain aspects of the product did not align with what the industry needs, but we didn’t listen. We just kept building.\nMy biggest regret from the experience was that we did not stop earlier when the signs were there.\n"},"notes/Startup/How-to-be-a-manager":{"slug":"notes/Startup/How-to-be-a-manager","filePath":"notes/Startup/How to be a manager.md","title":"How to be a manager","links":[],"tags":[],"content":"barely-managing.bearblog.dev/"},"notes/Startup/Payment-gateways-for-individuals":{"slug":"notes/Startup/Payment-gateways-for-individuals","filePath":"notes/Startup/Payment gateways for individuals.md","title":"Payment gateways for individuals","links":[],"tags":[],"content":"i.e. unincorporated business\n\nsupport.stripe.com/questions/selling-on-stripe-without-a-separate-business-entity\n\nMaybe?\n\nwww.paddle.com/\nGitHub Sponsors (OSS donations only)\n"},"notes/Startup/SaaS-product-strategy-at-Tanda":{"slug":"notes/Startup/SaaS-product-strategy-at-Tanda","filePath":"notes/Startup/SaaS product strategy at Tanda.md","title":"SaaS product strategy at Tanda","links":[],"tags":[],"content":"ghiculescu.substack.com/p/11-years-of-saas-product-strategy"},"notes/Storage/Changing-logical-sector-size-of-NVMe-SSDs":{"slug":"notes/Storage/Changing-logical-sector-size-of-NVMe-SSDs","filePath":"notes/Storage/Changing logical sector size of NVMe SSDs.md","title":"Changing logical sector size of NVMe SSDs","links":[],"tags":[],"content":"Introduction\nThe default fdisk -l output of two example datacenter SSDs are respectively\nDisk /dev/nvme2n1: 1.75 TiB, 1920383410176 bytes, 3750748848 sectors\nDisk model: INTEL SSDPF2KX019T1O\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\n\nDisk /dev/nvme2n1: 1.75 TiB, 1920383410176 bytes, 3750748848 sectors\nDisk model: Micron_7450_MTFDKCC1T9TFR\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\n\nand after reformatting, you get\nDisk /dev/nvme2n1: 1.75 TiB, 1920383410176 bytes, 468843606 sectors\nDisk model: INTEL SSDPF2KX019T1O\nUnits: sectors of 1 * 4096 = 4096 bytes\nSector size (logical/physical): 4096 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\n\nDisk /dev/nvme2n1: 1.75 TiB, 1920383410176 bytes, 468843606 sectors\nDisk model: Micron_7450_MTFDKCC1T9TFR\nUnits: sectors of 1 * 4096 = 4096 bytes\nSector size (logical/physical): 4096 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\n\nYou can check available LBA formats with nvme-cli:\napt-get install nvme-cli\nfor i in {0..3}; do\n  echo &quot;/dev/nvme$i:&quot;\n  nvme id-ctrl /dev/nvme${i} -H | grep &quot;LBA Format&quot;\n  echo &quot;---&quot;\n  nvme id-ns /dev/nvme${i}n1 -H | grep &quot;LBA Format&quot;\n  echo\ndone\n/dev/nvme2:\n  [15:15] : 0   Extended LBA Formats Not Supported\n---\n  [6:5] : 0     Most significant 2 bits of Current LBA Format Selected\n  [3:0] : 0     Least significant 4 bits of Current LBA Format Selected\nLBA Format  0 : Metadata Size: 0   bytes - Data Size: 512 bytes - Relative Performance: 0x2 Good (in use)\nLBA Format  1 : Metadata Size: 0   bytes - Data Size: 4096 bytes - Relative Performance: 0 Best\n\nYou should use the LBA format with best relative performance, and in this case, LBA format 1.\n\n\n                  \n                  NOTE\n                  \n                \n\ngithub.com/letsencrypt/openzfs-nvme-databases suggests using sst show -display SectorSize -ssd to check the sector size of Intel SSD drives, but for i in {0..3}; do sst show -display SectorSize,SectorDataSize -ssd $i; done results show that SectorSize and SectorDataSize have the same value and both of them correspond to the LBA format used by the namespace block device. Hence, you should use the more generic nvme-cli instead of sst.\n\n\nFormatting\nFormatting an NVMe namespace erases all data, so if you have already constructed a ZFS mirror on top of the disks, you must detach it first.\nzpool detach rpool /dev/disk/by-id/nvme-Micron_...\nThen, reformat the namespace with the desired LBA Format. Usually it should be “Metadata Size: 0 bytes - Data Size: 4096 bytes” and have the best Relative Performance level.\nnvme format /dev/nvme2n1 --lbaf=1\n\nIf the disk was part of a ZFS mirror, attach it back to mirror the other device.\n# zpool attach [-fsw] [-o property=value] pool device new_device\nzpool attach -o ashift=12 rpool /dev/disk/by-id/nvme-Micron_... /dev/disk/by-id/nvme-Micron_...\nand check fdisk -l results again."},"notes/Storage/Test-hard-disk-quality":{"slug":"notes/Storage/Test-hard-disk-quality","filePath":"notes/Storage/Test hard disk quality.md","title":"Test hard disk quality","links":[],"tags":[],"content":"Bad blocks\n# WARNING: destructive\nbadblocks -wsv /dev/device\n"},"notes/Storage/USB-hub-power-supply":{"slug":"notes/Storage/USB-hub-power-supply","filePath":"notes/Storage/USB hub power supply.md","title":"USB hub power supply","links":[],"tags":[],"content":"If a USB hub could not power two portable hard drives simultaneously, it could be that there isn’t sufficient power. To resolve this, use dedicated power supply to power the hub.\nDO NOT use the hub to power your laptop. It may work when the laptop is idle, but once the laptop draws too much power, hard drives become unstable and get disconnected."},"notes/Storage/ZFS-compression-test":{"slug":"notes/Storage/ZFS-compression-test","filePath":"notes/Storage/ZFS compression test.md","title":"ZFS compression test","links":[],"tags":[],"content":"\n1M recordsize does not improve compress ratio.\nzstd performs better than lz4.\n\n% zfs get recordsize\nNAME             PROPERTY    VALUE    SOURCE\n/Test1           recordsize  128K     default\n/Test2           recordsize  1M       local\n/Test3           recordsize  128K     default\n/Test4           recordsize  1M       local\n% zfs get compression\nNAME             PROPERTY     VALUE           SOURCE\n/Test1           compression  lz4             inherited\n/Test2           compression  lz4             inherited\n/Test3           compression  zstd            local\n/Test4           compression  zstd            local\n\n% zfs get compressratio\nNAME             PROPERTY       VALUE  SOURCE\n/Test1           compressratio  1.00x  -\n/Test2           compressratio  1.00x  -\n/Test3           compressratio  1.02x  -\n/Test4           compressratio  1.02x  -\n% zfs list\nNAME       USED  AVAIL  REFER  MOUNTPOINT\n/Test1     1.91G   651G  1.91G  /Volumes/zero_backup/Test1\n/Test2     1.92G   651G  1.92G  /Volumes/zero_backup/Test2\n/Test3     1.88G   651G  1.88G  /Volumes/zero_backup/Test3\n/Test4     1.89G   651G  1.89G  /Volumes/zero_backup/Test4\n"},"notes/Storage/ZFS":{"slug":"notes/Storage/ZFS","filePath":"notes/Storage/ZFS.md","title":"ZFS","links":["notes/Storage/ZFS-compression-test"],"tags":[],"content":"Recommended Settings\nzpool create \\\n      -o ashift=12 \\\n      -O compression=zstd \\\n      -O atime=off \\\n      -O xattr=off \\\n      -O dnodesize=auto \\\n      &lt;...&gt;\n\nashift=12 sets pool sector size.\nThe typical case for setting this property is when performance is important and the underlying disks use 4KiB sectors but report 512B sectors to the OS (for compatibility reasons); in that case, set ashift=12 (which is 1&lt;&lt;12 = 4096).\ncompression=zstd enables zstd compression. lz4 is recommended for generic workload, while zstd has better compression.\natime=off turns access time update off.\nxattr=off turns extended attributes off.\ndnodesize=auto to use the large_dnode feature.\n\nDatasets\nzfs craete &lt;dataset&gt;\n\nSnapshots\n# Create snapshot\nzfs snap &lt;volume&gt;@&lt;snapshot_name&gt;\n# Delete snapshot (dry-run)\nzfs destroy -vn &lt;volume&gt;@&lt;snapshot_name&gt;\n# List snapshots\nzfs list -t snapshot\n# Restore snapshot\nzfs rollback &lt;volume&gt;@&lt;snapshot_name&gt;\nDataset properties\nRecord size\n\n\n                  \n                  Note \n                  \n                \n\nThe default 128KiB is good enough for most cases. See also ZFS compression test.\n\n\nGeneral rules of thumb:\n\n1MiB for general-purpose file sharing/storage\n1MiB for BitTorrent download folders—this minimizes the impact of fragmentation!\n64KiB for KVM virtual machines using Qcow2 file-based storage\n16KiB for MySQL InnoDB \n8KiB for PostgreSQL\n\nSee klarasystems.com/articles/tuning-recordsize-in-openzfs/.\nCompression\n# List logical and compressed size\nzfs list -o name,logicalused,used,compressratio\n# List current compression config\nzfs get compression\n# Set zstd compression\nzfs set compression=zstd pool[/component]\n# Inherit from parent\nzfs inherit compression pool[/component]\nApplying to existing data\ncompression and deduplication can be applied to existing data with filerewrite, but recordsize change can not be applied in-place.\nAdding disks\nzpool attach adds a new device to an existing vdev in the pool, mirroring its content during the resilver process that is started immediately. This does not expand the pool’s capacity.\nzpool add adds a new vdev to the pool, expanding its capacity. You may also use this command to add a separate intent log or cache device on SSD to improve performance.\nRescue mount\nLinux\nmount -o zfsutil -t zfs &lt;dataset&gt; &lt;mountpoint&gt;\n\nZFS on Linux features and gotchas\n\n2.3.0: RAIDZ expansion, fast dedup, direct IO, long names.\n\nAvailable in Ubuntu since 25.04 (Plucky Puffin)\nDirect IO is  O_DIRECT support.\nFast dedup is still resource-intensive.\n\n\n\n\n\n                  \n                  WARNING\n                  \n                \n\nAll services depending on a ZFS filesystem should add a dependency on zfs.target to prevent early termination of critical ZFS services like zfs-zed.service. Otherwise your servicews may lose access to ZFS filesystems in their shutdown process and become stuck on I/O.\n\n\n[Unit]\nWants=zfs.target\nAfter=zfs.target\nOn Ubuntu, /etc/cron.d/zfsutils-linux schedules scrubbing on the second Sunday of every month.\nReferences\n\nwww.high-availability.com/docs/ZFS-Tuning-Guide/\n"},"notes/Storage/zstd-compression":{"slug":"notes/Storage/zstd-compression","filePath":"notes/Storage/zstd compression.md","title":"zstd compression","links":[],"tags":[],"content":"libarchive\n\nlibarchive built with libzstd has the best compression ratio.\nThe default level 3 is good for media files. YMMV.\n\n$ /usr/bin/bsdtar --version\nbsdtar 3.5.3 - libarchive 3.5.3 zlib/1.2.11 liblzma/5.0.5 bz2lib/1.0.8\n$ bsdtar --version\nbsdtar 3.7.2 - libarchive 3.7.2 zlib/1.2.13 liblzma/5.2.6 bz2lib/1.0.8 liblz4/1.9.3 libzstd/1.5.5\n$ zstd --version\n*** Zstandard CLI (64-bit) v1.5.5, by Yann Collet ***\n\n$ time bsdtar -cf /tmp/tar-raw.tar &lt;dir&gt;\n3.16s user 43.18s system 72% cpu 1:03.68 total\n$ time bsdtar --zstd -cf /tmp/tar-builtin.tar.zst &lt;dir&gt;\n62.27s user 44.48s system 90% cpu 1:57.63 total\n$ time /usr/bin/bsdtar --zstd -cf /tmp/tar-pipe.tar.zst &lt;dir&gt;\n61.47s user 64.16s system 166% cpu 1:15.60 total\n$ zstd tar-raw.tar\n$ time bsdtar --options zstd:compression-level=6 --zstd -cf /tmp/tar-z6.tar.zst &lt;dir&gt;\n124.99s user 42.30s system 93% cpu 2:58.48 total\n\n$ ls -goS\n-rw-r--r-- 1 36944175616 Oct 28 16:28 tar-raw.tar\n-rw-r--r-- 1 36801599496 Oct 28 16:28 tar-raw.tar.zst\n-rw-r--r-- 1 36801599484 Oct 28 16:30 tar-pipe.tar.zst\n-rw-r--r-- 1 36800436486 Oct 28 16:30 tar-builtin.tar.zst\n-rw-r--r-- 1 36792020901 Oct 28 17:08 tar-z6.tar.zst\n\n# Another directory\n\n$ time bsdtar -cf /tmp/tar-raw.tar &lt;dir&gt;\n0.55s user 7.16s system 61% cpu 12.488 total\n$ time bsdtar --zstd -cf /tmp/tar-builtin.tar.zst &lt;dir&gt;\n9.22s user 6.90s system 92% cpu 17.359 total\n$ time /usr/bin/bsdtar --zstd -cf /tmp/tar-pipe.tar.zst &lt;dir&gt;\n10.79s user 11.46s system 180% cpu 12.357 total\n$ zstd tar-raw.tar\n\n$ time bsdtar --options zstd:compression-level=6 --zstd -cf /tmp/tar-z6.tar.zst &lt;dir&gt;\n20.41s user 7.94s system 92% cpu 30.542 total\n$ time bsdtar --options zstd:compression-level=9 --zstd -cf /tmp/tar-z9.tar.zst &lt;dir&gt;\n37.27s user 7.34s system 96% cpu 46.029 total\n\n$ ls -goS\n-rw-r--r-- 1 6452066816 Oct 28 16:54 tar-raw.tar\n-rw-r--r-- 1 6427283841 Oct 28 16:54 tar-raw.tar.zst\n-rw-r--r-- 1 6427283829 Oct 28 16:55 tar-pipe.tar.zst\n-rw-r--r-- 1 6427182872 Oct 28 16:54 tar-builtin.tar.zst\n-rw-r--r-- 1 6425529524 Oct 28 17:02 tar-z6.tar.zst\n-rw-r--r-- 1 6423828358 Oct 28 17:03 tar-z9.tar.zst\n\nCompression threads\n#if HAVE_ZSTD_H &amp;&amp; HAVE_LIBZSTD_COMPRESSOR is true, libarchive defaults to set 0 ZSTD_c_nbWorkers, which is to use the number of physical CPU cores.\nOtherwise, given that data-&gt;threads != 0 is not true, the --threads flag will not be appended to command and 1 working thread is used by default.\nCompression levels\nWhen in doubt, either stick with the default level of 3 or something from the 6 to 9 range for a nice trade-off of speed versus space.\nReferences\n\nengineering.fb.com/2016/08/31/core-infra/smaller-and-faster-data-compression-with-zstandard/\n"},"notes/Twitter":{"slug":"notes/Twitter","filePath":"notes/Twitter.md","title":"Twitter","links":[],"tags":[],"content":"uBlock Origin rules\n! Discover more / More Tweets - Conversation view suggestions\ntwitter.com##[aria-label=&quot;Timeline: Conversation&quot;] [data-testid=&quot;cellInnerDiv&quot;] h2:has-text(/^(Discover more|More Tweets)$/):upward([data-testid=&quot;cellInnerDiv&quot;])\ntwitter.com##[aria-label=&quot;Timeline: Conversation&quot;] [data-testid=&quot;cellInnerDiv&quot;] h2:has-text(/^(Discover more|More Tweets)$/):upward([data-testid=&quot;cellInnerDiv&quot;])~div\n"},"notes/Unicode":{"slug":"notes/Unicode","filePath":"notes/Unicode.md","title":"Unicode","links":[],"tags":[],"content":"List of all Emoji characters\nwww.unicode.org/Public/emoji/16.0/emoji-test.txt\nNames list charts\nwww.unicode.org/charts/nameslist/\n\nClick on the block name to get to a code chart.\nClick on a code point in the chart to get the names list. Hovering over the code point shows the name.\n\nSearch for any Unicode character\nunicodeplus.com/"}}